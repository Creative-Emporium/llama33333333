{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dim': 4096,\n",
       " 'n_layers': 32,\n",
       " 'n_heads': 32,\n",
       " 'n_kv_heads': 8,\n",
       " 'vocab_size': 128256,\n",
       " 'multiple_of': 1024,\n",
       " 'ffn_dim_multiplier': 1.3,\n",
       " 'norm_eps': 1e-05,\n",
       " 'rope_theta': 500000.0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "params = json.loads(open('8B-Instruct.local/params.json', 'r').read())\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelArgs(dim=4096, n_layers=32, n_heads=32, n_kv_heads=8, vocab_size=128256, multiple_of=1024, ffn_dim_multiplier=1.3, norm_eps=1e-05, rope_theta=500000.0, max_batch_size=1, max_seq_len=512)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama.model import ModelArgs, Transformer\n",
    "\n",
    "\n",
    "model_args = ModelArgs(max_seq_len=512, max_batch_size=1, **params)\n",
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (tok_embeddings): VocabParallelEmbedding()\n",
       "  (layers): ModuleList(\n",
       "    (0-31): 32 x TransformerBlock(\n",
       "      (attention): Attention(\n",
       "        (wq): ColumnParallelLinear()\n",
       "        (wk): ColumnParallelLinear()\n",
       "        (wv): ColumnParallelLinear()\n",
       "        (wo): RowParallelLinear()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): ColumnParallelLinear()\n",
       "        (w2): RowParallelLinear()\n",
       "        (w3): ColumnParallelLinear()\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): ColumnParallelLinear()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from fairscale.nn.model_parallel.initialize import (\n",
    "    get_model_parallel_rank,\n",
    "    initialize_model_parallel,\n",
    "    model_parallel_is_initialized,\n",
    ")\n",
    "\n",
    "\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '1'\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "\n",
    "if not torch.distributed.is_initialized():\n",
    "\ttorch.distributed.init_process_group(\"nccl\")\n",
    "if not model_parallel_is_initialized():\n",
    "\tinitialize_model_parallel(1)\n",
    "\n",
    "\n",
    "model = Transformer(model_args)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "         114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "         128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
       "         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
       "         198, 199]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = torch.arange(100, 200).long()[None]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 100, 128256]),\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = model(tokens, 0)\n",
    "o.shape, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 4096])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = model.tok_embeddings(tokens)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 64]),\n",
       " tensor([[ 1.0000+0.0000e+00j,  1.0000+0.0000e+00j,  1.0000+0.0000e+00j,\n",
       "           ...,  1.0000+0.0000e+00j,  1.0000+0.0000e+00j,\n",
       "           1.0000+0.0000e+00j],\n",
       "         [ 0.5403+8.4147e-01j,  0.6861+7.2746e-01j,  0.7878+6.1596e-01j,\n",
       "           ...,  1.0000+3.6997e-06j,  1.0000+3.0139e-06j,\n",
       "           1.0000+2.4551e-06j],\n",
       "         [-0.4161+9.0930e-01j, -0.0584+9.9829e-01j,  0.2412+9.7048e-01j,\n",
       "           ...,  1.0000+7.3994e-06j,  1.0000+6.0277e-06j,\n",
       "           1.0000+4.9103e-06j],\n",
       "         ...,\n",
       "         [-0.9998+1.7612e-02j, -0.6982+7.1587e-01j,  0.5001-8.6597e-01j,\n",
       "           ...,  1.0000+3.7774e-03j,  1.0000+3.0771e-03j,\n",
       "           1.0000+2.5067e-03j],\n",
       "         [-0.5550-8.3182e-01j, -0.9999-1.6764e-02j,  0.9274-3.7418e-01j,\n",
       "           ...,  1.0000+3.7811e-03j,  1.0000+3.0802e-03j,\n",
       "           1.0000+2.5092e-03j],\n",
       "         [ 0.4001-9.1649e-01j, -0.6739-7.3884e-01j,  0.9610+2.7647e-01j,\n",
       "           ...,  1.0000+3.7848e-03j,  1.0000+3.0832e-03j,\n",
       "           1.0000+2.5116e-03j]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.freqs_cis.shape, model.freqs_cis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 100]),\n",
       " tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "         [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., -inf, -inf],\n",
       "         [0., 0., 0.,  ..., 0., 0., -inf],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full((100, 100), float(\"-inf\"), device=tokens.device)\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask = torch.hstack([torch.zeros((100, 0), device=tokens.device), mask]).type_as(h)\n",
    "mask.shape, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 100, 4096]),\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_cis = model.freqs_cis[0 : 100]\n",
    "\n",
    "layer = model.layers[0]\n",
    "\n",
    "h1 = layer(h, 0, freqs_cis, mask)\n",
    "h1.shape, h1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
