{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tok_embeddings.weight': tensor([[ 1.3733e-03,  5.0964e-03, -3.0365e-03,  ...,  2.2888e-03,\n",
       "          -1.9531e-03, -1.7166e-05],\n",
       "         [-2.7313e-03,  1.9379e-03, -1.3733e-03,  ..., -5.1498e-05,\n",
       "          -1.3962e-03, -1.9836e-03],\n",
       "         [ 9.5367e-04, -1.3367e-02,  4.1771e-04,  ...,  2.5940e-03,\n",
       "           7.0496e-03,  4.1809e-03],\n",
       "         ...,\n",
       "         [ 1.8715e-23,  3.2699e-24,  1.8198e-23,  ...,  5.3767e-23,\n",
       "          -2.2360e-24, -1.9852e-23],\n",
       "         [ 1.9335e-23, -1.8612e-24, -1.8818e-23,  ...,  2.3368e-23,\n",
       "           7.3412e-24, -3.1226e-23],\n",
       "         [-7.4860e-23, -6.3693e-23,  5.5059e-24,  ...,  4.9631e-24,\n",
       "          -5.4594e-23, -2.2877e-24]], dtype=torch.bfloat16),\n",
       " 'layers.0.attention.wq.weight': tensor([[-2.7618e-03, -2.9053e-02, -3.1586e-03,  ...,  7.3547e-03,\n",
       "          -4.6875e-02, -2.1606e-02],\n",
       "         [ 2.6367e-02,  3.3264e-03, -8.4839e-03,  ..., -7.5378e-03,\n",
       "          -5.7678e-03,  5.6458e-03],\n",
       "         [-1.2512e-02, -6.9824e-02, -3.8605e-03,  ..., -1.2573e-02,\n",
       "          -4.9805e-02,  2.0508e-02],\n",
       "         ...,\n",
       "         [-5.2795e-03, -1.4709e-02,  4.1504e-02,  ...,  5.4321e-03,\n",
       "          -3.2349e-03,  4.4346e-05],\n",
       "         [ 4.4632e-04,  3.1250e-02, -6.1523e-02,  ..., -2.3804e-03,\n",
       "           1.1444e-03, -1.8768e-03],\n",
       "         [-4.1504e-03, -1.6724e-02,  3.0396e-02,  ...,  8.6060e-03,\n",
       "           8.0872e-04,  3.1433e-03]], dtype=torch.bfloat16),\n",
       " 'layers.0.attention.wk.weight': tensor([[-0.1040, -0.1543,  0.0737,  ...,  0.0312, -0.0231,  0.0442],\n",
       "         [-0.0447, -0.0293,  0.0396,  ...,  0.0067,  0.0242, -0.0035],\n",
       "         [-0.0564, -0.0869,  0.0188,  ...,  0.0193, -0.0073,  0.0293],\n",
       "         ...,\n",
       "         [ 0.0136,  0.0356, -0.0162,  ..., -0.0177,  0.0018,  0.0102],\n",
       "         [-0.0052, -0.0284,  0.0289,  ...,  0.0135,  0.0055, -0.0042],\n",
       "         [ 0.0039, -0.0100,  0.0118,  ..., -0.0153,  0.0016, -0.0206]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.0.attention.wv.weight': tensor([[ 0.0089, -0.0020, -0.0005,  ...,  0.0026,  0.0008,  0.0031],\n",
       "         [ 0.0002, -0.0040, -0.0001,  ..., -0.0029, -0.0040,  0.0025],\n",
       "         [ 0.0102,  0.0008,  0.0015,  ..., -0.0062,  0.0080,  0.0070],\n",
       "         ...,\n",
       "         [ 0.0079,  0.0008,  0.0029,  ..., -0.0014, -0.0064, -0.0064],\n",
       "         [ 0.0032,  0.0012,  0.0025,  ...,  0.0027, -0.0046, -0.0011],\n",
       "         [-0.0024, -0.0070,  0.0017,  ...,  0.0033,  0.0071, -0.0034]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.0.attention.wo.weight': tensor([[ 0.0022, -0.0011, -0.0090,  ..., -0.0012, -0.0131,  0.0018],\n",
       "         [-0.0025,  0.0151,  0.0088,  ..., -0.0031, -0.0067,  0.0046],\n",
       "         [-0.0018,  0.0005,  0.0039,  ..., -0.0077, -0.0010, -0.0005],\n",
       "         ...,\n",
       "         [ 0.0077, -0.0044, -0.0398,  ...,  0.0162, -0.0037,  0.0063],\n",
       "         [-0.0093,  0.0006, -0.0050,  ..., -0.0019, -0.0020, -0.0029],\n",
       "         [-0.0078,  0.0028, -0.0047,  ..., -0.0054,  0.0037,  0.0014]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.0.feed_forward.w1.weight': tensor([[-0.0121, -0.0051, -0.0036,  ...,  0.0149, -0.0134, -0.0030],\n",
       "         [-0.0067, -0.0267, -0.0032,  ...,  0.0131,  0.0046, -0.0016],\n",
       "         [ 0.0110, -0.0005,  0.0135,  ..., -0.0006,  0.0047,  0.0050],\n",
       "         ...,\n",
       "         [-0.0008, -0.0114, -0.0102,  ..., -0.0117,  0.0050, -0.0177],\n",
       "         [-0.0045, -0.0008, -0.0041,  ..., -0.0183, -0.0143,  0.0048],\n",
       "         [-0.0057,  0.0095,  0.0055,  ..., -0.0063,  0.0157, -0.0043]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.0.feed_forward.w3.weight': tensor([[-0.0131,  0.0062,  0.0075,  ...,  0.0038, -0.0084, -0.0044],\n",
       "         [-0.0107,  0.0142, -0.0013,  ..., -0.0096, -0.0052,  0.0085],\n",
       "         [-0.0032, -0.0064,  0.0042,  ..., -0.0070, -0.0027,  0.0064],\n",
       "         ...,\n",
       "         [-0.0006,  0.0154,  0.0066,  ..., -0.0069,  0.0065,  0.0121],\n",
       "         [-0.0178,  0.0133,  0.0030,  ...,  0.0034,  0.0071, -0.0061],\n",
       "         [-0.0036, -0.0135, -0.0029,  ..., -0.0027, -0.0072,  0.0076]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.0.feed_forward.w2.weight': tensor([[ 0.0087, -0.0151, -0.0090,  ...,  0.0079, -0.0039,  0.0134],\n",
       "         [ 0.0204, -0.0107, -0.0057,  ...,  0.0010,  0.0172,  0.0011],\n",
       "         [ 0.0082, -0.0075, -0.0023,  ..., -0.0018,  0.0025, -0.0165],\n",
       "         ...,\n",
       "         [ 0.0085, -0.0208,  0.0217,  ..., -0.0199,  0.0081, -0.0129],\n",
       "         [-0.0135, -0.0059, -0.0110,  ...,  0.0093,  0.0015, -0.0131],\n",
       "         [-0.0029,  0.0069,  0.0085,  ..., -0.0082, -0.0051, -0.0120]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.0.attention_norm.weight': tensor([0.0537, 0.2090, 0.4492,  ..., 0.0859, 0.0437, 0.0292],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.0.ffn_norm.weight': tensor([0.1514, 0.1396, 0.1543,  ..., 0.1533, 0.1523, 0.1494],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.1.attention.wq.weight': tensor([[-0.0312, -0.0181, -0.0189,  ..., -0.0281,  0.0028, -0.0088],\n",
       "         [ 0.0117, -0.0277,  0.0303,  ...,  0.0098, -0.0137,  0.0298],\n",
       "         [-0.0029,  0.0005, -0.0078,  ..., -0.0229,  0.0010,  0.0079],\n",
       "         ...,\n",
       "         [-0.0198, -0.0222, -0.0427,  ...,  0.0391,  0.0234,  0.0153],\n",
       "         [-0.0175,  0.0092, -0.0042,  ...,  0.0292,  0.0050,  0.0405],\n",
       "         [ 0.0223,  0.0276, -0.0021,  ..., -0.0130, -0.0068, -0.0150]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.1.attention.wk.weight': tensor([[-0.0115,  0.0159,  0.0119,  ..., -0.0811, -0.0145,  0.0059],\n",
       "         [-0.0569,  0.0198, -0.0250,  ..., -0.0179,  0.0198,  0.0136],\n",
       "         [ 0.0134,  0.0214, -0.0172,  ..., -0.0143, -0.0256,  0.0164],\n",
       "         ...,\n",
       "         [ 0.0649,  0.0278, -0.0309,  ...,  0.0649, -0.0226,  0.0212],\n",
       "         [-0.0256, -0.0239,  0.0376,  ...,  0.0221, -0.0193, -0.0078],\n",
       "         [ 0.0369, -0.0042,  0.0170,  ..., -0.0051,  0.0062,  0.0042]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.1.attention.wv.weight': tensor([[ 0.0108, -0.0014, -0.0096,  ...,  0.0032,  0.0008,  0.0083],\n",
       "         [ 0.0058,  0.0015,  0.0098,  ..., -0.0010,  0.0104,  0.0126],\n",
       "         [-0.0134,  0.0015,  0.0070,  ...,  0.0039,  0.0067, -0.0036],\n",
       "         ...,\n",
       "         [ 0.0053, -0.0034,  0.0022,  ...,  0.0004, -0.0034, -0.0243],\n",
       "         [ 0.0153, -0.0057, -0.0093,  ..., -0.0085,  0.0170, -0.0008],\n",
       "         [ 0.0079, -0.0093, -0.0061,  ..., -0.0026, -0.0033,  0.0025]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.1.attention.wo.weight': tensor([[ 0.0125,  0.0095,  0.0029,  ..., -0.0067, -0.0125,  0.0101],\n",
       "         [ 0.0046, -0.0110, -0.0021,  ...,  0.0051, -0.0188, -0.0020],\n",
       "         [-0.0049, -0.0088, -0.0124,  ...,  0.0072, -0.0089, -0.0204],\n",
       "         ...,\n",
       "         [ 0.0069, -0.0121,  0.0036,  ...,  0.0117,  0.0162, -0.0070],\n",
       "         [ 0.0132,  0.0076, -0.0112,  ..., -0.0036, -0.0053, -0.0087],\n",
       "         [ 0.0115, -0.0020,  0.0059,  ...,  0.0042,  0.0123, -0.0027]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.1.feed_forward.w1.weight': tensor([[-0.0243, -0.0076, -0.0015,  ..., -0.0034,  0.0098, -0.0137],\n",
       "         [-0.0160,  0.0120, -0.0245,  ...,  0.0105, -0.0114, -0.0148],\n",
       "         [ 0.0036, -0.0071, -0.0016,  ...,  0.0173, -0.0056, -0.0231],\n",
       "         ...,\n",
       "         [ 0.0142,  0.0219,  0.0221,  ...,  0.0009,  0.0074,  0.0175],\n",
       "         [-0.0112,  0.0210, -0.0201,  ...,  0.0150, -0.0041, -0.0106],\n",
       "         [-0.0106, -0.0187, -0.0248,  ...,  0.0056, -0.0277, -0.0342]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.1.feed_forward.w3.weight': tensor([[ 0.0022,  0.0056,  0.0173,  ..., -0.0032,  0.0068, -0.0012],\n",
       "         [-0.0192, -0.0035,  0.0089,  ...,  0.0093, -0.0012,  0.0123],\n",
       "         [ 0.0152, -0.0063, -0.0005,  ..., -0.0067, -0.0144, -0.0101],\n",
       "         ...,\n",
       "         [ 0.0128,  0.0030,  0.0002,  ...,  0.0005,  0.0028, -0.0150],\n",
       "         [ 0.0006,  0.0065, -0.0052,  ..., -0.0060,  0.0056, -0.0006],\n",
       "         [-0.0084, -0.0215, -0.0143,  ..., -0.0053, -0.0171, -0.0192]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.1.feed_forward.w2.weight': tensor([[-2.1820e-03, -1.2451e-02, -8.9111e-03,  ...,  5.9204e-03,\n",
       "          -7.1106e-03,  5.2185e-03],\n",
       "         [-5.9814e-03,  1.0254e-02, -5.5847e-03,  ..., -1.0132e-02,\n",
       "           1.0071e-02, -7.0190e-03],\n",
       "         [ 2.6703e-03,  1.4282e-02,  5.9509e-03,  ..., -9.3994e-03,\n",
       "          -7.9346e-03,  6.0730e-03],\n",
       "         ...,\n",
       "         [-8.8501e-03, -1.2878e-02, -1.0452e-03,  ..., -9.0332e-03,\n",
       "          -1.1475e-02,  1.2085e-02],\n",
       "         [-2.9297e-03,  7.4768e-03, -1.3580e-03,  ..., -2.6512e-04,\n",
       "           4.9591e-04, -1.2207e-02],\n",
       "         [-1.4832e-02,  1.5625e-02,  5.1270e-03,  ..., -5.9204e-03,\n",
       "          -1.4221e-02, -1.2890e-06]], dtype=torch.bfloat16),\n",
       " 'layers.1.attention_norm.weight': tensor([0.1006, 0.0845, 0.0771,  ..., 0.3730, 0.0820, 0.0850],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.1.ffn_norm.weight': tensor([0.1855, 0.1816, 0.1826,  ..., 0.1201, 0.1885, 0.1875],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.2.attention.wq.weight': tensor([[-0.0248,  0.0095,  0.0024,  ...,  0.0082,  0.0198, -0.0088],\n",
       "         [-0.0103,  0.0005, -0.0229,  ..., -0.0234, -0.0151,  0.0018],\n",
       "         [-0.0161, -0.0220, -0.0201,  ..., -0.0097,  0.0036, -0.0034],\n",
       "         ...,\n",
       "         [-0.0060, -0.0175, -0.0089,  ...,  0.0004, -0.0232,  0.0065],\n",
       "         [ 0.0110,  0.0002, -0.0140,  ..., -0.0012,  0.0056,  0.0008],\n",
       "         [ 0.0306,  0.0045,  0.0003,  ..., -0.0081,  0.0244, -0.0116]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.2.attention.wk.weight': tensor([[ 0.0069, -0.0113, -0.0092,  ...,  0.0393,  0.0294,  0.0197],\n",
       "         [-0.0403, -0.0121,  0.0481,  ..., -0.0175, -0.0183,  0.0029],\n",
       "         [-0.0045,  0.0289, -0.0103,  ..., -0.0222, -0.0147, -0.0047],\n",
       "         ...,\n",
       "         [ 0.0327,  0.0061, -0.0147,  ...,  0.0192, -0.0510,  0.0645],\n",
       "         [ 0.0425, -0.0771, -0.0205,  ..., -0.0075, -0.0354, -0.0374],\n",
       "         [-0.0063,  0.0106,  0.0344,  ...,  0.0439, -0.0059,  0.0250]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.2.attention.wv.weight': tensor([[-4.8399e-05, -9.0942e-03, -7.0801e-03,  ...,  1.9989e-03,\n",
       "           8.0566e-03, -9.8267e-03],\n",
       "         [-7.9346e-03,  1.4404e-02, -5.6458e-03,  ...,  1.5945e-03,\n",
       "           1.8387e-03, -1.8921e-03],\n",
       "         [ 5.6839e-04,  3.7384e-03, -5.1270e-03,  ..., -2.8076e-03,\n",
       "           3.5400e-03,  2.3193e-03],\n",
       "         ...,\n",
       "         [ 3.6812e-04,  6.4697e-03,  1.1215e-03,  ..., -3.9978e-03,\n",
       "          -1.5320e-02,  5.3406e-03],\n",
       "         [ 9.2773e-03,  2.0294e-03, -4.0588e-03,  ..., -3.5400e-03,\n",
       "          -2.3499e-03, -7.1411e-03],\n",
       "         [-6.0425e-03,  1.1902e-02, -1.5198e-02,  ..., -2.0142e-03,\n",
       "          -5.7678e-03,  3.1586e-03]], dtype=torch.bfloat16),\n",
       " 'layers.2.attention.wo.weight': tensor([[ 0.0096,  0.0014, -0.0120,  ..., -0.0110, -0.0102,  0.0061],\n",
       "         [ 0.0049,  0.0011,  0.0023,  ...,  0.0042,  0.0023, -0.0042],\n",
       "         [ 0.0121, -0.0083, -0.0087,  ...,  0.0042,  0.0198, -0.0051],\n",
       "         ...,\n",
       "         [ 0.0014,  0.0183,  0.0087,  ...,  0.0134, -0.0085,  0.0076],\n",
       "         [-0.0170,  0.0051, -0.0063,  ...,  0.0016, -0.0060, -0.0002],\n",
       "         [ 0.0036,  0.0095,  0.0055,  ..., -0.0044,  0.0056,  0.0049]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.2.feed_forward.w1.weight': tensor([[ 2.9144e-03,  1.3977e-02,  5.4932e-03,  ...,  2.9907e-03,\n",
       "           1.6479e-02,  2.0630e-02],\n",
       "         [-1.3809e-03,  1.3245e-02,  5.7373e-03,  ..., -2.2888e-03,\n",
       "          -3.0398e-05, -5.1575e-03],\n",
       "         [ 1.0559e-02,  1.0300e-03,  2.0874e-02,  ..., -8.0566e-03,\n",
       "           9.7046e-03, -3.2806e-04],\n",
       "         ...,\n",
       "         [-1.2146e-02, -9.2773e-03, -1.5335e-03,  ...,  3.3112e-03,\n",
       "          -1.5030e-03,  8.3008e-03],\n",
       "         [ 1.6968e-02, -3.9673e-03,  1.0452e-03,  ..., -1.2131e-03,\n",
       "          -1.7471e-03, -1.1169e-02],\n",
       "         [-1.4038e-02,  2.9945e-04, -6.4392e-03,  ...,  6.4087e-03,\n",
       "           2.0996e-02, -2.8534e-03]], dtype=torch.bfloat16),\n",
       " 'layers.2.feed_forward.w3.weight': tensor([[ 0.0320, -0.0056, -0.0050,  ..., -0.0038, -0.0061, -0.0003],\n",
       "         [ 0.0162, -0.0052, -0.0013,  ..., -0.0046, -0.0127,  0.0085],\n",
       "         [-0.0057, -0.0242,  0.0050,  ...,  0.0216, -0.0153, -0.0302],\n",
       "         ...,\n",
       "         [-0.0044, -0.0030,  0.0188,  ...,  0.0055,  0.0098, -0.0159],\n",
       "         [ 0.0112,  0.0132,  0.0058,  ...,  0.0201,  0.0134, -0.0008],\n",
       "         [ 0.0006,  0.0023, -0.0044,  ..., -0.0031,  0.0212, -0.0061]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.2.feed_forward.w2.weight': tensor([[ 0.0179,  0.0063,  0.0030,  ...,  0.0134, -0.0051, -0.0048],\n",
       "         [ 0.0188, -0.0093, -0.0040,  ..., -0.0091, -0.0043, -0.0107],\n",
       "         [-0.0011, -0.0026, -0.0204,  ..., -0.0179, -0.0024, -0.0276],\n",
       "         ...,\n",
       "         [ 0.0085,  0.0210,  0.0096,  ..., -0.0099,  0.0075,  0.0064],\n",
       "         [ 0.0072, -0.0060, -0.0203,  ..., -0.0136,  0.0015,  0.0165],\n",
       "         [ 0.0176, -0.0103,  0.0030,  ...,  0.0096, -0.0018,  0.0127]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.2.attention_norm.weight': tensor([0.3145, 0.3145, 0.2969,  ..., 0.7930, 0.2910, 0.2969],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.2.ffn_norm.weight': tensor([0.2266, 0.2256, 0.2236,  ..., 0.1367, 0.2344, 0.2334],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.3.attention.wq.weight': tensor([[ 0.0092,  0.0076,  0.0015,  ...,  0.0166,  0.0034,  0.0076],\n",
       "         [-0.0133, -0.0030,  0.0040,  ...,  0.0058,  0.0092,  0.0093],\n",
       "         [ 0.0125,  0.0153,  0.0129,  ..., -0.0004,  0.0128,  0.0056],\n",
       "         ...,\n",
       "         [-0.0457,  0.0171, -0.0064,  ..., -0.0184, -0.0020, -0.0018],\n",
       "         [-0.0347,  0.0087,  0.0151,  ...,  0.0068,  0.0075,  0.0276],\n",
       "         [-0.0135, -0.0003, -0.0234,  ..., -0.0082,  0.0088,  0.0267]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.3.attention.wk.weight': tensor([[-0.0126, -0.0179, -0.0105,  ...,  0.0225, -0.0168,  0.0101],\n",
       "         [ 0.0486,  0.0195,  0.0004,  ...,  0.0198,  0.0103,  0.0048],\n",
       "         [ 0.0102, -0.0356, -0.0006,  ...,  0.0121,  0.0047, -0.0154],\n",
       "         ...,\n",
       "         [ 0.0030, -0.0085,  0.0109,  ..., -0.0193, -0.0138, -0.0322],\n",
       "         [ 0.0098,  0.0684, -0.0002,  ..., -0.0027,  0.0086,  0.0400],\n",
       "         [ 0.0269, -0.0200, -0.0002,  ..., -0.0266, -0.0009,  0.0437]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.3.attention.wv.weight': tensor([[-0.0033,  0.0005,  0.0033,  ...,  0.0075, -0.0061, -0.0005],\n",
       "         [-0.0136, -0.0043,  0.0031,  ...,  0.0072, -0.0117,  0.0011],\n",
       "         [ 0.0166,  0.0126,  0.0012,  ...,  0.0076,  0.0013,  0.0105],\n",
       "         ...,\n",
       "         [ 0.0091,  0.0006,  0.0067,  ..., -0.0012,  0.0012,  0.0021],\n",
       "         [ 0.0103, -0.0025,  0.0018,  ..., -0.0063,  0.0052, -0.0006],\n",
       "         [-0.0031,  0.0001, -0.0077,  ...,  0.0025, -0.0118, -0.0160]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.3.attention.wo.weight': tensor([[-0.0066,  0.0030,  0.0096,  ...,  0.0017,  0.0098,  0.0096],\n",
       "         [ 0.0023,  0.0053, -0.0018,  ..., -0.0030, -0.0054,  0.0101],\n",
       "         [-0.0062, -0.0090, -0.0134,  ...,  0.0034,  0.0015,  0.0090],\n",
       "         ...,\n",
       "         [ 0.0024, -0.0093, -0.0173,  ..., -0.0121,  0.0098, -0.0040],\n",
       "         [-0.0055,  0.0107, -0.0060,  ..., -0.0052, -0.0008,  0.0109],\n",
       "         [ 0.0056,  0.0018, -0.0088,  ..., -0.0126, -0.0036,  0.0136]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.3.feed_forward.w1.weight': tensor([[ 0.0055, -0.0122,  0.0130,  ...,  0.0133, -0.0106, -0.0172],\n",
       "         [-0.0077, -0.0078, -0.0010,  ..., -0.0043, -0.0227, -0.0112],\n",
       "         [-0.0259, -0.0087, -0.0094,  ..., -0.0050,  0.0041,  0.0116],\n",
       "         ...,\n",
       "         [-0.0057,  0.0132, -0.0258,  ..., -0.0059,  0.0098,  0.0008],\n",
       "         [ 0.0034, -0.0139,  0.0182,  ..., -0.0065,  0.0079,  0.0041],\n",
       "         [-0.0012, -0.0104,  0.0077,  ..., -0.0003,  0.0129,  0.0175]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.3.feed_forward.w3.weight': tensor([[ 7.0801e-03, -1.1353e-02,  1.9684e-03,  ...,  9.3994e-03,\n",
       "           5.6152e-03, -3.0212e-03],\n",
       "         [ 8.1177e-03,  3.7537e-03,  1.1902e-02,  ..., -4.6082e-03,\n",
       "          -1.4832e-02,  1.4282e-02],\n",
       "         [ 1.4221e-02,  6.5613e-03,  6.2866e-03,  ...,  2.7161e-03,\n",
       "          -2.7344e-02,  1.4420e-03],\n",
       "         ...,\n",
       "         [-2.4261e-03, -1.0620e-02,  1.2283e-03,  ..., -2.7618e-03,\n",
       "           1.5320e-02, -1.3123e-02],\n",
       "         [ 6.8054e-03, -2.8534e-03, -1.0620e-02,  ..., -2.1729e-02,\n",
       "          -1.5747e-02, -3.8862e-05],\n",
       "         [-1.0254e-02,  7.2937e-03,  1.3428e-02,  ..., -1.9836e-03,\n",
       "          -8.3618e-03, -1.9684e-03]], dtype=torch.bfloat16),\n",
       " 'layers.3.feed_forward.w2.weight': tensor([[ 0.0051,  0.0005, -0.0082,  ...,  0.0173, -0.0031, -0.0018],\n",
       "         [ 0.0046, -0.0010, -0.0005,  ..., -0.0165,  0.0009,  0.0145],\n",
       "         [ 0.0122, -0.0007,  0.0060,  ..., -0.0210,  0.0053, -0.0098],\n",
       "         ...,\n",
       "         [-0.0055, -0.0004,  0.0038,  ..., -0.0146, -0.0140, -0.0029],\n",
       "         [ 0.0137, -0.0276,  0.0044,  ...,  0.0016,  0.0034, -0.0087],\n",
       "         [ 0.0022,  0.0134, -0.0059,  ...,  0.0234, -0.0064, -0.0038]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.3.attention_norm.weight': tensor([0.3809, 0.3789, 0.3613,  ..., 0.4473, 0.3691, 0.3555],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.3.ffn_norm.weight': tensor([0.2520, 0.2480, 0.2539,  ..., 0.1699, 0.2656, 0.2617],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.4.attention.wq.weight': tensor([[-0.0052, -0.0096, -0.0068,  ...,  0.0015,  0.0238, -0.0254],\n",
       "         [ 0.0099,  0.0090, -0.0116,  ...,  0.0065, -0.0053,  0.0032],\n",
       "         [-0.0267, -0.0044, -0.0047,  ..., -0.0126,  0.0103, -0.0064],\n",
       "         ...,\n",
       "         [ 0.0061,  0.0004,  0.0410,  ..., -0.0349,  0.0172,  0.0002],\n",
       "         [ 0.0091,  0.0115, -0.0012,  ..., -0.0172, -0.0014,  0.0164],\n",
       "         [-0.0167,  0.0063, -0.0039,  ...,  0.0231, -0.0236,  0.0125]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.4.attention.wk.weight': tensor([[ 0.0393,  0.0078, -0.0198,  ..., -0.0030, -0.0245,  0.0302],\n",
       "         [ 0.0396,  0.0188, -0.0359,  ...,  0.0294,  0.0219, -0.0294],\n",
       "         [ 0.0170,  0.0021, -0.0374,  ...,  0.0063, -0.0166, -0.0211],\n",
       "         ...,\n",
       "         [ 0.0383, -0.0110,  0.0107,  ...,  0.0581, -0.0198,  0.0111],\n",
       "         [-0.0090,  0.0210,  0.0221,  ...,  0.0128,  0.0199,  0.0518],\n",
       "         [ 0.0215,  0.0444, -0.0020,  ..., -0.0123,  0.0045, -0.0300]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.4.attention.wv.weight': tensor([[-0.0260, -0.0183,  0.0023,  ...,  0.0124,  0.0028,  0.0063],\n",
       "         [ 0.0040, -0.0117, -0.0106,  ...,  0.0007,  0.0143,  0.0018],\n",
       "         [ 0.0023,  0.0063, -0.0077,  ..., -0.0062, -0.0183, -0.0127],\n",
       "         ...,\n",
       "         [ 0.0126,  0.0177, -0.0154,  ...,  0.0106, -0.0031, -0.0039],\n",
       "         [-0.0154,  0.0065, -0.0027,  ..., -0.0018,  0.0102,  0.0132],\n",
       "         [ 0.0082, -0.0031,  0.0150,  ..., -0.0037,  0.0050, -0.0151]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.4.attention.wo.weight': tensor([[ 1.5015e-02,  4.5471e-03, -2.2583e-03,  ...,  7.0190e-03,\n",
       "          -8.3618e-03,  3.0518e-03],\n",
       "         [ 8.8501e-03,  3.6774e-03,  1.3245e-02,  ...,  5.7678e-03,\n",
       "           1.0620e-02, -3.1281e-03],\n",
       "         [ 1.6556e-03,  7.9346e-03,  9.0942e-03,  ..., -6.6757e-04,\n",
       "           1.0925e-02,  3.2806e-03],\n",
       "         ...,\n",
       "         [-6.4392e-03,  8.4229e-03,  2.9373e-04,  ...,  8.6670e-03,\n",
       "          -3.5095e-03, -4.4556e-03],\n",
       "         [-8.0566e-03, -1.2085e-02, -3.4332e-03,  ...,  7.4387e-04,\n",
       "          -2.9907e-03,  1.5991e-02],\n",
       "         [ 7.5073e-03, -2.3804e-03,  7.7820e-03,  ..., -3.7384e-03,\n",
       "           9.2773e-03, -3.1948e-05]], dtype=torch.bfloat16),\n",
       " 'layers.4.feed_forward.w1.weight': tensor([[-1.1292e-02,  7.0190e-03,  1.1047e-02,  ...,  8.3618e-03,\n",
       "           8.1787e-03, -2.5024e-02],\n",
       "         [ 5.0049e-03, -9.5215e-03, -3.3691e-02,  ...,  8.6670e-03,\n",
       "          -1.0498e-02,  2.2888e-03],\n",
       "         [ 1.8677e-02, -3.1586e-03, -1.3855e-02,  ..., -3.5706e-03,\n",
       "           8.7891e-03, -5.3024e-04],\n",
       "         ...,\n",
       "         [ 8.7891e-03,  2.2430e-03,  7.8125e-03,  ...,  8.7891e-03,\n",
       "           5.9204e-03,  6.3705e-04],\n",
       "         [ 2.2430e-03,  4.8256e-04,  1.8555e-02,  ...,  5.5237e-03,\n",
       "          -1.5076e-02, -5.0366e-06],\n",
       "         [ 4.0283e-02,  1.0742e-02, -5.5237e-03,  ...,  7.2021e-03,\n",
       "           3.5400e-03, -1.1841e-02]], dtype=torch.bfloat16),\n",
       " 'layers.4.feed_forward.w3.weight': tensor([[-0.0038, -0.0114,  0.0041,  ...,  0.0036,  0.0018,  0.0020],\n",
       "         [ 0.0009,  0.0120,  0.0232,  ...,  0.0029,  0.0132, -0.0019],\n",
       "         [ 0.0106, -0.0072, -0.0072,  ...,  0.0170,  0.0010,  0.0108],\n",
       "         ...,\n",
       "         [-0.0016,  0.0058,  0.0006,  ...,  0.0057, -0.0045, -0.0054],\n",
       "         [ 0.0017,  0.0148,  0.0112,  ...,  0.0045, -0.0132,  0.0015],\n",
       "         [-0.0058, -0.0005, -0.0066,  ...,  0.0103, -0.0192, -0.0076]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.4.feed_forward.w2.weight': tensor([[-0.0130,  0.0048, -0.0094,  ..., -0.0090, -0.0011, -0.0150],\n",
       "         [-0.0053, -0.0044,  0.0046,  ...,  0.0135,  0.0148,  0.0103],\n",
       "         [-0.0035,  0.0066, -0.0117,  ...,  0.0010,  0.0043, -0.0232],\n",
       "         ...,\n",
       "         [ 0.0046, -0.0039,  0.0156,  ...,  0.0096,  0.0102,  0.0092],\n",
       "         [ 0.0194,  0.0085,  0.0102,  ..., -0.0065, -0.0007,  0.0136],\n",
       "         [ 0.0096, -0.0113, -0.0145,  ...,  0.0018, -0.0078,  0.0087]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.4.attention_norm.weight': tensor([0.3477, 0.3457, 0.3105,  ..., 0.4512, 0.2969, 0.3047],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.4.ffn_norm.weight': tensor([0.2754, 0.2734, 0.2754,  ..., 0.2080, 0.2812, 0.2832],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.5.attention.wq.weight': tensor([[ 0.0068, -0.0071,  0.0026,  ..., -0.0045, -0.0080,  0.0068],\n",
       "         [ 0.0004, -0.0140, -0.0005,  ...,  0.0173,  0.0045,  0.0133],\n",
       "         [ 0.0173, -0.0001,  0.0129,  ..., -0.0146, -0.0200, -0.0140],\n",
       "         ...,\n",
       "         [ 0.0066,  0.0127,  0.0197,  ..., -0.0034, -0.0248,  0.0080],\n",
       "         [-0.0140,  0.0269,  0.0107,  ..., -0.0029, -0.0121,  0.0084],\n",
       "         [ 0.0087, -0.0048, -0.0215,  ..., -0.0032,  0.0151, -0.0040]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.5.attention.wk.weight': tensor([[-0.0021,  0.0483, -0.0437,  ...,  0.0026, -0.0344,  0.0060],\n",
       "         [-0.0244, -0.0264, -0.0212,  ...,  0.0076,  0.0087, -0.0269],\n",
       "         [ 0.0170,  0.0552,  0.0059,  ...,  0.0112,  0.0259,  0.0011],\n",
       "         ...,\n",
       "         [ 0.0226, -0.0013,  0.0204,  ..., -0.0031, -0.0077,  0.0295],\n",
       "         [-0.0344,  0.0352, -0.0145,  ..., -0.0383, -0.0106, -0.0179],\n",
       "         [ 0.0547, -0.0003, -0.0090,  ...,  0.0167, -0.0089, -0.0188]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.5.attention.wv.weight': tensor([[-0.0050, -0.0055, -0.0044,  ...,  0.0021,  0.0059,  0.0017],\n",
       "         [ 0.0136,  0.0131,  0.0067,  ..., -0.0063,  0.0019,  0.0021],\n",
       "         [-0.0012, -0.0119, -0.0033,  ..., -0.0043,  0.0156, -0.0026],\n",
       "         ...,\n",
       "         [-0.0035, -0.0013, -0.0045,  ...,  0.0004, -0.0029, -0.0023],\n",
       "         [-0.0004,  0.0101,  0.0014,  ...,  0.0040,  0.0029,  0.0098],\n",
       "         [-0.0034, -0.0021,  0.0069,  ...,  0.0045, -0.0044, -0.0039]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.5.attention.wo.weight': tensor([[-0.0181, -0.0109, -0.0190,  ..., -0.0085, -0.0073, -0.0016],\n",
       "         [-0.0134,  0.0133, -0.0166,  ..., -0.0003, -0.0052,  0.0013],\n",
       "         [ 0.0288,  0.0026, -0.0159,  ..., -0.0012, -0.0056, -0.0042],\n",
       "         ...,\n",
       "         [-0.0090, -0.0002,  0.0015,  ...,  0.0035,  0.0023,  0.0036],\n",
       "         [-0.0074, -0.0005, -0.0012,  ...,  0.0046, -0.0087, -0.0005],\n",
       "         [-0.0015,  0.0133,  0.0007,  ...,  0.0170,  0.0110,  0.0099]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.5.feed_forward.w1.weight': tensor([[-0.0378,  0.0085, -0.0132,  ...,  0.0227,  0.0199,  0.0064],\n",
       "         [ 0.0056,  0.0028, -0.0114,  ..., -0.0079, -0.0143, -0.0128],\n",
       "         [-0.0061,  0.0188,  0.0004,  ...,  0.0007, -0.0069, -0.0172],\n",
       "         ...,\n",
       "         [-0.0101, -0.0065,  0.0126,  ...,  0.0024, -0.0104,  0.0205],\n",
       "         [-0.0006, -0.0127, -0.0256,  ...,  0.0012, -0.0195,  0.0300],\n",
       "         [ 0.0121,  0.0028,  0.0297,  ...,  0.0106,  0.0047,  0.0066]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.5.feed_forward.w3.weight': tensor([[ 3.4904e-04,  7.9956e-03,  9.3384e-03,  ..., -1.3428e-02,\n",
       "          -7.4158e-03,  1.2390e-02],\n",
       "         [ 2.8968e-05,  1.8692e-03,  1.2451e-02,  ..., -1.0315e-02,\n",
       "          -1.3489e-02,  7.7209e-03],\n",
       "         [-2.5635e-03, -1.1475e-02,  2.1210e-03,  ...,  1.9043e-02,\n",
       "           1.6724e-02,  7.2632e-03],\n",
       "         ...,\n",
       "         [-7.0801e-03, -2.2583e-02, -5.6458e-03,  ...,  4.1504e-03,\n",
       "           2.2705e-02,  5.7983e-03],\n",
       "         [-1.1719e-02,  1.2695e-02, -2.9907e-03,  ...,  5.7220e-05,\n",
       "          -1.2573e-02, -4.1504e-03],\n",
       "         [ 4.3106e-04, -1.4832e-02,  4.3030e-03,  ..., -5.0964e-03,\n",
       "           1.4648e-02, -1.8311e-02]], dtype=torch.bfloat16),\n",
       " 'layers.5.feed_forward.w2.weight': tensor([[ 0.0058,  0.0010,  0.0029,  ..., -0.0366, -0.0147, -0.0060],\n",
       "         [-0.0037, -0.0030, -0.0019,  ..., -0.0042,  0.0064, -0.0114],\n",
       "         [ 0.0167, -0.0077, -0.0081,  ...,  0.0075, -0.0091, -0.0032],\n",
       "         ...,\n",
       "         [-0.0067, -0.0034,  0.0023,  ...,  0.0101, -0.0092, -0.0067],\n",
       "         [-0.0042,  0.0073, -0.0118,  ...,  0.0220, -0.0064,  0.0107],\n",
       "         [-0.0059,  0.0193,  0.0023,  ...,  0.0036,  0.0002, -0.0096]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.5.attention_norm.weight': tensor([0.4004, 0.3984, 0.3535,  ..., 0.5898, 0.3320, 0.3223],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.5.ffn_norm.weight': tensor([0.2910, 0.2910, 0.2969,  ..., 0.2266, 0.3027, 0.2988],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.6.attention.wq.weight': tensor([[-0.0098,  0.0156, -0.0015,  ..., -0.0002, -0.0009, -0.0031],\n",
       "         [ 0.0025,  0.0181, -0.0069,  ..., -0.0339, -0.0160, -0.0121],\n",
       "         [-0.0142, -0.0012,  0.0046,  ..., -0.0134, -0.0005,  0.0078],\n",
       "         ...,\n",
       "         [-0.0175, -0.0420,  0.0076,  ...,  0.0036, -0.0187, -0.0422],\n",
       "         [-0.0583, -0.0272, -0.0486,  ...,  0.0165,  0.0203,  0.0248],\n",
       "         [-0.0464,  0.0447,  0.0388,  ..., -0.0051,  0.0256,  0.0267]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.6.attention.wk.weight': tensor([[ 0.0023, -0.0344,  0.0354,  ...,  0.0142,  0.0095, -0.0137],\n",
       "         [-0.0008,  0.0400, -0.0317,  ..., -0.0286, -0.0559, -0.0114],\n",
       "         [ 0.0103,  0.0043, -0.0059,  ..., -0.0147, -0.0051,  0.0325],\n",
       "         ...,\n",
       "         [ 0.0211,  0.0413, -0.0076,  ..., -0.0281,  0.0014, -0.0092],\n",
       "         [ 0.0244, -0.0161, -0.0286,  ...,  0.0840,  0.0189,  0.0220],\n",
       "         [ 0.0253, -0.0195, -0.0483,  ...,  0.0102, -0.0300,  0.0112]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.6.attention.wv.weight': tensor([[ 0.0022, -0.0010, -0.0121,  ...,  0.0035,  0.0096,  0.0104],\n",
       "         [ 0.0032, -0.0123,  0.0019,  ..., -0.0050, -0.0067,  0.0109],\n",
       "         [-0.0002,  0.0143, -0.0102,  ..., -0.0059,  0.0062,  0.0016],\n",
       "         ...,\n",
       "         [ 0.0017, -0.0006,  0.0017,  ...,  0.0115, -0.0036,  0.0029],\n",
       "         [-0.0056,  0.0115, -0.0015,  ..., -0.0061, -0.0063, -0.0005],\n",
       "         [-0.0145, -0.0027,  0.0042,  ..., -0.0036, -0.0041,  0.0017]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.6.attention.wo.weight': tensor([[ 0.0129,  0.0192,  0.0019,  ...,  0.0020,  0.0090, -0.0054],\n",
       "         [ 0.0060, -0.0025,  0.0097,  ...,  0.0097,  0.0012,  0.0014],\n",
       "         [-0.0094, -0.0080,  0.0162,  ...,  0.0016,  0.0052, -0.0109],\n",
       "         ...,\n",
       "         [-0.0126, -0.0028,  0.0109,  ...,  0.0162,  0.0012,  0.0025],\n",
       "         [-0.0073,  0.0121,  0.0005,  ...,  0.0006, -0.0007,  0.0022],\n",
       "         [ 0.0166,  0.0061,  0.0003,  ...,  0.0028,  0.0043, -0.0048]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.6.feed_forward.w1.weight': tensor([[-0.0054, -0.0096, -0.0012,  ..., -0.0117,  0.0007,  0.0053],\n",
       "         [ 0.0151,  0.0118,  0.0244,  ..., -0.0101,  0.0222, -0.0304],\n",
       "         [ 0.0029, -0.0042,  0.0008,  ..., -0.0139,  0.0059,  0.0067],\n",
       "         ...,\n",
       "         [-0.0187, -0.0156,  0.0221,  ..., -0.0187, -0.0129, -0.0167],\n",
       "         [ 0.0024, -0.0195, -0.0137,  ...,  0.0069, -0.0002,  0.0064],\n",
       "         [-0.0043, -0.0114, -0.0102,  ...,  0.0082, -0.0090,  0.0036]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.6.feed_forward.w3.weight': tensor([[-8.9111e-03, -1.7578e-02,  8.8501e-03,  ..., -1.7624e-03,\n",
       "          -1.7944e-02, -2.8687e-03],\n",
       "         [ 1.3855e-02, -2.4109e-03, -7.6294e-03,  ..., -5.9814e-03,\n",
       "           1.9989e-03, -7.7820e-03],\n",
       "         [ 8.1787e-03, -3.4637e-03, -1.6602e-02,  ..., -1.2878e-02,\n",
       "           1.5106e-03,  2.4872e-03],\n",
       "         ...,\n",
       "         [-9.0408e-04, -5.6028e-05, -4.2725e-03,  ...,  9.6130e-04,\n",
       "           6.0425e-03, -3.3417e-03],\n",
       "         [-3.6316e-03,  2.5940e-03,  1.2207e-02,  ..., -1.2634e-02,\n",
       "           9.3994e-03,  1.1047e-02],\n",
       "         [-1.4709e-02, -2.6245e-02, -3.3188e-04,  ..., -7.7820e-03,\n",
       "           1.0620e-02, -7.9956e-03]], dtype=torch.bfloat16),\n",
       " 'layers.6.feed_forward.w2.weight': tensor([[ 8.1787e-03,  8.4305e-04, -1.3351e-03,  ...,  5.2795e-03,\n",
       "          -1.4160e-02,  4.8523e-03],\n",
       "         [-1.6357e-02, -6.4697e-03,  6.2256e-03,  ...,  1.3367e-02,\n",
       "           5.8594e-03, -4.7913e-03],\n",
       "         [-1.2817e-02, -4.6997e-03,  3.0708e-04,  ...,  6.8970e-03,\n",
       "           2.0027e-05, -1.1169e-02],\n",
       "         ...,\n",
       "         [-1.6602e-02, -1.8311e-03, -7.9346e-03,  ...,  9.1553e-03,\n",
       "          -1.1658e-02, -9.1553e-03],\n",
       "         [-1.9043e-02,  1.4099e-02,  7.6599e-03,  ...,  6.8665e-04,\n",
       "           8.3008e-03,  1.0132e-02],\n",
       "         [-1.1292e-03, -8.6670e-03,  9.9487e-03,  ...,  8.4229e-03,\n",
       "          -1.0498e-02,  4.3335e-03]], dtype=torch.bfloat16),\n",
       " 'layers.6.attention_norm.weight': tensor([0.4004, 0.4160, 0.3945,  ..., 0.4648, 0.3242, 0.3164],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.6.ffn_norm.weight': tensor([0.2988, 0.3008, 0.3105,  ..., 0.2500, 0.3145, 0.3027],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.7.attention.wq.weight': tensor([[ 0.0053,  0.0047, -0.0042,  ..., -0.0122, -0.0029, -0.0053],\n",
       "         [ 0.0047, -0.0153,  0.0175,  ...,  0.0065,  0.0135,  0.0093],\n",
       "         [-0.0084,  0.0070, -0.0171,  ..., -0.0156, -0.0049, -0.0047],\n",
       "         ...,\n",
       "         [-0.0047, -0.0151, -0.0178,  ..., -0.0074, -0.0076,  0.0153],\n",
       "         [-0.0121,  0.0176, -0.0192,  ..., -0.0067,  0.0205, -0.0081],\n",
       "         [ 0.0024, -0.0267,  0.0098,  ..., -0.0048,  0.0027,  0.0420]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.7.attention.wk.weight': tensor([[-0.0183,  0.0703, -0.0383,  ..., -0.0048, -0.0120,  0.0085],\n",
       "         [-0.0167,  0.0303,  0.0107,  ...,  0.0142,  0.0198,  0.0223],\n",
       "         [-0.0003,  0.0054,  0.0066,  ..., -0.0188, -0.0164, -0.0118],\n",
       "         ...,\n",
       "         [-0.0175, -0.0435, -0.0137,  ...,  0.0264, -0.0112,  0.0054],\n",
       "         [-0.0334, -0.0659,  0.0354,  ...,  0.0152,  0.0035, -0.0181],\n",
       "         [ 0.0023,  0.0830, -0.0129,  ..., -0.0145,  0.0007, -0.0254]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.7.attention.wv.weight': tensor([[ 1.4038e-02, -9.1553e-05, -3.6926e-03,  ..., -1.1230e-02,\n",
       "           9.5367e-04, -5.5847e-03],\n",
       "         [-1.1292e-02,  4.2114e-03,  1.0254e-02,  ..., -4.6997e-03,\n",
       "          -4.4250e-03,  9.9487e-03],\n",
       "         [ 2.1973e-03,  3.9062e-03, -9.7046e-03,  ..., -1.6689e-04,\n",
       "          -7.7515e-03,  7.9956e-03],\n",
       "         ...,\n",
       "         [ 8.2397e-03,  5.4016e-03,  9.8705e-05,  ..., -1.1673e-03,\n",
       "           2.4567e-03, -1.0071e-02],\n",
       "         [ 1.6251e-03, -7.2937e-03,  1.1475e-02,  ...,  4.9133e-03,\n",
       "          -3.4027e-03,  9.4604e-03],\n",
       "         [-1.0376e-02, -8.1787e-03, -1.2390e-02,  ...,  5.8594e-03,\n",
       "           1.0071e-02, -5.0964e-03]], dtype=torch.bfloat16),\n",
       " 'layers.7.attention.wo.weight': tensor([[-0.0017,  0.0184,  0.0101,  ..., -0.0053, -0.0055,  0.0132],\n",
       "         [ 0.0005, -0.0094, -0.0034,  ..., -0.0071,  0.0036, -0.0047],\n",
       "         [ 0.0063, -0.0025,  0.0096,  ..., -0.0023,  0.0035,  0.0222],\n",
       "         ...,\n",
       "         [ 0.0036,  0.0014, -0.0070,  ..., -0.0017,  0.0157,  0.0031],\n",
       "         [ 0.0096, -0.0011, -0.0021,  ...,  0.0116,  0.0046,  0.0074],\n",
       "         [-0.0117,  0.0103, -0.0035,  ..., -0.0051,  0.0029,  0.0022]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.7.feed_forward.w1.weight': tensor([[ 0.0259,  0.0004,  0.0115,  ..., -0.0153, -0.0053,  0.0100],\n",
       "         [-0.0069,  0.0118,  0.0209,  ..., -0.0143, -0.0025,  0.0168],\n",
       "         [ 0.0001,  0.0058,  0.0006,  ...,  0.0105,  0.0054, -0.0008],\n",
       "         ...,\n",
       "         [ 0.0092, -0.0297, -0.0074,  ..., -0.0239, -0.0092,  0.0022],\n",
       "         [ 0.0226, -0.0051, -0.0095,  ..., -0.0077, -0.0120, -0.0042],\n",
       "         [-0.0021,  0.0096, -0.0152,  ..., -0.0022,  0.0030,  0.0007]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.7.feed_forward.w3.weight': tensor([[ 0.0019,  0.0016,  0.0249,  ..., -0.0029,  0.0168, -0.0056],\n",
       "         [ 0.0117, -0.0145, -0.0117,  ...,  0.0022,  0.0024,  0.0082],\n",
       "         [ 0.0273, -0.0085, -0.0006,  ...,  0.0025,  0.0085, -0.0061],\n",
       "         ...,\n",
       "         [-0.0126, -0.0061, -0.0025,  ...,  0.0197,  0.0024,  0.0086],\n",
       "         [-0.0023, -0.0125,  0.0077,  ..., -0.0005,  0.0208,  0.0043],\n",
       "         [-0.0088, -0.0201, -0.0081,  ...,  0.0027, -0.0149,  0.0040]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.7.feed_forward.w2.weight': tensor([[-0.0065, -0.0227,  0.0066,  ..., -0.0081,  0.0084, -0.0053],\n",
       "         [-0.0082,  0.0029, -0.0065,  ...,  0.0146, -0.0052, -0.0154],\n",
       "         [-0.0055,  0.0076, -0.0035,  ..., -0.0037,  0.0096,  0.0167],\n",
       "         ...,\n",
       "         [ 0.0123, -0.0113, -0.0011,  ...,  0.0031,  0.0036, -0.0099],\n",
       "         [-0.0053, -0.0173, -0.0018,  ...,  0.0179, -0.0005, -0.0082],\n",
       "         [-0.0096,  0.0195, -0.0007,  ...,  0.0086,  0.0083, -0.0023]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.7.attention_norm.weight': tensor([0.4043, 0.4551, 0.4141,  ..., 0.4238, 0.3340, 0.3223],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.7.ffn_norm.weight': tensor([0.3027, 0.3047, 0.3125,  ..., 0.2578, 0.3125, 0.2949],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.8.attention.wq.weight': tensor([[-0.0074, -0.0166,  0.0028,  ...,  0.0008, -0.0066,  0.0116],\n",
       "         [-0.0148,  0.0121, -0.0031,  ..., -0.0127,  0.0104, -0.0008],\n",
       "         [ 0.0112, -0.0211,  0.0008,  ...,  0.0194, -0.0116, -0.0056],\n",
       "         ...,\n",
       "         [-0.0278,  0.0090,  0.0352,  ...,  0.0417, -0.0126,  0.0063],\n",
       "         [-0.0272, -0.0122, -0.0295,  ..., -0.0054,  0.0254,  0.0038],\n",
       "         [-0.0417, -0.0125,  0.0002,  ..., -0.0264,  0.0198,  0.0111]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.8.attention.wk.weight': tensor([[ 0.0065,  0.0070,  0.0168,  ..., -0.0063,  0.0029,  0.0031],\n",
       "         [ 0.0142, -0.0134,  0.0072,  ..., -0.0342,  0.0081,  0.0018],\n",
       "         [-0.0121,  0.0130, -0.0110,  ...,  0.0088, -0.0165,  0.0044],\n",
       "         ...,\n",
       "         [-0.0221,  0.0173,  0.0217,  ...,  0.0403,  0.0212,  0.0410],\n",
       "         [-0.0117, -0.0120, -0.0491,  ..., -0.0053,  0.0019, -0.0222],\n",
       "         [-0.0618, -0.0361, -0.0374,  ..., -0.0022, -0.0415, -0.0304]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.8.attention.wv.weight': tensor([[ 0.0030, -0.0049,  0.0040,  ..., -0.0068, -0.0048, -0.0042],\n",
       "         [-0.0039, -0.0079,  0.0066,  ...,  0.0047, -0.0055, -0.0039],\n",
       "         [ 0.0077,  0.0051, -0.0119,  ..., -0.0049, -0.0084,  0.0012],\n",
       "         ...,\n",
       "         [ 0.0039,  0.0003,  0.0048,  ...,  0.0057, -0.0054,  0.0043],\n",
       "         [ 0.0046,  0.0030, -0.0013,  ..., -0.0040, -0.0008, -0.0188],\n",
       "         [ 0.0109, -0.0137,  0.0032,  ..., -0.0017,  0.0015, -0.0070]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.8.attention.wo.weight': tensor([[ 0.0096,  0.0090, -0.0067,  ...,  0.0066,  0.0104,  0.0112],\n",
       "         [-0.0251,  0.0053, -0.0168,  ..., -0.0167,  0.0042, -0.0056],\n",
       "         [ 0.0027,  0.0112, -0.0061,  ...,  0.0015,  0.0044,  0.0060],\n",
       "         ...,\n",
       "         [ 0.0020,  0.0012,  0.0050,  ...,  0.0017, -0.0081,  0.0015],\n",
       "         [-0.0091,  0.0078,  0.0040,  ..., -0.0052, -0.0016, -0.0040],\n",
       "         [ 0.0049,  0.0060,  0.0051,  ..., -0.0025, -0.0097, -0.0023]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.8.feed_forward.w1.weight': tensor([[-0.0211, -0.0114,  0.0132,  ..., -0.0098, -0.0075,  0.0074],\n",
       "         [-0.0282, -0.0011, -0.0181,  ...,  0.0099, -0.0062,  0.0201],\n",
       "         [-0.0057, -0.0017,  0.0035,  ...,  0.0045,  0.0020, -0.0106],\n",
       "         ...,\n",
       "         [ 0.0095, -0.0046, -0.0186,  ...,  0.0210, -0.0193, -0.0017],\n",
       "         [-0.0272,  0.0055, -0.0115,  ..., -0.0391,  0.0170, -0.0132],\n",
       "         [ 0.0027, -0.0011,  0.0090,  ..., -0.0059, -0.0026,  0.0277]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.8.feed_forward.w3.weight': tensor([[-0.0160, -0.0077,  0.0024,  ...,  0.0118,  0.0162, -0.0135],\n",
       "         [-0.0015,  0.0068,  0.0145,  ..., -0.0170,  0.0068,  0.0165],\n",
       "         [ 0.0132, -0.0033,  0.0022,  ..., -0.0109,  0.0011, -0.0049],\n",
       "         ...,\n",
       "         [-0.0063,  0.0093,  0.0139,  ..., -0.0029, -0.0168, -0.0059],\n",
       "         [ 0.0055, -0.0037, -0.0079,  ...,  0.0114, -0.0011, -0.0018],\n",
       "         [ 0.0143,  0.0132,  0.0022,  ..., -0.0034,  0.0056, -0.0083]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.8.feed_forward.w2.weight': tensor([[-0.0001, -0.0043,  0.0062,  ..., -0.0014,  0.0094, -0.0051],\n",
       "         [ 0.0112,  0.0069, -0.0071,  ...,  0.0012,  0.0075, -0.0071],\n",
       "         [-0.0095,  0.0160,  0.0021,  ...,  0.0053, -0.0111, -0.0045],\n",
       "         ...,\n",
       "         [ 0.0014, -0.0178, -0.0236,  ...,  0.0047,  0.0184,  0.0083],\n",
       "         [ 0.0086,  0.0120, -0.0154,  ..., -0.0120,  0.0032,  0.0120],\n",
       "         [-0.0008,  0.0065,  0.0099,  ...,  0.0033, -0.0116, -0.0172]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.8.attention_norm.weight': tensor([0.4258, 0.4668, 0.4512,  ..., 0.4316, 0.3281, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.8.ffn_norm.weight': tensor([0.3047, 0.3047, 0.3125,  ..., 0.2676, 0.3125, 0.3047],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.9.attention.wq.weight': tensor([[ 5.2490e-03,  2.7466e-02,  1.0729e-04,  ...,  2.4567e-03,\n",
       "           2.0752e-02,  2.5513e-02],\n",
       "         [-3.7842e-03, -1.2268e-02,  1.0620e-02,  ...,  4.3678e-04,\n",
       "          -6.5918e-03, -1.4114e-03],\n",
       "         [ 5.0354e-03,  1.0315e-02,  1.1063e-03,  ..., -1.6846e-02,\n",
       "          -1.0376e-02,  1.4343e-02],\n",
       "         ...,\n",
       "         [-3.7842e-02,  7.7637e-02, -2.6123e-02,  ...,  4.3678e-04,\n",
       "           7.1526e-05,  4.7607e-03],\n",
       "         [-3.1738e-02,  2.1729e-02,  1.0193e-02,  ...,  2.0874e-02,\n",
       "          -3.2501e-03, -6.7749e-03],\n",
       "         [ 3.8452e-03, -1.1597e-02, -5.1270e-03,  ...,  3.9864e-04,\n",
       "          -1.5991e-02, -1.8311e-02]], dtype=torch.bfloat16),\n",
       " 'layers.9.attention.wk.weight': tensor([[-0.0063,  0.0183, -0.0148,  ...,  0.0187,  0.0090, -0.0194],\n",
       "         [-0.0014,  0.0122, -0.0003,  ...,  0.0366,  0.0021, -0.0047],\n",
       "         [ 0.0018, -0.0087,  0.0032,  ..., -0.0154,  0.0104,  0.0114],\n",
       "         ...,\n",
       "         [-0.0146,  0.0199, -0.0537,  ..., -0.0253, -0.0461, -0.0006],\n",
       "         [-0.0096,  0.0086, -0.0035,  ...,  0.0352, -0.0029, -0.0422],\n",
       "         [-0.0173,  0.0060, -0.0308,  ...,  0.0284,  0.0248,  0.0239]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.9.attention.wv.weight': tensor([[ 0.0020, -0.0043,  0.0069,  ..., -0.0140,  0.0003, -0.0052],\n",
       "         [ 0.0031, -0.0081,  0.0087,  ...,  0.0017,  0.0145,  0.0014],\n",
       "         [ 0.0019,  0.0116, -0.0020,  ..., -0.0011, -0.0055, -0.0013],\n",
       "         ...,\n",
       "         [ 0.0103,  0.0039, -0.0089,  ...,  0.0002,  0.0023, -0.0145],\n",
       "         [-0.0052, -0.0010, -0.0002,  ..., -0.0038,  0.0006,  0.0039],\n",
       "         [-0.0008,  0.0116,  0.0027,  ..., -0.0032,  0.0004,  0.0110]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.9.attention.wo.weight': tensor([[ 0.0029,  0.0156, -0.0114,  ...,  0.0123,  0.0037, -0.0040],\n",
       "         [-0.0055,  0.0154, -0.0038,  ...,  0.0083,  0.0059,  0.0135],\n",
       "         [-0.0254, -0.0264,  0.0038,  ..., -0.0040, -0.0042,  0.0046],\n",
       "         ...,\n",
       "         [ 0.0035,  0.0073,  0.0064,  ..., -0.0013,  0.0009, -0.0033],\n",
       "         [-0.0030, -0.0140,  0.0074,  ..., -0.0023, -0.0033,  0.0025],\n",
       "         [ 0.0012, -0.0051,  0.0048,  ..., -0.0070, -0.0040,  0.0107]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.9.feed_forward.w1.weight': tensor([[ 0.0008,  0.0184,  0.0170,  ...,  0.0003,  0.0042, -0.0008],\n",
       "         [ 0.0024,  0.0042, -0.0033,  ..., -0.0065,  0.0024, -0.0044],\n",
       "         [ 0.0156,  0.0030, -0.0069,  ...,  0.0300,  0.0226,  0.0027],\n",
       "         ...,\n",
       "         [-0.0035, -0.0089, -0.0167,  ..., -0.0077, -0.0027,  0.0295],\n",
       "         [ 0.0047,  0.0128,  0.0083,  ..., -0.0150,  0.0148,  0.0194],\n",
       "         [-0.0132,  0.0214,  0.0042,  ...,  0.0051,  0.0160, -0.0002]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.9.feed_forward.w3.weight': tensor([[-0.0031,  0.0265, -0.0068,  ...,  0.0194,  0.0017, -0.0107],\n",
       "         [ 0.0049, -0.0137,  0.0014,  ..., -0.0050, -0.0029,  0.0066],\n",
       "         [ 0.0009, -0.0096, -0.0115,  ...,  0.0029, -0.0030,  0.0046],\n",
       "         ...,\n",
       "         [ 0.0038, -0.0012, -0.0044,  ..., -0.0066,  0.0011,  0.0209],\n",
       "         [-0.0057,  0.0007,  0.0033,  ..., -0.0077, -0.0042, -0.0129],\n",
       "         [-0.0114, -0.0039,  0.0089,  ...,  0.0095, -0.0109,  0.0059]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.9.feed_forward.w2.weight': tensor([[ 1.8433e-02,  1.4954e-02,  1.9226e-03,  ...,  9.4604e-04,\n",
       "          -7.6294e-03,  2.4719e-03],\n",
       "         [ 6.3782e-03,  8.3008e-03,  1.7452e-04,  ...,  1.8692e-03,\n",
       "          -1.6846e-02, -1.4771e-02],\n",
       "         [ 2.5269e-02,  8.9722e-03,  5.3406e-03,  ..., -1.8539e-03,\n",
       "           8.0566e-03,  1.3542e-04],\n",
       "         ...,\n",
       "         [ 1.0437e-02,  5.4626e-03,  1.2085e-02,  ...,  8.7891e-03,\n",
       "          -7.8735e-03,  5.0049e-03],\n",
       "         [-1.1047e-02, -1.2512e-02,  6.1340e-03,  ...,  1.0132e-02,\n",
       "          -1.7334e-02, -1.9455e-04],\n",
       "         [-3.1710e-05,  1.1902e-02, -1.9531e-03,  ..., -2.1362e-02,\n",
       "          -1.1475e-02,  1.7944e-02]], dtype=torch.bfloat16),\n",
       " 'layers.9.attention_norm.weight': tensor([0.4180, 0.4863, 0.4668,  ..., 0.3984, 0.3340, 0.3223],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.9.ffn_norm.weight': tensor([0.3027, 0.3027, 0.3105,  ..., 0.2734, 0.3223, 0.3027],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.10.attention.wq.weight': tensor([[-1.9531e-02,  1.2207e-02, -1.5381e-02,  ..., -3.4523e-04,\n",
       "           5.8289e-03,  6.5231e-04],\n",
       "         [-2.0142e-02,  2.3193e-03, -4.2114e-03,  ...,  9.3460e-05,\n",
       "           2.9907e-02, -6.8665e-03],\n",
       "         [-4.0283e-02,  9.6436e-03, -2.8076e-02,  ...,  5.0964e-03,\n",
       "          -2.2217e-02, -3.8086e-02],\n",
       "         ...,\n",
       "         [ 1.7212e-02,  1.7822e-02, -9.4604e-03,  ...,  3.6621e-02,\n",
       "           1.2939e-02,  3.3936e-02],\n",
       "         [-5.0781e-02, -3.6316e-03,  2.7466e-02,  ..., -1.4114e-03,\n",
       "           3.2471e-02, -1.6724e-02],\n",
       "         [ 2.8320e-02, -4.0039e-02,  3.2227e-02,  ...,  3.2471e-02,\n",
       "          -2.6367e-02, -7.4768e-03]], dtype=torch.bfloat16),\n",
       " 'layers.10.attention.wk.weight': tensor([[-0.0013,  0.0077, -0.0126,  ..., -0.0145, -0.0054, -0.0018],\n",
       "         [ 0.0023,  0.0027,  0.0187,  ...,  0.0056, -0.0048,  0.0057],\n",
       "         [-0.0126,  0.0008, -0.0242,  ...,  0.0106,  0.0058, -0.0094],\n",
       "         ...,\n",
       "         [ 0.0178, -0.0204,  0.0408,  ..., -0.0243,  0.0356,  0.0425],\n",
       "         [-0.0036,  0.0125,  0.0791,  ..., -0.0070,  0.0593, -0.0096],\n",
       "         [ 0.0181, -0.0693,  0.0449,  ...,  0.0557, -0.0298,  0.0157]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.10.attention.wv.weight': tensor([[ 0.0095,  0.0036, -0.0026,  ..., -0.0135,  0.0013,  0.0021],\n",
       "         [-0.0008,  0.0076,  0.0072,  ..., -0.0025, -0.0019,  0.0096],\n",
       "         [-0.0012, -0.0082,  0.0008,  ..., -0.0115,  0.0033, -0.0037],\n",
       "         ...,\n",
       "         [-0.0156,  0.0025,  0.0008,  ..., -0.0026,  0.0077,  0.0015],\n",
       "         [-0.0065,  0.0056, -0.0062,  ..., -0.0024, -0.0011,  0.0073],\n",
       "         [-0.0018,  0.0074, -0.0024,  ...,  0.0038, -0.0057,  0.0013]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.10.attention.wo.weight': tensor([[-0.0100,  0.0029, -0.0039,  ...,  0.0040, -0.0011, -0.0092],\n",
       "         [ 0.0091, -0.0033, -0.0017,  ..., -0.0026, -0.0037,  0.0128],\n",
       "         [ 0.0118, -0.0013, -0.0064,  ...,  0.0125, -0.0053, -0.0024],\n",
       "         ...,\n",
       "         [ 0.0145,  0.0073,  0.0103,  ...,  0.0044,  0.0047,  0.0058],\n",
       "         [-0.0021,  0.0045, -0.0064,  ...,  0.0051,  0.0036,  0.0039],\n",
       "         [-0.0114, -0.0013, -0.0011,  ...,  0.0085,  0.0072, -0.0030]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.10.feed_forward.w1.weight': tensor([[-4.6082e-03, -6.4087e-03, -1.9531e-03,  ...,  9.6436e-03,\n",
       "           1.0132e-02,  6.6528e-03],\n",
       "         [ 4.8523e-03, -4.3869e-04, -3.2715e-02,  ...,  1.2329e-02,\n",
       "           8.4229e-03, -1.1963e-02],\n",
       "         [-1.1292e-02,  5.9814e-03,  3.7537e-03,  ...,  4.0283e-03,\n",
       "           3.0518e-02, -3.0518e-03],\n",
       "         ...,\n",
       "         [ 9.3994e-03, -2.7100e-02, -1.5381e-02,  ..., -5.6458e-03,\n",
       "          -5.7068e-03, -2.7008e-03],\n",
       "         [ 6.7444e-03,  1.8433e-02,  1.8463e-03,  ...,  2.5630e-05,\n",
       "           1.8433e-02, -1.6235e-02],\n",
       "         [-7.0190e-03,  1.4648e-02, -3.0975e-03,  ..., -7.0496e-03,\n",
       "           3.2715e-02,  2.0264e-02]], dtype=torch.bfloat16),\n",
       " 'layers.10.feed_forward.w3.weight': tensor([[ 5.9204e-03, -1.3855e-02, -4.1246e-05,  ..., -3.4943e-03,\n",
       "           2.4109e-03,  9.8267e-03],\n",
       "         [-3.8757e-03,  5.8594e-03,  1.2451e-02,  ...,  3.2806e-03,\n",
       "           4.3335e-03,  1.4648e-02],\n",
       "         [ 2.6611e-02,  1.8555e-02,  7.0496e-03,  ..., -7.3242e-03,\n",
       "          -2.8198e-02, -8.2779e-04],\n",
       "         ...,\n",
       "         [ 2.9449e-03,  1.2756e-02, -5.2185e-03,  ...,  2.0142e-02,\n",
       "          -6.9275e-03,  1.1230e-02],\n",
       "         [-8.3542e-04,  2.2461e-02, -5.6763e-03,  ..., -1.5442e-02,\n",
       "          -1.1963e-02,  4.3335e-03],\n",
       "         [ 1.3245e-02,  4.3640e-03,  7.5150e-04,  ..., -5.9204e-03,\n",
       "          -8.3008e-03, -3.7994e-03]], dtype=torch.bfloat16),\n",
       " 'layers.10.feed_forward.w2.weight': tensor([[ 0.0087, -0.0116,  0.0093,  ..., -0.0098, -0.0078,  0.0068],\n",
       "         [-0.0059,  0.0089,  0.0061,  ...,  0.0025,  0.0203, -0.0133],\n",
       "         [-0.0131,  0.0167,  0.0060,  ..., -0.0065, -0.0233, -0.0004],\n",
       "         ...,\n",
       "         [ 0.0049, -0.0145, -0.0013,  ..., -0.0186, -0.0131,  0.0057],\n",
       "         [ 0.0093, -0.0025,  0.0080,  ..., -0.0063, -0.0036, -0.0084],\n",
       "         [ 0.0131,  0.0210,  0.0031,  ..., -0.0077, -0.0133, -0.0090]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.10.attention_norm.weight': tensor([0.4277, 0.4922, 0.4746,  ..., 0.4043, 0.3379, 0.3398],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.10.ffn_norm.weight': tensor([0.3125, 0.3047, 0.3164,  ..., 0.2773, 0.3125, 0.3027],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.11.attention.wq.weight': tensor([[-0.0096,  0.0144,  0.0040,  ..., -0.0082, -0.0140, -0.0215],\n",
       "         [ 0.0226, -0.0115,  0.0139,  ...,  0.0200, -0.0195, -0.0054],\n",
       "         [ 0.0013, -0.0046,  0.0087,  ..., -0.0142, -0.0070,  0.0023],\n",
       "         ...,\n",
       "         [-0.0038,  0.0154, -0.0034,  ...,  0.0053, -0.0003, -0.0121],\n",
       "         [-0.0013, -0.0084,  0.0126,  ..., -0.0098,  0.0077, -0.0234],\n",
       "         [-0.0038, -0.0084,  0.0087,  ...,  0.0098, -0.0027, -0.0045]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.11.attention.wk.weight': tensor([[ 0.0048, -0.0019,  0.0153,  ...,  0.0049, -0.0003,  0.0090],\n",
       "         [-0.0034,  0.0094,  0.0044,  ...,  0.0105,  0.0039,  0.0121],\n",
       "         [ 0.0063, -0.0040, -0.0038,  ..., -0.0107, -0.0194, -0.0120],\n",
       "         ...,\n",
       "         [-0.0371,  0.0072, -0.0111,  ..., -0.0457, -0.0135,  0.0103],\n",
       "         [-0.0452, -0.0300, -0.0315,  ..., -0.0021,  0.0157,  0.0153],\n",
       "         [ 0.0859,  0.0266, -0.0151,  ..., -0.0811,  0.0114,  0.0231]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.11.attention.wv.weight': tensor([[-1.2451e-02, -5.7373e-03, -3.3569e-03,  ..., -9.1553e-03,\n",
       "          -9.9945e-04,  5.0354e-03],\n",
       "         [-3.2654e-03, -7.5989e-03, -7.6599e-03,  ..., -1.0803e-02,\n",
       "          -9.5367e-04, -2.2736e-03],\n",
       "         [ 6.0120e-03, -1.0376e-02, -6.9046e-04,  ..., -4.4556e-03,\n",
       "          -9.6798e-05, -8.7280e-03],\n",
       "         ...,\n",
       "         [-1.3733e-03, -5.4016e-03,  3.9978e-03,  ..., -1.5869e-03,\n",
       "          -1.3885e-03,  5.6152e-03],\n",
       "         [ 3.1891e-03, -1.7166e-03,  3.8910e-03,  ..., -7.1411e-03,\n",
       "          -3.6621e-03, -9.0332e-03],\n",
       "         [-1.6632e-03,  1.0071e-02, -1.4099e-02,  ...,  9.0332e-03,\n",
       "          -3.1738e-03, -1.1353e-02]], dtype=torch.bfloat16),\n",
       " 'layers.11.attention.wo.weight': tensor([[-1.3489e-02,  2.1820e-03,  3.0212e-03,  ...,  1.6357e-02,\n",
       "          -9.0942e-03, -6.9885e-03],\n",
       "         [ 4.6692e-03,  8.0566e-03,  1.4160e-02,  ..., -7.6294e-03,\n",
       "           1.0559e-02, -7.6771e-05],\n",
       "         [ 9.9945e-04, -1.3245e-02, -4.7913e-03,  ...,  7.5684e-03,\n",
       "          -1.2665e-03, -1.0681e-02],\n",
       "         ...,\n",
       "         [-3.4790e-03, -5.8899e-03, -7.7209e-03,  ...,  1.5381e-02,\n",
       "          -6.9427e-04,  7.2861e-04],\n",
       "         [-3.2654e-03,  7.5912e-04, -2.0630e-02,  ...,  4.6692e-03,\n",
       "          -6.6223e-03,  4.6349e-04],\n",
       "         [ 1.8066e-02,  4.4556e-03, -7.7820e-03,  ...,  3.6011e-03,\n",
       "          -1.0864e-02,  1.8921e-03]], dtype=torch.bfloat16),\n",
       " 'layers.11.feed_forward.w1.weight': tensor([[-0.0005,  0.0067,  0.0014,  ..., -0.0008,  0.0020, -0.0017],\n",
       "         [-0.0011,  0.0015, -0.0208,  ...,  0.0106,  0.0063,  0.0006],\n",
       "         [ 0.0052, -0.0059,  0.0134,  ..., -0.0115, -0.0123,  0.0066],\n",
       "         ...,\n",
       "         [-0.0049,  0.0026,  0.0030,  ..., -0.0034,  0.0144, -0.0103],\n",
       "         [-0.0055,  0.0132,  0.0140,  ..., -0.0170, -0.0109, -0.0036],\n",
       "         [-0.0134,  0.0013,  0.0168,  ..., -0.0008,  0.0062, -0.0104]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.11.feed_forward.w3.weight': tensor([[-0.0002,  0.0054,  0.0008,  ..., -0.0036,  0.0092, -0.0183],\n",
       "         [-0.0214,  0.0114, -0.0050,  ...,  0.0051, -0.0026,  0.0170],\n",
       "         [-0.0004,  0.0042,  0.0061,  ..., -0.0123, -0.0027, -0.0041],\n",
       "         ...,\n",
       "         [ 0.0030, -0.0129,  0.0035,  ..., -0.0047, -0.0081, -0.0064],\n",
       "         [ 0.0054, -0.0096,  0.0093,  ..., -0.0206,  0.0145,  0.0120],\n",
       "         [-0.0098,  0.0014,  0.0121,  ..., -0.0071, -0.0031,  0.0175]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.11.feed_forward.w2.weight': tensor([[ 0.0037, -0.0074, -0.0059,  ..., -0.0229, -0.0067,  0.0142],\n",
       "         [-0.0103,  0.0002, -0.0026,  ...,  0.0008, -0.0049,  0.0154],\n",
       "         [-0.0012,  0.0107,  0.0017,  ..., -0.0039,  0.0041, -0.0192],\n",
       "         ...,\n",
       "         [-0.0118,  0.0013,  0.0052,  ..., -0.0035,  0.0099,  0.0055],\n",
       "         [-0.0093, -0.0085, -0.0107,  ...,  0.0106,  0.0041, -0.0089],\n",
       "         [-0.0036,  0.0046, -0.0011,  ...,  0.0075,  0.0016, -0.0071]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.11.attention_norm.weight': tensor([0.4629, 0.5039, 0.4824,  ..., 0.3789, 0.3496, 0.3418],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.11.ffn_norm.weight': tensor([0.3164, 0.3047, 0.3164,  ..., 0.2871, 0.3086, 0.2949],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.12.attention.wq.weight': tensor([[ 0.0033,  0.0079,  0.0029,  ...,  0.0190, -0.0141,  0.0128],\n",
       "         [ 0.0013, -0.0067,  0.0139,  ...,  0.0082, -0.0060,  0.0226],\n",
       "         [ 0.0154, -0.0145,  0.0108,  ...,  0.0052, -0.0014, -0.0092],\n",
       "         ...,\n",
       "         [-0.0148,  0.0048, -0.0049,  ...,  0.0004,  0.0187, -0.0112],\n",
       "         [-0.0127, -0.0344, -0.0132,  ..., -0.0114,  0.0106,  0.0273],\n",
       "         [-0.0308, -0.0332, -0.0034,  ..., -0.0016, -0.0082, -0.0089]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.12.attention.wk.weight': tensor([[ 7.5340e-05,  1.4343e-02, -1.6235e-02,  ..., -6.7749e-03,\n",
       "          -7.4768e-03, -1.2634e-02],\n",
       "         [-7.1411e-03,  2.9541e-02,  5.0964e-03,  ...,  3.1006e-02,\n",
       "           1.2451e-02,  2.6855e-02],\n",
       "         [-2.8076e-02,  2.1729e-02, -7.0496e-03,  ...,  2.6855e-02,\n",
       "          -1.4404e-02, -3.8147e-04],\n",
       "         ...,\n",
       "         [ 5.2979e-02,  2.2583e-02, -2.6489e-02,  ..., -1.8555e-02,\n",
       "           3.4668e-02, -4.5410e-02],\n",
       "         [ 5.6396e-02, -4.1504e-02,  4.8096e-02,  ..., -3.6621e-03,\n",
       "          -6.1035e-03,  1.5869e-02],\n",
       "         [-3.8300e-03,  2.9297e-02,  2.8564e-02,  ...,  2.5757e-02,\n",
       "          -1.4343e-02, -3.5553e-03]], dtype=torch.bfloat16),\n",
       " 'layers.12.attention.wv.weight': tensor([[-1.7242e-03, -3.4485e-03,  1.2207e-02,  ...,  3.2654e-03,\n",
       "          -7.6904e-03, -8.5068e-04],\n",
       "         [ 1.3062e-02,  4.6692e-03, -8.9722e-03,  ..., -3.2654e-03,\n",
       "          -2.2583e-03,  9.8419e-04],\n",
       "         [ 1.7853e-03,  5.9204e-03, -2.0905e-03,  ...,  1.5259e-02,\n",
       "           6.2561e-04, -9.8705e-05],\n",
       "         ...,\n",
       "         [-1.1215e-03, -7.9727e-04, -1.2054e-03,  ...,  7.5989e-03,\n",
       "           7.6904e-03, -3.7384e-03],\n",
       "         [-4.6692e-03, -3.9673e-03,  2.0447e-03,  ..., -8.4229e-03,\n",
       "           3.0823e-03, -1.1673e-03],\n",
       "         [-5.7373e-03,  5.4932e-04, -6.2866e-03,  ..., -1.8311e-02,\n",
       "          -3.7994e-03, -2.7618e-03]], dtype=torch.bfloat16),\n",
       " 'layers.12.attention.wo.weight': tensor([[ 0.0105, -0.0175,  0.0053,  ...,  0.0028,  0.0262,  0.0072],\n",
       "         [ 0.0013, -0.0018,  0.0101,  ..., -0.0032,  0.0128,  0.0023],\n",
       "         [-0.0078,  0.0162, -0.0027,  ..., -0.0037, -0.0068,  0.0087],\n",
       "         ...,\n",
       "         [-0.0001,  0.0055,  0.0064,  ...,  0.0074, -0.0195, -0.0124],\n",
       "         [ 0.0082, -0.0234, -0.0013,  ..., -0.0211,  0.0006, -0.0082],\n",
       "         [-0.0079,  0.0065, -0.0087,  ...,  0.0075, -0.0081,  0.0249]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.12.feed_forward.w1.weight': tensor([[-0.0094, -0.0015, -0.0035,  ..., -0.0039, -0.0239, -0.0013],\n",
       "         [-0.0038, -0.0085, -0.0037,  ..., -0.0034,  0.0033,  0.0046],\n",
       "         [-0.0104, -0.0135,  0.0066,  ..., -0.0140, -0.0020, -0.0058],\n",
       "         ...,\n",
       "         [-0.0170,  0.0132, -0.0304,  ...,  0.0070, -0.0028,  0.0195],\n",
       "         [ 0.0176,  0.0029,  0.0273,  ...,  0.0037, -0.0034, -0.0099],\n",
       "         [-0.0020, -0.0143, -0.0287,  ...,  0.0035, -0.0038,  0.0221]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.12.feed_forward.w3.weight': tensor([[-0.0060, -0.0003,  0.0024,  ...,  0.0106, -0.0181,  0.0053],\n",
       "         [ 0.0082, -0.0104,  0.0011,  ...,  0.0172, -0.0043,  0.0107],\n",
       "         [ 0.0041, -0.0042, -0.0018,  ..., -0.0085, -0.0234, -0.0220],\n",
       "         ...,\n",
       "         [-0.0118, -0.0039, -0.0013,  ..., -0.0165,  0.0175, -0.0084],\n",
       "         [-0.0026, -0.0101,  0.0077,  ..., -0.0282, -0.0058,  0.0041],\n",
       "         [-0.0026, -0.0018,  0.0147,  ..., -0.0095, -0.0020,  0.0164]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.12.feed_forward.w2.weight': tensor([[ 0.0095, -0.0103,  0.0050,  ..., -0.0018, -0.0058, -0.0072],\n",
       "         [-0.0167,  0.0026, -0.0103,  ..., -0.0070,  0.0100,  0.0054],\n",
       "         [-0.0026, -0.0231, -0.0072,  ...,  0.0090,  0.0208,  0.0036],\n",
       "         ...,\n",
       "         [-0.0011,  0.0088,  0.0050,  ..., -0.0083, -0.0222, -0.0173],\n",
       "         [-0.0141, -0.0167, -0.0203,  ...,  0.0146, -0.0101,  0.0048],\n",
       "         [ 0.0037,  0.0109, -0.0303,  ..., -0.0214, -0.0020,  0.0079]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.12.attention_norm.weight': tensor([0.4355, 0.4570, 0.4355,  ..., 0.3516, 0.3262, 0.3301],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.12.ffn_norm.weight': tensor([0.3066, 0.3027, 0.3105,  ..., 0.2891, 0.3066, 0.2930],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.13.attention.wq.weight': tensor([[-0.0099, -0.0032,  0.0062,  ..., -0.0120,  0.0001, -0.0119],\n",
       "         [ 0.0088,  0.0012,  0.0071,  ..., -0.0085,  0.0068,  0.0100],\n",
       "         [ 0.0096,  0.0051, -0.0060,  ...,  0.0081, -0.0013,  0.0077],\n",
       "         ...,\n",
       "         [-0.0013, -0.0262, -0.0405,  ...,  0.0043,  0.0444,  0.0287],\n",
       "         [-0.0332, -0.0176, -0.0339,  ..., -0.0187,  0.0320,  0.0322],\n",
       "         [-0.0107,  0.0233,  0.0064,  ..., -0.0549, -0.0107,  0.0071]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.13.attention.wk.weight': tensor([[ 5.6458e-03, -4.0894e-03,  3.8624e-05,  ...,  1.8616e-03,\n",
       "          -8.9722e-03,  2.6245e-02],\n",
       "         [ 1.0193e-02, -6.5613e-03, -2.5513e-02,  ...,  2.8320e-02,\n",
       "           1.1780e-02,  1.8616e-03],\n",
       "         [ 5.6152e-03, -1.3977e-02, -2.2339e-02,  ...,  9.5215e-03,\n",
       "          -1.4832e-02, -1.2939e-02],\n",
       "         ...,\n",
       "         [-3.3447e-02,  2.4414e-03, -2.4048e-02,  ...,  1.6479e-02,\n",
       "          -7.1106e-03,  7.8735e-03],\n",
       "         [ 1.0620e-02, -7.3242e-03,  1.8311e-02,  ...,  1.4343e-03,\n",
       "           2.6245e-02,  3.2715e-02],\n",
       "         [-2.4414e-02, -1.9043e-02, -1.7578e-02,  ..., -3.4424e-02,\n",
       "          -6.8665e-03, -2.6001e-02]], dtype=torch.bfloat16),\n",
       " 'layers.13.attention.wv.weight': tensor([[-0.0035,  0.0103,  0.0077,  ..., -0.0187, -0.0109, -0.0026],\n",
       "         [-0.0009,  0.0166,  0.0099,  ...,  0.0081, -0.0046, -0.0075],\n",
       "         [-0.0018,  0.0022,  0.0058,  ..., -0.0017,  0.0006,  0.0033],\n",
       "         ...,\n",
       "         [ 0.0106,  0.0037,  0.0079,  ..., -0.0036, -0.0049, -0.0183],\n",
       "         [ 0.0028,  0.0081,  0.0029,  ..., -0.0045, -0.0035, -0.0093],\n",
       "         [-0.0103, -0.0065,  0.0086,  ...,  0.0108,  0.0134,  0.0133]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.13.attention.wo.weight': tensor([[ 0.0194,  0.0181,  0.0006,  ...,  0.0140,  0.0010,  0.0053],\n",
       "         [-0.0092, -0.0036,  0.0098,  ...,  0.0036,  0.0045, -0.0125],\n",
       "         [-0.0170,  0.0046, -0.0033,  ...,  0.0006,  0.0046, -0.0076],\n",
       "         ...,\n",
       "         [ 0.0002, -0.0118,  0.0014,  ..., -0.0070, -0.0057,  0.0085],\n",
       "         [ 0.0004, -0.0019, -0.0076,  ...,  0.0091,  0.0010,  0.0105],\n",
       "         [ 0.0032, -0.0097,  0.0007,  ..., -0.0050, -0.0077,  0.0014]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.13.feed_forward.w1.weight': tensor([[ 0.0055,  0.0243, -0.0154,  ..., -0.0046, -0.0088,  0.0251],\n",
       "         [-0.0034, -0.0046,  0.0010,  ...,  0.0237,  0.0027,  0.0070],\n",
       "         [ 0.0095,  0.0130,  0.0087,  ...,  0.0082, -0.0058,  0.0160],\n",
       "         ...,\n",
       "         [ 0.0042,  0.0044,  0.0167,  ..., -0.0105, -0.0058, -0.0127],\n",
       "         [ 0.0006, -0.0142,  0.0092,  ...,  0.0211,  0.0361, -0.0016],\n",
       "         [ 0.0060, -0.0045, -0.0007,  ..., -0.0001,  0.0056, -0.0190]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.13.feed_forward.w3.weight': tensor([[-0.0119, -0.0205, -0.0070,  ..., -0.0112,  0.0109, -0.0119],\n",
       "         [ 0.0005, -0.0003,  0.0118,  ..., -0.0168, -0.0085, -0.0059],\n",
       "         [-0.0058,  0.0123, -0.0031,  ...,  0.0092, -0.0004, -0.0032],\n",
       "         ...,\n",
       "         [-0.0004, -0.0122, -0.0200,  ...,  0.0126, -0.0071,  0.0007],\n",
       "         [-0.0017,  0.0004, -0.0027,  ..., -0.0123,  0.0050,  0.0068],\n",
       "         [-0.0225,  0.0014, -0.0083,  ...,  0.0060,  0.0073,  0.0051]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.13.feed_forward.w2.weight': tensor([[-4.3335e-03,  1.0010e-02, -1.1108e-02,  ...,  4.4107e-05,\n",
       "           1.6403e-03,  4.8218e-03],\n",
       "         [-1.1536e-02, -1.2939e-02, -4.1199e-03,  ..., -2.3956e-03,\n",
       "           2.7313e-03,  6.2866e-03],\n",
       "         [-8.1787e-03, -5.2490e-03, -9.8419e-04,  ...,  8.6060e-03,\n",
       "          -5.6763e-03, -3.1433e-03],\n",
       "         ...,\n",
       "         [-1.3550e-02, -2.6367e-02, -2.8534e-03,  ...,  4.6387e-03,\n",
       "          -3.9673e-03,  7.7438e-04],\n",
       "         [ 1.4465e-02,  7.0190e-03, -5.3406e-03,  ...,  9.7656e-03,\n",
       "           6.9885e-03,  1.4282e-02],\n",
       "         [-1.4648e-02, -2.5269e-02,  8.0566e-03,  ...,  2.8038e-04,\n",
       "          -9.7656e-03,  1.4160e-02]], dtype=torch.bfloat16),\n",
       " 'layers.13.attention_norm.weight': tensor([0.4648, 0.5352, 0.5000,  ..., 0.3906, 0.3789, 0.3770],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.13.ffn_norm.weight': tensor([0.3164, 0.3145, 0.3203,  ..., 0.3086, 0.3262, 0.3125],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.14.attention.wq.weight': tensor([[ 0.0054,  0.0109,  0.0177,  ..., -0.0011, -0.0032,  0.0026],\n",
       "         [-0.0034, -0.0085,  0.0052,  ...,  0.0162,  0.0003,  0.0171],\n",
       "         [ 0.0014, -0.0280,  0.0054,  ...,  0.0166, -0.0125,  0.0127],\n",
       "         ...,\n",
       "         [ 0.0091, -0.0102,  0.0261,  ...,  0.0322,  0.0062,  0.0276],\n",
       "         [-0.0121,  0.0566,  0.0093,  ...,  0.0036,  0.0231,  0.0074],\n",
       "         [ 0.0006, -0.0405, -0.0142,  ...,  0.0045,  0.0179, -0.0215]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.14.attention.wk.weight': tensor([[-0.0018, -0.0020, -0.0107,  ...,  0.0092, -0.0101,  0.0089],\n",
       "         [-0.0160, -0.0035, -0.0097,  ...,  0.0083,  0.0047, -0.0021],\n",
       "         [-0.0118,  0.0210,  0.0129,  ..., -0.0057,  0.0128, -0.0053],\n",
       "         ...,\n",
       "         [-0.0161,  0.0178,  0.0193,  ...,  0.0118, -0.0154,  0.0486],\n",
       "         [-0.0029,  0.0267,  0.0952,  ...,  0.0281, -0.0127,  0.0088],\n",
       "         [ 0.0030, -0.0527,  0.0273,  ...,  0.0071,  0.0171, -0.0066]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.14.attention.wv.weight': tensor([[-4.2419e-03,  2.6345e-05,  3.7384e-03,  ..., -7.4768e-03,\n",
       "          -3.8528e-04, -2.6703e-03],\n",
       "         [-1.3489e-02, -3.7231e-03, -5.8899e-03,  ...,  8.1787e-03,\n",
       "          -9.4604e-03,  1.7548e-03],\n",
       "         [-2.3041e-03, -7.7515e-03,  2.8534e-03,  ...,  3.4943e-03,\n",
       "           5.2185e-03,  5.3711e-03],\n",
       "         ...,\n",
       "         [ 5.3101e-03,  1.0376e-02,  3.9978e-03,  ...,  7.9727e-04,\n",
       "          -8.2397e-03,  2.9297e-02],\n",
       "         [-1.0559e-02,  2.3651e-03,  5.1270e-03,  ...,  4.7607e-03,\n",
       "          -1.2131e-03, -1.2207e-02],\n",
       "         [-5.3406e-03,  1.9836e-03,  7.9346e-03,  ..., -3.3264e-03,\n",
       "          -1.3916e-02,  9.2773e-03]], dtype=torch.bfloat16),\n",
       " 'layers.14.attention.wo.weight': tensor([[-1.3306e-02, -9.7656e-03, -2.0885e-04,  ...,  1.1047e-02,\n",
       "           3.7384e-03, -5.0049e-03],\n",
       "         [ 1.7700e-02,  7.9346e-03, -1.3245e-02,  ..., -7.2937e-03,\n",
       "          -8.7357e-04,  8.5235e-06],\n",
       "         [-1.1902e-03,  3.9673e-03,  8.1253e-04,  ...,  1.6602e-02,\n",
       "          -1.0437e-02,  4.9744e-03],\n",
       "         ...,\n",
       "         [ 3.4790e-03,  1.3275e-03, -6.0120e-03,  ...,  9.6436e-03,\n",
       "          -6.1035e-03, -8.8501e-03],\n",
       "         [-7.5378e-03, -5.0354e-03,  8.0566e-03,  ..., -6.1951e-03,\n",
       "           1.0925e-02,  1.2329e-02],\n",
       "         [ 1.9897e-02, -3.6621e-03,  2.4986e-04,  ..., -8.3542e-04,\n",
       "          -2.6550e-03, -1.7944e-02]], dtype=torch.bfloat16),\n",
       " 'layers.14.feed_forward.w1.weight': tensor([[-0.0056,  0.0272, -0.0054,  ...,  0.0003,  0.0134,  0.0074],\n",
       "         [ 0.0161,  0.0043, -0.0004,  ...,  0.0143,  0.0004, -0.0018],\n",
       "         [-0.0027, -0.0136,  0.0072,  ...,  0.0053,  0.0100, -0.0102],\n",
       "         ...,\n",
       "         [-0.0009,  0.0051,  0.0193,  ...,  0.0205,  0.0047, -0.0050],\n",
       "         [ 0.0193,  0.0063, -0.0028,  ..., -0.0035, -0.0015,  0.0102],\n",
       "         [-0.0019,  0.0045, -0.0111,  ...,  0.0151, -0.0007, -0.0134]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.14.feed_forward.w3.weight': tensor([[-0.0023, -0.0047, -0.0051,  ...,  0.0187, -0.0018,  0.0033],\n",
       "         [-0.0105, -0.0110,  0.0009,  ...,  0.0114, -0.0033,  0.0050],\n",
       "         [ 0.0188,  0.0068, -0.0062,  ..., -0.0082, -0.0151, -0.0060],\n",
       "         ...,\n",
       "         [ 0.0139, -0.0061,  0.0070,  ..., -0.0214, -0.0021,  0.0281],\n",
       "         [ 0.0240, -0.0026,  0.0005,  ..., -0.0022, -0.0011,  0.0073],\n",
       "         [ 0.0048,  0.0103, -0.0075,  ..., -0.0007,  0.0033, -0.0040]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.14.feed_forward.w2.weight': tensor([[ 0.0010, -0.0182,  0.0077,  ...,  0.0007,  0.0076, -0.0099],\n",
       "         [-0.0278, -0.0125,  0.0176,  ...,  0.0019,  0.0074,  0.0189],\n",
       "         [ 0.0107, -0.0091, -0.0017,  ..., -0.0067,  0.0239, -0.0074],\n",
       "         ...,\n",
       "         [ 0.0113,  0.0125, -0.0068,  ..., -0.0098, -0.0144,  0.0054],\n",
       "         [-0.0037,  0.0045, -0.0112,  ..., -0.0164, -0.0023,  0.0078],\n",
       "         [-0.0016,  0.0205, -0.0082,  ...,  0.0222, -0.0190, -0.0053]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.14.attention_norm.weight': tensor([0.4551, 0.4883, 0.4980,  ..., 0.3945, 0.3789, 0.3750],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.14.ffn_norm.weight': tensor([0.3359, 0.3262, 0.3359,  ..., 0.3223, 0.3457, 0.3359],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.15.attention.wq.weight': tensor([[-0.0021, -0.0201,  0.0214,  ...,  0.0270,  0.0153, -0.0187],\n",
       "         [-0.0050,  0.0043, -0.0026,  ..., -0.0461, -0.0167, -0.0111],\n",
       "         [ 0.0330, -0.0171,  0.0444,  ...,  0.0079,  0.0099, -0.0076],\n",
       "         ...,\n",
       "         [-0.0086,  0.0046,  0.0048,  ...,  0.0209, -0.0093, -0.0047],\n",
       "         [ 0.0132,  0.0045,  0.0170,  ..., -0.0081,  0.0147,  0.0016],\n",
       "         [-0.0063,  0.0071,  0.0143,  ...,  0.0051, -0.0012, -0.0127]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.15.attention.wk.weight': tensor([[ 0.0122, -0.0172,  0.0033,  ...,  0.0015,  0.0249, -0.0063],\n",
       "         [ 0.0087, -0.0127, -0.0002,  ...,  0.0078, -0.0146, -0.0317],\n",
       "         [ 0.0110,  0.0057, -0.0005,  ..., -0.0294, -0.0006, -0.0065],\n",
       "         ...,\n",
       "         [-0.0693, -0.0332,  0.0172,  ..., -0.0249,  0.0019, -0.0437],\n",
       "         [ 0.0030, -0.0254,  0.0106,  ...,  0.0226, -0.0084, -0.0082],\n",
       "         [ 0.0288,  0.0187,  0.0106,  ..., -0.0339, -0.0099,  0.0069]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.15.attention.wv.weight': tensor([[ 0.0065,  0.0032,  0.0072,  ..., -0.0029, -0.0060, -0.0064],\n",
       "         [-0.0063,  0.0039, -0.0083,  ...,  0.0043, -0.0085, -0.0113],\n",
       "         [-0.0082,  0.0116,  0.0140,  ...,  0.0035, -0.0112, -0.0020],\n",
       "         ...,\n",
       "         [-0.0069,  0.0038, -0.0029,  ...,  0.0037, -0.0058, -0.0001],\n",
       "         [-0.0084, -0.0074,  0.0032,  ..., -0.0009,  0.0050, -0.0157],\n",
       "         [-0.0028,  0.0027, -0.0082,  ..., -0.0070,  0.0038, -0.0051]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.15.attention.wo.weight': tensor([[ 0.0126,  0.0017,  0.0011,  ...,  0.0010, -0.0103, -0.0084],\n",
       "         [ 0.0027,  0.0085, -0.0016,  ...,  0.0030, -0.0005, -0.0173],\n",
       "         [ 0.0134,  0.0063,  0.0014,  ..., -0.0015,  0.0002,  0.0072],\n",
       "         ...,\n",
       "         [ 0.0130, -0.0028, -0.0041,  ..., -0.0002, -0.0124,  0.0014],\n",
       "         [-0.0018, -0.0151, -0.0045,  ...,  0.0046,  0.0109, -0.0023],\n",
       "         [-0.0051,  0.0015, -0.0019,  ..., -0.0066, -0.0067, -0.0003]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.15.feed_forward.w1.weight': tensor([[-2.6855e-03, -3.7994e-03, -1.1826e-03,  ..., -3.4485e-03,\n",
       "          -5.2490e-03, -1.3000e-02],\n",
       "         [ 1.4526e-02,  7.6294e-03,  5.2214e-05,  ...,  2.3041e-03,\n",
       "          -1.7944e-02, -1.7471e-03],\n",
       "         [-3.4943e-03,  2.7618e-03, -3.3875e-03,  ...,  1.3123e-02,\n",
       "           6.4392e-03, -1.2024e-02],\n",
       "         ...,\n",
       "         [ 1.8845e-03,  1.8997e-03, -5.3711e-03,  ...,  4.7684e-04,\n",
       "          -8.3008e-03,  1.5442e-02],\n",
       "         [ 1.8921e-02,  1.6602e-02, -4.1199e-03,  ..., -5.6458e-03,\n",
       "          -1.2436e-03, -1.0193e-02],\n",
       "         [ 1.9165e-02,  1.4709e-02,  5.6763e-03,  ..., -3.9978e-03,\n",
       "          -1.1841e-02, -3.9368e-03]], dtype=torch.bfloat16),\n",
       " 'layers.15.feed_forward.w3.weight': tensor([[ 0.0107,  0.0003, -0.0156,  ..., -0.0060,  0.0084, -0.0005],\n",
       "         [-0.0051,  0.0129, -0.0004,  ..., -0.0033, -0.0138,  0.0178],\n",
       "         [-0.0003,  0.0183, -0.0137,  ..., -0.0037, -0.0123, -0.0052],\n",
       "         ...,\n",
       "         [-0.0024, -0.0022, -0.0010,  ...,  0.0021,  0.0053, -0.0032],\n",
       "         [ 0.0069, -0.0040,  0.0004,  ..., -0.0036, -0.0212,  0.0339],\n",
       "         [-0.0026, -0.0009, -0.0182,  ..., -0.0080, -0.0033,  0.0037]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.15.feed_forward.w2.weight': tensor([[ 0.0015,  0.0070,  0.0006,  ...,  0.0197,  0.0156, -0.0040],\n",
       "         [ 0.0039, -0.0108, -0.0061,  ...,  0.0253,  0.0073,  0.0036],\n",
       "         [-0.0157, -0.0110, -0.0102,  ...,  0.0055,  0.0096, -0.0057],\n",
       "         ...,\n",
       "         [ 0.0167, -0.0143,  0.0020,  ...,  0.0050, -0.0062,  0.0039],\n",
       "         [ 0.0143, -0.0064, -0.0046,  ..., -0.0050,  0.0076, -0.0054],\n",
       "         [-0.0107,  0.0078,  0.0057,  ...,  0.0164,  0.0115, -0.0074]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.15.attention_norm.weight': tensor([0.4551, 0.4590, 0.4609,  ..., 0.4258, 0.3965, 0.4082],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.15.ffn_norm.weight': tensor([0.3457, 0.3496, 0.3555,  ..., 0.3398, 0.3633, 0.3516],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.16.attention.wq.weight': tensor([[-0.0024,  0.0074,  0.0005,  ..., -0.0055,  0.0060,  0.0069],\n",
       "         [ 0.0037,  0.0025, -0.0023,  ...,  0.0107, -0.0013, -0.0010],\n",
       "         [ 0.0021,  0.0096, -0.0036,  ...,  0.0017,  0.0053,  0.0085],\n",
       "         ...,\n",
       "         [ 0.0054,  0.0084, -0.0019,  ..., -0.0171, -0.0194, -0.0087],\n",
       "         [-0.0063, -0.0206,  0.0002,  ...,  0.0031,  0.0295, -0.0162],\n",
       "         [ 0.0273, -0.0016,  0.0264,  ..., -0.0121,  0.0067, -0.0063]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.16.attention.wk.weight': tensor([[ 0.0031, -0.0026,  0.0035,  ...,  0.0140, -0.0101, -0.0186],\n",
       "         [ 0.0147, -0.0042, -0.0034,  ..., -0.0084, -0.0088,  0.0026],\n",
       "         [-0.0019,  0.0075,  0.0179,  ...,  0.0064, -0.0035, -0.0041],\n",
       "         ...,\n",
       "         [-0.0223, -0.0386,  0.0041,  ...,  0.0103,  0.0111, -0.0222],\n",
       "         [ 0.0076,  0.0312, -0.0304,  ...,  0.0108, -0.0175, -0.0038],\n",
       "         [ 0.0208,  0.0197,  0.0278,  ..., -0.0005, -0.0349, -0.0023]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.16.attention.wv.weight': tensor([[ 0.0114,  0.0065, -0.0087,  ..., -0.0046,  0.0003,  0.0011],\n",
       "         [ 0.0128,  0.0006, -0.0069,  ...,  0.0033,  0.0079,  0.0035],\n",
       "         [ 0.0005, -0.0004, -0.0011,  ...,  0.0083, -0.0019, -0.0150],\n",
       "         ...,\n",
       "         [ 0.0028, -0.0211, -0.0109,  ..., -0.0002,  0.0043, -0.0045],\n",
       "         [-0.0044,  0.0001, -0.0018,  ...,  0.0028,  0.0080, -0.0096],\n",
       "         [ 0.0036, -0.0030, -0.0001,  ..., -0.0008, -0.0083,  0.0066]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.16.attention.wo.weight': tensor([[-0.0232,  0.0126,  0.0048,  ...,  0.0089,  0.0049,  0.0008],\n",
       "         [-0.0413, -0.0055, -0.0079,  ..., -0.0027,  0.0094, -0.0056],\n",
       "         [ 0.0215,  0.0028, -0.0068,  ..., -0.0006,  0.0071, -0.0029],\n",
       "         ...,\n",
       "         [ 0.0041, -0.0172, -0.0209,  ..., -0.0009,  0.0076,  0.0057],\n",
       "         [-0.0128, -0.0146, -0.0078,  ..., -0.0077,  0.0048,  0.0069],\n",
       "         [-0.0031, -0.0019, -0.0168,  ..., -0.0042, -0.0043, -0.0004]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.16.feed_forward.w1.weight': tensor([[ 0.0179,  0.0004, -0.0067,  ..., -0.0161,  0.0344, -0.0085],\n",
       "         [-0.0270, -0.0025, -0.0143,  ...,  0.0140,  0.0192, -0.0322],\n",
       "         [-0.0070,  0.0361,  0.0066,  ...,  0.0038,  0.0053, -0.0118],\n",
       "         ...,\n",
       "         [ 0.0179, -0.0036,  0.0058,  ...,  0.0007,  0.0177, -0.0002],\n",
       "         [ 0.0126,  0.0030,  0.0205,  ...,  0.0038,  0.0092, -0.0054],\n",
       "         [ 0.0104,  0.0019,  0.0017,  ...,  0.0255,  0.0221, -0.0055]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.16.feed_forward.w3.weight': tensor([[-0.0181, -0.0101,  0.0013,  ...,  0.0043,  0.0010, -0.0106],\n",
       "         [ 0.0045, -0.0094,  0.0030,  ...,  0.0060,  0.0072,  0.0033],\n",
       "         [ 0.0027, -0.0030,  0.0192,  ..., -0.0056, -0.0147, -0.0040],\n",
       "         ...,\n",
       "         [ 0.0145, -0.0031,  0.0075,  ..., -0.0064, -0.0073,  0.0090],\n",
       "         [ 0.0109, -0.0068,  0.0142,  ..., -0.0010, -0.0092,  0.0048],\n",
       "         [ 0.0240,  0.0204, -0.0108,  ...,  0.0195, -0.0124, -0.0104]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.16.feed_forward.w2.weight': tensor([[-1.3916e-02,  8.4229e-03,  4.0894e-03,  ..., -2.6550e-03,\n",
       "          -3.8605e-03,  3.1128e-02],\n",
       "         [ 1.1749e-03, -3.5553e-03, -1.2131e-03,  ..., -1.2573e-02,\n",
       "          -2.3499e-03,  1.3489e-02],\n",
       "         [-1.5106e-03, -3.6478e-05,  2.2461e-02,  ...,  1.8921e-02,\n",
       "           1.6785e-03,  9.0027e-04],\n",
       "         ...,\n",
       "         [ 3.0670e-03, -9.6436e-03,  1.9989e-03,  ..., -1.4099e-02,\n",
       "          -1.6113e-02,  1.2146e-02],\n",
       "         [ 4.8828e-03, -1.2817e-03, -8.5449e-03,  ..., -1.9455e-04,\n",
       "           1.7395e-03,  2.8381e-03],\n",
       "         [-1.7090e-03, -1.3199e-03,  1.0071e-02,  ..., -4.2114e-03,\n",
       "          -6.4392e-03,  6.6223e-03]], dtype=torch.bfloat16),\n",
       " 'layers.16.attention_norm.weight': tensor([0.4355, 0.4375, 0.4355,  ..., 0.4355, 0.4219, 0.4004],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.16.ffn_norm.weight': tensor([0.3652, 0.3711, 0.3770,  ..., 0.3633, 0.3848, 0.3750],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.17.attention.wq.weight': tensor([[ 2.2339e-02,  1.2283e-03,  1.7944e-02,  ..., -3.4027e-03,\n",
       "          -7.3242e-03, -1.3123e-03],\n",
       "         [ 6.7749e-03, -3.8910e-03,  1.2756e-02,  ...,  1.1981e-05,\n",
       "          -3.7689e-03, -2.3651e-03],\n",
       "         [-6.1035e-03,  1.0742e-02,  6.7520e-04,  ..., -1.6235e-02,\n",
       "          -1.8005e-03, -8.9722e-03],\n",
       "         ...,\n",
       "         [ 1.1658e-02,  3.1128e-03, -1.8677e-02,  ..., -3.2715e-02,\n",
       "          -1.7456e-02, -1.6113e-02],\n",
       "         [-2.5513e-02, -7.7515e-03, -2.0508e-02,  ...,  3.7842e-02,\n",
       "           1.0498e-02,  9.5215e-03],\n",
       "         [-3.4912e-02,  1.3550e-02, -6.4087e-03,  ..., -2.9419e-02,\n",
       "          -5.4626e-03,  4.9133e-03]], dtype=torch.bfloat16),\n",
       " 'layers.17.attention.wk.weight': tensor([[-5.9204e-03,  2.3071e-02,  5.4626e-03,  ...,  1.9775e-02,\n",
       "          -1.0254e-02, -2.0020e-02],\n",
       "         [-2.1484e-02,  1.9409e-02,  2.8931e-02,  ..., -2.0874e-02,\n",
       "          -7.3624e-04, -5.4688e-02],\n",
       "         [ 8.7280e-03,  6.7139e-03,  1.4954e-02,  ..., -1.4709e-02,\n",
       "          -3.1494e-02, -1.6479e-02],\n",
       "         ...,\n",
       "         [ 2.2217e-02, -3.3203e-02, -1.0376e-02,  ..., -2.7344e-02,\n",
       "          -1.2817e-02, -2.8687e-02],\n",
       "         [ 4.4434e-02,  2.2217e-02, -1.3672e-02,  ...,  2.1362e-02,\n",
       "          -1.2040e-05,  3.3447e-02],\n",
       "         [ 1.4267e-03,  2.2949e-02, -3.5889e-02,  ..., -1.5640e-03,\n",
       "           5.8350e-02, -4.1016e-02]], dtype=torch.bfloat16),\n",
       " 'layers.17.attention.wv.weight': tensor([[-3.7079e-03,  1.7090e-02,  3.0975e-03,  ...,  8.5449e-03,\n",
       "          -9.0027e-04,  1.0910e-03],\n",
       "         [ 5.0659e-03, -8.4229e-03, -7.8583e-04,  ...,  2.4319e-05,\n",
       "          -4.4823e-05, -9.9487e-03],\n",
       "         [ 7.7515e-03, -1.3611e-02, -2.1973e-03,  ..., -2.8809e-02,\n",
       "           1.7090e-02, -7.5684e-03],\n",
       "         ...,\n",
       "         [-3.3722e-03, -9.5825e-03,  3.4790e-03,  ...,  1.7090e-03,\n",
       "           5.3711e-03,  8.1177e-03],\n",
       "         [ 1.7456e-02,  5.9814e-03, -9.9487e-03,  ..., -3.0212e-03,\n",
       "           8.1787e-03,  2.0752e-03],\n",
       "         [-1.5137e-02, -2.6703e-03, -8.1787e-03,  ..., -4.0588e-03,\n",
       "           2.7084e-04, -7.4768e-03]], dtype=torch.bfloat16),\n",
       " 'layers.17.attention.wo.weight': tensor([[-0.0087,  0.0126,  0.0284,  ..., -0.0034,  0.0193, -0.0126],\n",
       "         [ 0.0146,  0.0053, -0.0095,  ..., -0.0003,  0.0043, -0.0143],\n",
       "         [ 0.0087,  0.0063,  0.0071,  ..., -0.0021,  0.0025,  0.0035],\n",
       "         ...,\n",
       "         [-0.0103,  0.0069, -0.0112,  ..., -0.0033,  0.0034,  0.0081],\n",
       "         [ 0.0056,  0.0015,  0.0081,  ..., -0.0104, -0.0023,  0.0131],\n",
       "         [-0.0115,  0.0018, -0.0011,  ..., -0.0014, -0.0064,  0.0178]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.17.feed_forward.w1.weight': tensor([[ 0.0237,  0.0193, -0.0002,  ..., -0.0104, -0.0067,  0.0100],\n",
       "         [-0.0503,  0.0071,  0.0153,  ..., -0.0396,  0.0197,  0.0038],\n",
       "         [ 0.0024, -0.0289, -0.0030,  ...,  0.0077, -0.0030, -0.0092],\n",
       "         ...,\n",
       "         [-0.0188, -0.0156,  0.0062,  ...,  0.0103,  0.0184, -0.0030],\n",
       "         [-0.0038, -0.0186, -0.0053,  ..., -0.0228, -0.0092, -0.0048],\n",
       "         [-0.0134,  0.0051,  0.0339,  ...,  0.0008,  0.0334, -0.0189]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.17.feed_forward.w3.weight': tensor([[ 7.2021e-03,  1.2878e-02, -7.8583e-04,  ..., -5.9509e-03,\n",
       "          -6.0272e-04,  1.1292e-02],\n",
       "         [ 5.6458e-03,  2.9449e-03, -1.2268e-02,  ...,  7.8125e-03,\n",
       "           4.6997e-03, -8.0566e-03],\n",
       "         [-1.2207e-02,  2.4292e-02,  2.6123e-02,  ..., -5.3406e-03,\n",
       "          -2.0905e-03, -4.8828e-03],\n",
       "         ...,\n",
       "         [-1.1292e-02, -1.4404e-02, -8.8811e-06,  ..., -1.8921e-03,\n",
       "           2.3682e-02,  4.0588e-03],\n",
       "         [-1.1230e-02,  1.8188e-02,  3.0518e-03,  ..., -5.5542e-03,\n",
       "           4.8523e-03, -3.3417e-03],\n",
       "         [ 1.0376e-02,  2.7466e-03, -9.5825e-03,  ...,  1.1353e-02,\n",
       "          -8.1787e-03, -4.2725e-03]], dtype=torch.bfloat16),\n",
       " 'layers.17.feed_forward.w2.weight': tensor([[-0.0137,  0.0062,  0.0059,  ..., -0.0029,  0.0045,  0.0160],\n",
       "         [-0.0160, -0.0021, -0.0051,  ..., -0.0106, -0.0070, -0.0040],\n",
       "         [-0.0117, -0.0125,  0.0139,  ..., -0.0095, -0.0181, -0.0170],\n",
       "         ...,\n",
       "         [ 0.0117, -0.0031, -0.0012,  ..., -0.0010, -0.0113,  0.0014],\n",
       "         [-0.0017, -0.0125, -0.0018,  ...,  0.0049, -0.0011, -0.0284],\n",
       "         [-0.0195,  0.0072, -0.0187,  ..., -0.0035, -0.0001, -0.0023]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.17.attention_norm.weight': tensor([0.4648, 0.4648, 0.4355,  ..., 0.4238, 0.4141, 0.4180],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.17.ffn_norm.weight': tensor([0.3828, 0.3848, 0.3906,  ..., 0.3730, 0.4062, 0.3867],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.18.attention.wq.weight': tensor([[ 0.0205, -0.0024,  0.0062,  ..., -0.0048, -0.0030,  0.0199],\n",
       "         [ 0.0065, -0.0027,  0.0079,  ...,  0.0167,  0.0103,  0.0114],\n",
       "         [ 0.0002,  0.0046,  0.0068,  ...,  0.0036, -0.0113, -0.0060],\n",
       "         ...,\n",
       "         [ 0.0013, -0.0131,  0.0359,  ...,  0.0159,  0.0013, -0.0061],\n",
       "         [-0.0054, -0.0022, -0.0273,  ...,  0.0044, -0.0212, -0.0105],\n",
       "         [ 0.0229,  0.0086, -0.0237,  ...,  0.0080, -0.0271, -0.0095]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.18.attention.wk.weight': tensor([[-0.0520, -0.0292, -0.0273,  ...,  0.0192,  0.0043, -0.0217],\n",
       "         [ 0.0002,  0.0093, -0.0102,  ...,  0.0099,  0.0081,  0.0510],\n",
       "         [ 0.0052,  0.0457, -0.0091,  ..., -0.0254, -0.0193,  0.0183],\n",
       "         ...,\n",
       "         [ 0.0005,  0.0371, -0.0295,  ..., -0.0391, -0.0396,  0.0540],\n",
       "         [ 0.0090, -0.0330, -0.0096,  ..., -0.0093,  0.0417,  0.0383],\n",
       "         [ 0.0309, -0.0106,  0.0586,  ..., -0.0393,  0.0334, -0.0123]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.18.attention.wv.weight': tensor([[ 0.0098,  0.0033,  0.0223,  ...,  0.0052,  0.0077,  0.0016],\n",
       "         [-0.0098, -0.0154, -0.0078,  ..., -0.0022,  0.0052, -0.0005],\n",
       "         [ 0.0019, -0.0032, -0.0083,  ..., -0.0054,  0.0078,  0.0059],\n",
       "         ...,\n",
       "         [-0.0087, -0.0050,  0.0006,  ...,  0.0033, -0.0042, -0.0096],\n",
       "         [ 0.0176, -0.0020,  0.0007,  ...,  0.0033,  0.0010, -0.0028],\n",
       "         [-0.0026, -0.0083,  0.0026,  ...,  0.0081,  0.0080, -0.0029]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.18.attention.wo.weight': tensor([[-0.0073,  0.0193,  0.0024,  ..., -0.0043,  0.0018, -0.0109],\n",
       "         [ 0.0004,  0.0051, -0.0066,  ...,  0.0081, -0.0084, -0.0124],\n",
       "         [ 0.0058, -0.0060, -0.0049,  ...,  0.0109,  0.0116,  0.0017],\n",
       "         ...,\n",
       "         [-0.0096, -0.0146,  0.0051,  ..., -0.0147,  0.0130, -0.0086],\n",
       "         [ 0.0060,  0.0005,  0.0101,  ..., -0.0137, -0.0055,  0.0151],\n",
       "         [-0.0044, -0.0029, -0.0092,  ..., -0.0023,  0.0048, -0.0095]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.18.feed_forward.w1.weight': tensor([[ 0.0043,  0.0034,  0.0020,  ..., -0.0087, -0.0289,  0.0137],\n",
       "         [-0.0115, -0.0240,  0.0170,  ...,  0.0181,  0.0258, -0.0116],\n",
       "         [ 0.0157,  0.0258,  0.0024,  ..., -0.0142,  0.0031,  0.0170],\n",
       "         ...,\n",
       "         [ 0.0016, -0.0231, -0.0148,  ...,  0.0038,  0.0139,  0.0237],\n",
       "         [ 0.0072,  0.0033, -0.0003,  ...,  0.0004, -0.0012, -0.0141],\n",
       "         [-0.0084, -0.0306,  0.0150,  ..., -0.0093, -0.0027, -0.0104]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.18.feed_forward.w3.weight': tensor([[-0.0072,  0.0148, -0.0081,  ...,  0.0014, -0.0117, -0.0132],\n",
       "         [ 0.0208, -0.0103, -0.0229,  ..., -0.0041,  0.0054,  0.0093],\n",
       "         [ 0.0021, -0.0012, -0.0142,  ..., -0.0073,  0.0133,  0.0142],\n",
       "         ...,\n",
       "         [ 0.0014,  0.0031,  0.0043,  ..., -0.0106, -0.0052, -0.0037],\n",
       "         [ 0.0100,  0.0045,  0.0076,  ...,  0.0027,  0.0047,  0.0071],\n",
       "         [-0.0090,  0.0092,  0.0092,  ..., -0.0166, -0.0114, -0.0011]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.18.feed_forward.w2.weight': tensor([[-0.0134,  0.0146,  0.0034,  ...,  0.0041, -0.0006, -0.0183],\n",
       "         [ 0.0111,  0.0025, -0.0047,  ...,  0.0124,  0.0182, -0.0029],\n",
       "         [-0.0009,  0.0046,  0.0182,  ...,  0.0025,  0.0097,  0.0007],\n",
       "         ...,\n",
       "         [ 0.0047,  0.0223,  0.0009,  ..., -0.0126, -0.0043, -0.0027],\n",
       "         [ 0.0137,  0.0042, -0.0049,  ..., -0.0036,  0.0010,  0.0001],\n",
       "         [-0.0283,  0.0103, -0.0041,  ..., -0.0114, -0.0082, -0.0109]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.18.attention_norm.weight': tensor([0.4883, 0.4746, 0.4531,  ..., 0.4453, 0.4512, 0.4473],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.18.ffn_norm.weight': tensor([0.3945, 0.3984, 0.4082,  ..., 0.3906, 0.4199, 0.4023],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.19.attention.wq.weight': tensor([[ 0.0152, -0.0009, -0.0107,  ..., -0.0103, -0.0052,  0.0134],\n",
       "         [-0.0165, -0.0016,  0.0063,  ...,  0.0031,  0.0014, -0.0154],\n",
       "         [ 0.0038, -0.0136,  0.0080,  ...,  0.0175, -0.0171, -0.0059],\n",
       "         ...,\n",
       "         [ 0.0132, -0.0178, -0.0256,  ..., -0.0035, -0.0447,  0.0161],\n",
       "         [ 0.0120,  0.0391, -0.0015,  ..., -0.0374, -0.0154, -0.0138],\n",
       "         [-0.0173, -0.0051,  0.0188,  ..., -0.0012,  0.0236, -0.0013]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.19.attention.wk.weight': tensor([[-0.0014, -0.0013, -0.0053,  ..., -0.0153, -0.0110, -0.0006],\n",
       "         [-0.0188, -0.0074, -0.0008,  ...,  0.0304,  0.0077,  0.0250],\n",
       "         [-0.0011,  0.0043,  0.0026,  ..., -0.0278, -0.0435, -0.0090],\n",
       "         ...,\n",
       "         [-0.0211,  0.0189, -0.0280,  ...,  0.0215,  0.0320,  0.0422],\n",
       "         [ 0.0408,  0.0747,  0.0425,  ...,  0.0141,  0.0006, -0.0359],\n",
       "         [-0.0283, -0.0012, -0.0050,  ...,  0.0425, -0.0403,  0.0172]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.19.attention.wv.weight': tensor([[-0.0015, -0.0035,  0.0077,  ...,  0.0074, -0.0126,  0.0099],\n",
       "         [-0.0003,  0.0020,  0.0040,  ..., -0.0018, -0.0132,  0.0042],\n",
       "         [-0.0086, -0.0088,  0.0014,  ..., -0.0025,  0.0104,  0.0059],\n",
       "         ...,\n",
       "         [ 0.0060,  0.0148,  0.0072,  ...,  0.0024, -0.0039,  0.0080],\n",
       "         [-0.0101,  0.0037,  0.0156,  ..., -0.0050, -0.0070, -0.0025],\n",
       "         [ 0.0004,  0.0256,  0.0008,  ...,  0.0162, -0.0056,  0.0211]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.19.attention.wo.weight': tensor([[ 0.0131,  0.0090, -0.0054,  ...,  0.0009, -0.0088,  0.0184],\n",
       "         [ 0.0017, -0.0051,  0.0055,  ...,  0.0237, -0.0028, -0.0024],\n",
       "         [-0.0012,  0.0015,  0.0074,  ..., -0.0142, -0.0078,  0.0038],\n",
       "         ...,\n",
       "         [ 0.0052, -0.0012,  0.0036,  ...,  0.0128, -0.0016, -0.0008],\n",
       "         [ 0.0053,  0.0016,  0.0046,  ..., -0.0079,  0.0172, -0.0004],\n",
       "         [ 0.0113, -0.0007, -0.0065,  ..., -0.0041,  0.0114, -0.0015]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.19.feed_forward.w1.weight': tensor([[-0.0088, -0.0178, -0.0084,  ...,  0.0068, -0.0024,  0.0036],\n",
       "         [ 0.0073, -0.0211,  0.0110,  ..., -0.0039, -0.0001, -0.0017],\n",
       "         [ 0.0332,  0.0042,  0.0564,  ...,  0.0513,  0.0215, -0.0292],\n",
       "         ...,\n",
       "         [ 0.0064,  0.0016, -0.0115,  ..., -0.0011,  0.0106,  0.0266],\n",
       "         [-0.0075, -0.0030,  0.0089,  ...,  0.0005,  0.0103,  0.0160],\n",
       "         [ 0.0025,  0.0136,  0.0017,  ...,  0.0165, -0.0074,  0.0001]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.19.feed_forward.w3.weight': tensor([[-1.2207e-02, -1.1658e-02,  5.7373e-03,  ...,  1.4160e-02,\n",
       "           6.4392e-03,  2.0020e-02],\n",
       "         [ 1.2390e-02,  4.9133e-03,  5.6763e-03,  ..., -1.4465e-02,\n",
       "           6.1340e-03, -1.5869e-02],\n",
       "         [-7.6675e-04, -1.3245e-02, -1.0132e-02,  ...,  3.5400e-03,\n",
       "           1.2512e-02,  1.4587e-02],\n",
       "         ...,\n",
       "         [ 1.7578e-02, -9.0599e-06,  1.5503e-02,  ..., -4.9438e-03,\n",
       "           7.5378e-03, -1.1475e-02],\n",
       "         [-5.9509e-03, -6.7139e-03, -3.7079e-03,  ..., -2.2827e-02,\n",
       "           2.6512e-04,  1.0986e-03],\n",
       "         [-1.5747e-02, -2.1210e-03, -9.5825e-03,  ..., -3.1471e-04,\n",
       "           1.4771e-02, -4.8828e-03]], dtype=torch.bfloat16),\n",
       " 'layers.19.feed_forward.w2.weight': tensor([[ 7.9346e-03, -2.0218e-04, -1.0620e-02,  ...,  5.9814e-03,\n",
       "           1.5991e-02, -6.1646e-03],\n",
       "         [-3.2349e-03,  1.3351e-03, -6.7139e-03,  ...,  1.4221e-02,\n",
       "           2.0752e-02, -7.5531e-04],\n",
       "         [-1.7090e-02, -2.2602e-04,  7.9346e-03,  ..., -1.1292e-02,\n",
       "           2.7771e-03,  8.6212e-04],\n",
       "         ...,\n",
       "         [ 1.7090e-02, -6.5918e-03, -1.0376e-02,  ..., -1.1292e-03,\n",
       "           7.4387e-04,  8.6670e-03],\n",
       "         [ 1.0437e-02,  2.7466e-02,  7.1335e-04,  ...,  1.7624e-03,\n",
       "           9.8705e-05, -7.9956e-03],\n",
       "         [ 1.2695e-02, -5.0049e-03,  2.5177e-04,  ..., -8.7280e-03,\n",
       "          -1.6357e-02,  9.9487e-03]], dtype=torch.bfloat16),\n",
       " 'layers.19.attention_norm.weight': tensor([0.4492, 0.4707, 0.4590,  ..., 0.4629, 0.4414, 0.4395],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.19.ffn_norm.weight': tensor([0.4121, 0.4141, 0.4219,  ..., 0.4062, 0.4277, 0.4180],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.20.attention.wq.weight': tensor([[ 0.0030, -0.0018,  0.0052,  ...,  0.0184, -0.0143, -0.0043],\n",
       "         [ 0.0020,  0.0079, -0.0053,  ..., -0.0060, -0.0042, -0.0120],\n",
       "         [-0.0167,  0.0038, -0.0010,  ...,  0.0147, -0.0118,  0.0084],\n",
       "         ...,\n",
       "         [-0.0040, -0.0053, -0.0054,  ...,  0.0304,  0.0186,  0.0271],\n",
       "         [ 0.0311, -0.0032, -0.0063,  ..., -0.0225, -0.0188, -0.0164],\n",
       "         [ 0.0128,  0.0139,  0.0259,  ..., -0.0305,  0.0166,  0.0168]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.20.attention.wk.weight': tensor([[-0.0146, -0.0032,  0.0144,  ..., -0.0171, -0.0115,  0.0308],\n",
       "         [-0.0381, -0.0110, -0.0234,  ...,  0.0179,  0.0320, -0.0102],\n",
       "         [-0.0242, -0.0017,  0.0107,  ..., -0.0029,  0.0131, -0.0334],\n",
       "         ...,\n",
       "         [ 0.0160,  0.0226,  0.0115,  ...,  0.0062, -0.0031, -0.0259],\n",
       "         [ 0.0183,  0.0183,  0.0076,  ..., -0.0217, -0.0076, -0.0059],\n",
       "         [ 0.0221, -0.0625,  0.0256,  ..., -0.0503, -0.0005,  0.0093]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.20.attention.wv.weight': tensor([[ 0.0058,  0.0059,  0.0041,  ...,  0.0030, -0.0085,  0.0032],\n",
       "         [ 0.0006,  0.0115, -0.0060,  ...,  0.0079,  0.0057,  0.0038],\n",
       "         [-0.0020,  0.0041, -0.0140,  ...,  0.0067,  0.0067,  0.0104],\n",
       "         ...,\n",
       "         [ 0.0018,  0.0010,  0.0040,  ...,  0.0019,  0.0047, -0.0098],\n",
       "         [ 0.0147, -0.0027, -0.0057,  ...,  0.0084, -0.0038,  0.0189],\n",
       "         [ 0.0039,  0.0132, -0.0137,  ..., -0.0102, -0.0029,  0.0045]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.20.attention.wo.weight': tensor([[-0.0293,  0.0066,  0.0026,  ...,  0.0004, -0.0120,  0.0070],\n",
       "         [ 0.0028, -0.0119, -0.0027,  ..., -0.0071,  0.0077,  0.0007],\n",
       "         [-0.0014, -0.0142,  0.0134,  ...,  0.0033,  0.0179,  0.0004],\n",
       "         ...,\n",
       "         [ 0.0025, -0.0050, -0.0076,  ...,  0.0026,  0.0016,  0.0036],\n",
       "         [ 0.0039, -0.0044, -0.0044,  ..., -0.0073,  0.0044,  0.0181],\n",
       "         [ 0.0034,  0.0020,  0.0064,  ...,  0.0020,  0.0007, -0.0219]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.20.feed_forward.w1.weight': tensor([[ 0.0018, -0.0198, -0.0076,  ..., -0.0258,  0.0156,  0.0027],\n",
       "         [-0.0107, -0.0131, -0.0013,  ..., -0.0026,  0.0055, -0.0029],\n",
       "         [ 0.0173,  0.0229,  0.0027,  ...,  0.0030,  0.0065, -0.0137],\n",
       "         ...,\n",
       "         [-0.0052, -0.0007, -0.0181,  ...,  0.0139,  0.0128,  0.0171],\n",
       "         [ 0.0123, -0.0087, -0.0142,  ...,  0.0092,  0.0070,  0.0126],\n",
       "         [ 0.0099,  0.0186, -0.0189,  ...,  0.0103, -0.0049,  0.0219]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.20.feed_forward.w3.weight': tensor([[-0.0205, -0.0023,  0.0034,  ..., -0.0156, -0.0066, -0.0078],\n",
       "         [ 0.0181, -0.0026, -0.0057,  ...,  0.0210,  0.0013, -0.0121],\n",
       "         [ 0.0032,  0.0095,  0.0014,  ..., -0.0200,  0.0128, -0.0066],\n",
       "         ...,\n",
       "         [ 0.0096, -0.0194, -0.0085,  ...,  0.0013, -0.0189, -0.0120],\n",
       "         [-0.0073,  0.0155, -0.0084,  ..., -0.0063, -0.0046, -0.0052],\n",
       "         [-0.0060, -0.0063, -0.0022,  ...,  0.0089,  0.0057, -0.0050]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.20.feed_forward.w2.weight': tensor([[ 0.0014,  0.0236, -0.0229,  ...,  0.0161, -0.0186,  0.0078],\n",
       "         [ 0.0107,  0.0035, -0.0052,  ...,  0.0049,  0.0080, -0.0123],\n",
       "         [-0.0109,  0.0004,  0.0056,  ..., -0.0172, -0.0135, -0.0020],\n",
       "         ...,\n",
       "         [-0.0086, -0.0050, -0.0204,  ..., -0.0036,  0.0036,  0.0037],\n",
       "         [-0.0135, -0.0057,  0.0007,  ...,  0.0010,  0.0097, -0.0060],\n",
       "         [ 0.0074, -0.0099, -0.0189,  ...,  0.0038,  0.0123,  0.0208]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.20.attention_norm.weight': tensor([0.4648, 0.4688, 0.4551,  ..., 0.4629, 0.4453, 0.4512],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.20.ffn_norm.weight': tensor([0.4238, 0.4258, 0.4375,  ..., 0.4160, 0.4395, 0.4355],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.21.attention.wq.weight': tensor([[-0.0006, -0.0002,  0.0106,  ..., -0.0047,  0.0020,  0.0125],\n",
       "         [ 0.0084,  0.0054,  0.0040,  ...,  0.0146, -0.0135, -0.0161],\n",
       "         [-0.0023,  0.0105,  0.0116,  ...,  0.0030, -0.0041,  0.0157],\n",
       "         ...,\n",
       "         [ 0.0165,  0.0115,  0.0083,  ..., -0.0192, -0.0150, -0.0074],\n",
       "         [-0.0160, -0.0139,  0.0225,  ..., -0.0320,  0.0115, -0.0022],\n",
       "         [ 0.0152,  0.0312, -0.0275,  ...,  0.0152, -0.0150, -0.0135]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.21.attention.wk.weight': tensor([[ 0.0077, -0.0232,  0.0201,  ..., -0.0084,  0.0052,  0.0132],\n",
       "         [-0.0159,  0.0089, -0.0085,  ..., -0.0014, -0.0298, -0.0292],\n",
       "         [ 0.0093,  0.0211,  0.0012,  ...,  0.0106,  0.0080, -0.0300],\n",
       "         ...,\n",
       "         [ 0.0131,  0.0084,  0.0082,  ..., -0.0024,  0.0206,  0.0282],\n",
       "         [ 0.0322,  0.0096,  0.0115,  ...,  0.0013,  0.0253,  0.0031],\n",
       "         [-0.0054, -0.0014, -0.0093,  ...,  0.0205,  0.0002,  0.0183]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.21.attention.wv.weight': tensor([[-9.7046e-03, -5.9204e-03, -6.5613e-03,  ...,  5.4626e-03,\n",
       "          -1.2665e-03, -5.6458e-03],\n",
       "         [ 1.2512e-02, -3.7231e-03,  7.9956e-03,  ..., -6.2943e-04,\n",
       "           4.7302e-03, -1.3000e-02],\n",
       "         [-5.9509e-03,  1.5137e-02,  3.3951e-04,  ..., -1.6479e-03,\n",
       "           7.0572e-05,  2.0630e-02],\n",
       "         ...,\n",
       "         [-1.2024e-02, -3.3264e-03,  4.4250e-03,  ..., -1.4771e-02,\n",
       "           1.9226e-03,  1.0071e-02],\n",
       "         [ 4.9591e-04,  3.5400e-03, -5.7373e-03,  ...,  4.4250e-03,\n",
       "          -1.4801e-03, -6.8359e-03],\n",
       "         [-9.9487e-03,  5.5542e-03, -3.4332e-04,  ..., -1.4709e-02,\n",
       "           1.4038e-02,  1.3351e-03]], dtype=torch.bfloat16),\n",
       " 'layers.21.attention.wo.weight': tensor([[ 7.9346e-04,  6.1035e-04,  5.4321e-03,  ..., -3.4790e-03,\n",
       "          -4.1504e-03,  5.5552e-05],\n",
       "         [-1.3916e-02,  3.0212e-03,  9.8267e-03,  ..., -1.2207e-02,\n",
       "          -6.5918e-03, -1.3672e-02],\n",
       "         [ 9.0332e-03, -6.5308e-03, -6.0730e-03,  ..., -1.4893e-02,\n",
       "          -3.7079e-03, -5.3406e-03],\n",
       "         ...,\n",
       "         [ 4.4861e-03,  6.8054e-03,  9.2163e-03,  ..., -2.3956e-03,\n",
       "           8.0872e-04,  3.7842e-03],\n",
       "         [ 1.0071e-02,  5.7678e-03,  2.0599e-03,  ...,  6.8054e-03,\n",
       "           3.2616e-04, -1.5991e-02],\n",
       "         [-1.7929e-03, -5.7983e-03, -1.9989e-03,  ..., -5.4321e-03,\n",
       "          -8.7280e-03, -3.2959e-03]], dtype=torch.bfloat16),\n",
       " 'layers.21.feed_forward.w1.weight': tensor([[ 0.0201,  0.0105, -0.0289,  ...,  0.0048,  0.0175,  0.0112],\n",
       "         [ 0.0125, -0.0042,  0.0002,  ...,  0.0017,  0.0015, -0.0386],\n",
       "         [ 0.0034,  0.0181, -0.0019,  ..., -0.0117, -0.0172,  0.0325],\n",
       "         ...,\n",
       "         [-0.0137,  0.0154,  0.0011,  ...,  0.0120, -0.0179,  0.0049],\n",
       "         [ 0.0087,  0.0126,  0.0079,  ...,  0.0184,  0.0054,  0.0208],\n",
       "         [ 0.0145, -0.0148, -0.0129,  ...,  0.0115, -0.0029, -0.0044]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.21.feed_forward.w3.weight': tensor([[ 0.0018,  0.0102,  0.0020,  ...,  0.0005, -0.0082,  0.0187],\n",
       "         [-0.0166, -0.0052, -0.0043,  ..., -0.0017, -0.0027,  0.0040],\n",
       "         [ 0.0005,  0.0015,  0.0092,  ...,  0.0165, -0.0049,  0.0140],\n",
       "         ...,\n",
       "         [ 0.0106, -0.0190, -0.0048,  ...,  0.0087,  0.0028,  0.0079],\n",
       "         [-0.0189,  0.0305,  0.0020,  ..., -0.0124, -0.0108, -0.0029],\n",
       "         [ 0.0129, -0.0089, -0.0043,  ...,  0.0012, -0.0006, -0.0126]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.21.feed_forward.w2.weight': tensor([[-0.0033, -0.0195,  0.0045,  ..., -0.0145, -0.0182,  0.0137],\n",
       "         [ 0.0055, -0.0025,  0.0153,  ...,  0.0123,  0.0164, -0.0159],\n",
       "         [ 0.0030, -0.0110, -0.0132,  ...,  0.0039,  0.0203, -0.0194],\n",
       "         ...,\n",
       "         [ 0.0001, -0.0008,  0.0210,  ..., -0.0050, -0.0046,  0.0043],\n",
       "         [ 0.0194, -0.0046, -0.0016,  ..., -0.0096, -0.0081,  0.0055],\n",
       "         [ 0.0117, -0.0110, -0.0104,  ..., -0.0173, -0.0133, -0.0028]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.21.attention_norm.weight': tensor([0.4766, 0.4531, 0.4590,  ..., 0.4707, 0.4375, 0.4707],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.21.ffn_norm.weight': tensor([0.4434, 0.4453, 0.4551,  ..., 0.4375, 0.4512, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.22.attention.wq.weight': tensor([[-0.0025,  0.0102, -0.0044,  ..., -0.0160, -0.0195, -0.0042],\n",
       "         [-0.0044,  0.0037,  0.0081,  ...,  0.0101, -0.0019, -0.0028],\n",
       "         [-0.0006,  0.0101,  0.0157,  ..., -0.0038, -0.0032, -0.0069],\n",
       "         ...,\n",
       "         [-0.0031, -0.0084,  0.0223,  ...,  0.0126,  0.0060,  0.0016],\n",
       "         [ 0.0070, -0.0150, -0.0206,  ...,  0.0302,  0.0036, -0.0177],\n",
       "         [-0.0104,  0.0050, -0.0069,  ..., -0.0072, -0.0242, -0.0029]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.22.attention.wk.weight': tensor([[-0.0007, -0.0095,  0.0027,  ...,  0.0322, -0.0046, -0.0045],\n",
       "         [ 0.0334,  0.0215,  0.0004,  ...,  0.0098, -0.0187, -0.0028],\n",
       "         [ 0.0026,  0.0256, -0.0107,  ...,  0.0095,  0.0181,  0.0053],\n",
       "         ...,\n",
       "         [ 0.0115,  0.0087,  0.0325,  ..., -0.0222, -0.0292, -0.0354],\n",
       "         [-0.0074, -0.0119, -0.0243,  ...,  0.0156,  0.0231,  0.0430],\n",
       "         [ 0.0050, -0.0110,  0.0160,  ...,  0.0112, -0.0189,  0.0021]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.22.attention.wv.weight': tensor([[-0.0046,  0.0053,  0.0026,  ...,  0.0077,  0.0030, -0.0007],\n",
       "         [ 0.0027, -0.0092,  0.0106,  ...,  0.0200,  0.0112,  0.0066],\n",
       "         [-0.0011, -0.0079,  0.0008,  ..., -0.0067, -0.0095, -0.0225],\n",
       "         ...,\n",
       "         [-0.0076,  0.0045,  0.0062,  ..., -0.0151,  0.0020, -0.0071],\n",
       "         [-0.0079,  0.0004,  0.0127,  ...,  0.0091, -0.0107,  0.0135],\n",
       "         [-0.0069, -0.0093, -0.0121,  ...,  0.0160,  0.0128, -0.0344]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.22.attention.wo.weight': tensor([[-5.5542e-03, -6.6528e-03,  9.4414e-05,  ...,  2.1667e-03,\n",
       "           2.6733e-02, -9.5825e-03],\n",
       "         [-9.5215e-03, -1.9165e-02,  1.5991e-02,  ..., -8.7280e-03,\n",
       "           3.5248e-03, -2.3956e-03],\n",
       "         [ 1.2085e-02, -7.0496e-03,  1.6724e-02,  ..., -1.9150e-03,\n",
       "           1.4954e-02, -8.1177e-03],\n",
       "         ...,\n",
       "         [-1.6357e-02, -5.1575e-03, -7.3853e-03,  ..., -1.1292e-02,\n",
       "           6.4087e-03, -8.1787e-03],\n",
       "         [ 1.7822e-02, -1.6968e-02, -6.8665e-03,  ..., -6.4697e-03,\n",
       "           1.3580e-03, -1.3367e-02],\n",
       "         [ 2.1458e-05,  7.9346e-03,  3.5248e-03,  ...,  5.4932e-03,\n",
       "           1.6846e-02,  7.3242e-04]], dtype=torch.bfloat16),\n",
       " 'layers.22.feed_forward.w1.weight': tensor([[-0.0020,  0.0095,  0.0026,  ...,  0.0108, -0.0183, -0.0242],\n",
       "         [ 0.0118, -0.0173,  0.0076,  ..., -0.0011,  0.0238, -0.0036],\n",
       "         [-0.0269, -0.0126, -0.0060,  ...,  0.0018,  0.0144,  0.0148],\n",
       "         ...,\n",
       "         [ 0.0073,  0.0142,  0.0017,  ...,  0.0059,  0.0122, -0.0183],\n",
       "         [-0.0160,  0.0243, -0.0055,  ...,  0.0221, -0.0072,  0.0177],\n",
       "         [-0.0150, -0.0280, -0.0197,  ...,  0.0168,  0.0058,  0.0014]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.22.feed_forward.w3.weight': tensor([[ 0.0009,  0.0054,  0.0004,  ..., -0.0032,  0.0099, -0.0045],\n",
       "         [-0.0037, -0.0150,  0.0190,  ..., -0.0146, -0.0067,  0.0066],\n",
       "         [ 0.0018, -0.0049,  0.0103,  ..., -0.0088,  0.0015, -0.0042],\n",
       "         ...,\n",
       "         [-0.0060,  0.0008,  0.0160,  ..., -0.0061, -0.0093,  0.0069],\n",
       "         [ 0.0071,  0.0099,  0.0035,  ...,  0.0065,  0.0156,  0.0032],\n",
       "         [-0.0122,  0.0134,  0.0236,  ...,  0.0160, -0.0002,  0.0016]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.22.feed_forward.w2.weight': tensor([[-8.5449e-03, -1.8616e-03,  5.9509e-03,  ...,  2.6367e-02,\n",
       "          -1.7822e-02,  9.4604e-03],\n",
       "         [ 5.7602e-04, -1.5869e-02, -5.1270e-03,  ...,  3.7670e-05,\n",
       "           2.5177e-03, -1.8921e-03],\n",
       "         [ 4.4250e-03,  1.0315e-02, -1.4038e-02,  ...,  6.3705e-04,\n",
       "          -1.3855e-02,  1.6724e-02],\n",
       "         ...,\n",
       "         [-4.8828e-03, -4.7302e-03,  1.2085e-02,  ..., -1.3428e-03,\n",
       "          -1.0132e-02, -1.1902e-03],\n",
       "         [-1.8539e-03,  4.0283e-03, -1.2817e-02,  ..., -2.9297e-03,\n",
       "           3.8300e-03,  1.3062e-02],\n",
       "         [ 1.6113e-02,  1.4343e-02,  7.9956e-03,  ...,  8.3618e-03,\n",
       "          -1.2741e-03,  1.8845e-03]], dtype=torch.bfloat16),\n",
       " 'layers.22.attention_norm.weight': tensor([0.4824, 0.4727, 0.4805,  ..., 0.4844, 0.4453, 0.4824],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.22.ffn_norm.weight': tensor([0.4570, 0.4570, 0.4707,  ..., 0.4473, 0.4688, 0.4668],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.23.attention.wq.weight': tensor([[-0.0032, -0.0096, -0.0040,  ..., -0.0118,  0.0039, -0.0020],\n",
       "         [ 0.0090, -0.0030,  0.0021,  ..., -0.0025, -0.0179,  0.0045],\n",
       "         [ 0.0103, -0.0160,  0.0019,  ...,  0.0107,  0.0082, -0.0093],\n",
       "         ...,\n",
       "         [-0.0245,  0.0054,  0.0107,  ...,  0.0439, -0.0175, -0.0089],\n",
       "         [ 0.0105, -0.0059,  0.0115,  ...,  0.0311,  0.0131, -0.0150],\n",
       "         [-0.0111, -0.0076, -0.0190,  ...,  0.0063,  0.0208,  0.0063]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.23.attention.wk.weight': tensor([[-0.0083,  0.0111,  0.0093,  ...,  0.0117, -0.0060,  0.0035],\n",
       "         [ 0.0025,  0.0059,  0.0029,  ...,  0.0134,  0.0276, -0.0064],\n",
       "         [ 0.0304, -0.0007, -0.0415,  ..., -0.0162, -0.0250, -0.0259],\n",
       "         ...,\n",
       "         [-0.0146,  0.0111,  0.0310,  ..., -0.0598, -0.0107, -0.0278],\n",
       "         [ 0.0486,  0.0034, -0.0236,  ...,  0.0393,  0.0332,  0.0259],\n",
       "         [-0.0258, -0.0107, -0.0128,  ...,  0.0204, -0.0288, -0.0135]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.23.attention.wv.weight': tensor([[ 0.0077, -0.0008,  0.0074,  ...,  0.0045, -0.0020, -0.0017],\n",
       "         [-0.0079,  0.0231, -0.0134,  ..., -0.0019,  0.0069,  0.0062],\n",
       "         [ 0.0090, -0.0003,  0.0073,  ...,  0.0026,  0.0096,  0.0188],\n",
       "         ...,\n",
       "         [-0.0045,  0.0101,  0.0124,  ...,  0.0010,  0.0179,  0.0060],\n",
       "         [ 0.0001, -0.0029, -0.0016,  ..., -0.0099, -0.0144, -0.0014],\n",
       "         [ 0.0140, -0.0029, -0.0006,  ...,  0.0150,  0.0154, -0.0170]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.23.attention.wo.weight': tensor([[ 0.0063, -0.0143,  0.0106,  ..., -0.0168, -0.0074, -0.0042],\n",
       "         [-0.0128, -0.0073,  0.0096,  ...,  0.0025, -0.0011,  0.0026],\n",
       "         [-0.0023,  0.0078,  0.0111,  ..., -0.0022, -0.0091,  0.0019],\n",
       "         ...,\n",
       "         [ 0.0227,  0.0038, -0.0173,  ..., -0.0038, -0.0096,  0.0054],\n",
       "         [ 0.0057,  0.0001,  0.0172,  ...,  0.0054,  0.0099, -0.0032],\n",
       "         [ 0.0022,  0.0018,  0.0102,  ..., -0.0064,  0.0045, -0.0058]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.23.feed_forward.w1.weight': tensor([[-0.0016, -0.0053, -0.0205,  ..., -0.0164,  0.0036, -0.0117],\n",
       "         [ 0.0083,  0.0024,  0.0050,  ...,  0.0222, -0.0132, -0.0072],\n",
       "         [-0.0197, -0.0004,  0.0058,  ..., -0.0092,  0.0222,  0.0034],\n",
       "         ...,\n",
       "         [ 0.0238,  0.0037, -0.0075,  ...,  0.0060,  0.0095, -0.0177],\n",
       "         [ 0.0074, -0.0162, -0.0098,  ..., -0.0157,  0.0102,  0.0117],\n",
       "         [-0.0004, -0.0212,  0.0034,  ...,  0.0160,  0.0038, -0.0128]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.23.feed_forward.w3.weight': tensor([[ 2.0752e-02, -5.7373e-03, -1.4343e-02,  ..., -1.2878e-02,\n",
       "          -7.4463e-03,  1.3123e-02],\n",
       "         [ 1.1658e-02, -1.5869e-03, -2.3484e-05,  ...,  8.3008e-03,\n",
       "          -1.0437e-02,  6.5308e-03],\n",
       "         [-3.5858e-03, -2.0447e-03,  1.7456e-02,  ...,  1.9836e-03,\n",
       "          -1.4465e-02,  2.1851e-02],\n",
       "         ...,\n",
       "         [ 1.0071e-02, -2.1667e-03,  8.9722e-03,  ...,  4.1199e-03,\n",
       "           4.6387e-03,  2.9602e-03],\n",
       "         [ 3.7537e-03,  1.6499e-04,  7.5989e-03,  ...,  2.9564e-04,\n",
       "          -1.3855e-02,  1.3550e-02],\n",
       "         [ 5.1270e-03,  6.4392e-03, -1.0254e-02,  ...,  1.2512e-03,\n",
       "          -1.3794e-02,  1.1873e-04]], dtype=torch.bfloat16),\n",
       " 'layers.23.feed_forward.w2.weight': tensor([[ 0.0006,  0.0049,  0.0018,  ...,  0.0037,  0.0037,  0.0005],\n",
       "         [-0.0159, -0.0045, -0.0116,  ..., -0.0095,  0.0107,  0.0078],\n",
       "         [ 0.0067, -0.0001,  0.0053,  ..., -0.0049,  0.0101, -0.0012],\n",
       "         ...,\n",
       "         [ 0.0085,  0.0089, -0.0071,  ..., -0.0027, -0.0139,  0.0044],\n",
       "         [-0.0056, -0.0091, -0.0071,  ..., -0.0231, -0.0201, -0.0055],\n",
       "         [-0.0277, -0.0186,  0.0121,  ...,  0.0013,  0.0003,  0.0050]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.23.attention_norm.weight': tensor([0.4941, 0.4902, 0.4883,  ..., 0.5078, 0.4648, 0.4941],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.23.ffn_norm.weight': tensor([0.4727, 0.4746, 0.4746,  ..., 0.4668, 0.4805, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.24.attention.wq.weight': tensor([[-0.0068,  0.0033,  0.0166,  ...,  0.0069, -0.0109, -0.0256],\n",
       "         [ 0.0077, -0.0143,  0.0023,  ..., -0.0104, -0.0025,  0.0050],\n",
       "         [-0.0106, -0.0044, -0.0138,  ..., -0.0098,  0.0045, -0.0182],\n",
       "         ...,\n",
       "         [-0.0113, -0.0193, -0.0024,  ...,  0.0142, -0.0204, -0.0474],\n",
       "         [-0.0309, -0.0164,  0.0144,  ...,  0.0150, -0.0141,  0.0277],\n",
       "         [-0.0352, -0.0269, -0.0330,  ..., -0.0280, -0.0199,  0.0203]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.24.attention.wk.weight': tensor([[ 0.0106, -0.0063,  0.0168,  ...,  0.0284,  0.0044,  0.0028],\n",
       "         [ 0.0199,  0.0148,  0.0194,  ...,  0.0017,  0.0011, -0.0005],\n",
       "         [-0.0125,  0.0080,  0.0051,  ...,  0.0099,  0.0057,  0.0178],\n",
       "         ...,\n",
       "         [ 0.0282,  0.0041, -0.0244,  ..., -0.0286,  0.0330, -0.0444],\n",
       "         [-0.0442,  0.0054, -0.0117,  ...,  0.0688, -0.0022,  0.0233],\n",
       "         [-0.0173, -0.0013,  0.0444,  ..., -0.0221, -0.0069, -0.0003]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.24.attention.wv.weight': tensor([[ 0.0070, -0.0153, -0.0049,  ...,  0.0062, -0.0039, -0.0139],\n",
       "         [ 0.0079, -0.0004,  0.0019,  ...,  0.0023,  0.0210, -0.0099],\n",
       "         [-0.0253,  0.0344,  0.0266,  ..., -0.0109, -0.0078, -0.0045],\n",
       "         ...,\n",
       "         [-0.0177,  0.0014, -0.0089,  ...,  0.0034, -0.0135, -0.0025],\n",
       "         [ 0.0077, -0.0072, -0.0078,  ..., -0.0162, -0.0231, -0.0009],\n",
       "         [-0.0036, -0.0079, -0.0172,  ...,  0.0007,  0.0092, -0.0011]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.24.attention.wo.weight': tensor([[ 0.0063,  0.0101, -0.0009,  ..., -0.0011,  0.0006,  0.0040],\n",
       "         [ 0.0031, -0.0064, -0.0256,  ..., -0.0007, -0.0023,  0.0056],\n",
       "         [-0.0016,  0.0034, -0.0016,  ..., -0.0014, -0.0019, -0.0090],\n",
       "         ...,\n",
       "         [-0.0085,  0.0090, -0.0149,  ...,  0.0042,  0.0116,  0.0027],\n",
       "         [-0.0145,  0.0128, -0.0352,  ..., -0.0164, -0.0058, -0.0007],\n",
       "         [-0.0003, -0.0029, -0.0042,  ...,  0.0061, -0.0003,  0.0013]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.24.feed_forward.w1.weight': tensor([[ 0.0010, -0.0072, -0.0027,  ...,  0.0298, -0.0148,  0.0077],\n",
       "         [ 0.0027, -0.0178, -0.0061,  ...,  0.0184,  0.0229, -0.0140],\n",
       "         [-0.0131, -0.0026,  0.0001,  ...,  0.0287,  0.0104, -0.0093],\n",
       "         ...,\n",
       "         [ 0.0072,  0.0160,  0.0040,  ...,  0.0151, -0.0037, -0.0208],\n",
       "         [-0.0239,  0.0019, -0.0115,  ..., -0.0168, -0.0172,  0.0311],\n",
       "         [-0.0057,  0.0057, -0.0008,  ...,  0.0031,  0.0148,  0.0190]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.24.feed_forward.w3.weight': tensor([[-9.6436e-03, -1.3733e-02,  1.6724e-02,  ..., -1.4648e-03,\n",
       "          -1.4038e-02, -5.5542e-03],\n",
       "         [ 1.8188e-02,  5.0964e-03,  3.5156e-02,  ..., -1.4221e-02,\n",
       "           1.3794e-02,  6.5308e-03],\n",
       "         [ 2.3365e-04, -1.2589e-03, -1.2817e-02,  ...,  2.5024e-03,\n",
       "           1.1108e-02,  1.3199e-03],\n",
       "         ...,\n",
       "         [ 7.3853e-03, -8.3618e-03,  9.3842e-04,  ..., -1.1719e-02,\n",
       "           1.5564e-02, -8.3008e-03],\n",
       "         [-2.5940e-03,  4.6082e-03,  8.6308e-05,  ...,  2.0142e-02,\n",
       "           8.3008e-03, -1.1108e-02],\n",
       "         [-3.5400e-03,  3.4027e-03, -4.7302e-03,  ..., -1.3062e-02,\n",
       "          -2.2827e-02, -1.5015e-02]], dtype=torch.bfloat16),\n",
       " 'layers.24.feed_forward.w2.weight': tensor([[-0.0125,  0.0092, -0.0026,  ..., -0.0043, -0.0113, -0.0112],\n",
       "         [-0.0039, -0.0047, -0.0129,  ..., -0.0205,  0.0013, -0.0060],\n",
       "         [-0.0031,  0.0136,  0.0007,  ...,  0.0135,  0.0176, -0.0059],\n",
       "         ...,\n",
       "         [-0.0198,  0.0081,  0.0032,  ..., -0.0061,  0.0089,  0.0027],\n",
       "         [ 0.0120,  0.0007, -0.0118,  ..., -0.0027,  0.0093,  0.0038],\n",
       "         [-0.0198,  0.0159, -0.0067,  ..., -0.0054, -0.0078, -0.0123]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.24.attention_norm.weight': tensor([0.4883, 0.4922, 0.4922,  ..., 0.5156, 0.4707, 0.4902],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.24.ffn_norm.weight': tensor([0.4922, 0.4902, 0.4961,  ..., 0.4824, 0.4980, 0.5000],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.25.attention.wq.weight': tensor([[ 0.0117, -0.0027, -0.0017,  ...,  0.0059,  0.0109,  0.0106],\n",
       "         [ 0.0118, -0.0072,  0.0051,  ..., -0.0151, -0.0075, -0.0070],\n",
       "         [ 0.0011,  0.0007, -0.0112,  ..., -0.0137,  0.0049,  0.0104],\n",
       "         ...,\n",
       "         [-0.0225,  0.0172,  0.0108,  ..., -0.0275, -0.0391, -0.0223],\n",
       "         [-0.0093,  0.0011,  0.0073,  ...,  0.0139, -0.0117,  0.0116],\n",
       "         [-0.0177, -0.0248,  0.0067,  ...,  0.0232,  0.0228, -0.0091]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.25.attention.wk.weight': tensor([[ 0.0142, -0.0001, -0.0026,  ..., -0.0201, -0.0157, -0.0233],\n",
       "         [-0.0004,  0.0016,  0.0070,  ..., -0.0110, -0.0006,  0.0133],\n",
       "         [-0.0118,  0.0108, -0.0029,  ..., -0.0094, -0.0060, -0.0139],\n",
       "         ...,\n",
       "         [-0.0283,  0.0201, -0.0194,  ...,  0.0248,  0.0430,  0.0293],\n",
       "         [-0.0168, -0.0162,  0.0120,  ...,  0.0098, -0.0016,  0.0442],\n",
       "         [-0.0488,  0.0219, -0.0146,  ..., -0.0036, -0.0417,  0.0172]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.25.attention.wv.weight': tensor([[ 0.0137, -0.0211,  0.0028,  ..., -0.0061, -0.0087, -0.0058],\n",
       "         [ 0.0023,  0.0036,  0.0142,  ...,  0.0018, -0.0049,  0.0040],\n",
       "         [ 0.0157, -0.0126, -0.0170,  ...,  0.0107, -0.0016, -0.0065],\n",
       "         ...,\n",
       "         [ 0.0010,  0.0009,  0.0075,  ...,  0.0208,  0.0084, -0.0229],\n",
       "         [-0.0070,  0.0074,  0.0020,  ...,  0.0109,  0.0104, -0.0189],\n",
       "         [ 0.0042,  0.0126,  0.0023,  ..., -0.0079, -0.0132,  0.0050]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.25.attention.wo.weight': tensor([[-1.1108e-02,  5.0964e-03, -9.5825e-03,  ..., -8.9722e-03,\n",
       "           1.5625e-02,  8.3160e-04],\n",
       "         [-2.7954e-02,  5.7068e-03,  7.3242e-03,  ..., -1.1902e-02,\n",
       "          -1.1230e-02, -1.1475e-02],\n",
       "         [-1.9287e-02, -2.1729e-02, -1.7090e-02,  ...,  5.3711e-03,\n",
       "           2.6367e-02, -2.1851e-02],\n",
       "         ...,\n",
       "         [ 1.0559e-02,  4.5166e-03, -3.3569e-03,  ..., -1.3062e-02,\n",
       "           8.1787e-03,  1.2131e-03],\n",
       "         [ 2.6489e-02, -3.7079e-03, -1.2573e-02,  ...,  8.9264e-04,\n",
       "           1.0071e-02,  1.4465e-02],\n",
       "         [-1.6846e-02,  5.6028e-05,  1.9169e-04,  ...,  5.0659e-03,\n",
       "          -6.1646e-03, -7.7820e-03]], dtype=torch.bfloat16),\n",
       " 'layers.25.feed_forward.w1.weight': tensor([[ 1.0498e-02,  9.7656e-04, -5.6458e-03,  ...,  1.4420e-03,\n",
       "           1.0803e-02,  2.1210e-03],\n",
       "         [-3.6926e-03, -9.9487e-03, -2.1973e-02,  ..., -7.7820e-03,\n",
       "          -1.9897e-02,  8.0566e-03],\n",
       "         [ 1.1902e-02,  1.8555e-02, -1.0315e-02,  ..., -4.2236e-02,\n",
       "          -3.2654e-03, -7.5989e-03],\n",
       "         ...,\n",
       "         [ 1.4722e-05,  1.4099e-02, -1.1841e-02,  ..., -1.4267e-03,\n",
       "           3.9673e-04,  1.3123e-02],\n",
       "         [ 4.1580e-04, -1.6235e-02, -7.6904e-03,  ..., -1.1108e-02,\n",
       "          -6.2866e-03,  5.7373e-03],\n",
       "         [-3.1494e-02, -9.6893e-04, -2.3926e-02,  ...,  6.4850e-04,\n",
       "          -2.5330e-03,  8.3923e-04]], dtype=torch.bfloat16),\n",
       " 'layers.25.feed_forward.w3.weight': tensor([[-5.8289e-03,  3.1738e-02, -1.3428e-02,  ..., -1.1414e-02,\n",
       "          -1.4221e-02, -9.0942e-03],\n",
       "         [-1.5076e-02, -9.8267e-03,  5.1880e-03,  ...,  5.7983e-03,\n",
       "           1.7456e-02,  1.3977e-02],\n",
       "         [ 4.6082e-03,  1.0376e-02,  7.1335e-04,  ...,  4.3640e-03,\n",
       "           3.6163e-03,  2.1606e-02],\n",
       "         ...,\n",
       "         [-2.4170e-02, -3.0212e-03, -3.7842e-03,  ..., -1.4343e-03,\n",
       "          -4.1199e-03,  1.5137e-02],\n",
       "         [-1.5747e-02,  1.8082e-03, -2.5177e-03,  ...,  1.8311e-02,\n",
       "          -2.1484e-02,  6.3171e-03],\n",
       "         [ 1.4893e-02, -2.9297e-03, -1.5259e-02,  ...,  9.0942e-03,\n",
       "          -6.5863e-06,  1.5137e-02]], dtype=torch.bfloat16),\n",
       " 'layers.25.feed_forward.w2.weight': tensor([[ 0.0035, -0.0155,  0.0079,  ...,  0.0136, -0.0089,  0.0042],\n",
       "         [-0.0199, -0.0179, -0.0065,  ..., -0.0117, -0.0081, -0.0089],\n",
       "         [-0.0027, -0.0010, -0.0023,  ...,  0.0059,  0.0018,  0.0060],\n",
       "         ...,\n",
       "         [-0.0134,  0.0280, -0.0106,  ...,  0.0097, -0.0198,  0.0003],\n",
       "         [ 0.0002,  0.0087,  0.0054,  ..., -0.0115, -0.0018,  0.0057],\n",
       "         [ 0.0201,  0.0189,  0.0118,  ..., -0.0003,  0.0029, -0.0244]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.25.attention_norm.weight': tensor([0.5000, 0.5039, 0.4922,  ..., 0.5352, 0.4766, 0.5078],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.25.ffn_norm.weight': tensor([0.5078, 0.5039, 0.5117,  ..., 0.5000, 0.5117, 0.5078],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.26.attention.wq.weight': tensor([[ 0.0002, -0.0017, -0.0089,  ...,  0.0046, -0.0008,  0.0081],\n",
       "         [-0.0037,  0.0060, -0.0010,  ..., -0.0056, -0.0037, -0.0085],\n",
       "         [ 0.0047, -0.0005, -0.0204,  ...,  0.0023, -0.0069,  0.0011],\n",
       "         ...,\n",
       "         [ 0.0005, -0.0097, -0.0020,  ..., -0.0247,  0.0090, -0.0181],\n",
       "         [ 0.0035,  0.0097,  0.0175,  ...,  0.0014,  0.0016, -0.0129],\n",
       "         [-0.0109,  0.0166,  0.0146,  ...,  0.0104,  0.0045, -0.0062]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.26.attention.wk.weight': tensor([[ 0.0198,  0.0044,  0.0049,  ..., -0.0154, -0.0332,  0.0134],\n",
       "         [ 0.0126,  0.0177, -0.0036,  ..., -0.0287, -0.0280, -0.0107],\n",
       "         [ 0.0031,  0.0006,  0.0057,  ...,  0.0168,  0.0305,  0.0089],\n",
       "         ...,\n",
       "         [ 0.0107, -0.0005, -0.0023,  ...,  0.0027, -0.0038,  0.0225],\n",
       "         [-0.0190, -0.0114,  0.0029,  ..., -0.0008, -0.0113,  0.0142],\n",
       "         [ 0.0008, -0.0148, -0.0088,  ...,  0.0025,  0.0211,  0.0144]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.26.attention.wv.weight': tensor([[ 1.4893e-02, -1.5747e-02, -4.3030e-03,  ..., -4.7913e-03,\n",
       "          -9.3384e-03, -1.0315e-02],\n",
       "         [-1.4587e-02, -1.7334e-02,  6.3171e-03,  ..., -3.6163e-03,\n",
       "           1.8799e-02,  1.9043e-02],\n",
       "         [-7.2632e-03, -1.0254e-02, -6.7902e-04,  ...,  2.4719e-03,\n",
       "           1.8433e-02,  7.2479e-05],\n",
       "         ...,\n",
       "         [-1.4526e-02, -1.4801e-03,  5.3406e-03,  ..., -5.6763e-03,\n",
       "          -1.8555e-02,  3.9368e-03],\n",
       "         [ 2.6703e-03,  2.4658e-02, -9.0332e-03,  ...,  1.2695e-02,\n",
       "           1.3580e-03, -2.7771e-03],\n",
       "         [-1.0498e-02,  1.2756e-02, -9.4604e-03,  ...,  1.4893e-02,\n",
       "          -1.8433e-02, -3.8605e-03]], dtype=torch.bfloat16),\n",
       " 'layers.26.attention.wo.weight': tensor([[-0.0265, -0.0031, -0.0003,  ...,  0.0015,  0.0029, -0.0090],\n",
       "         [-0.0085,  0.0134,  0.0045,  ...,  0.0214,  0.0212, -0.0117],\n",
       "         [-0.0081,  0.0014,  0.0010,  ..., -0.0240,  0.0010, -0.0046],\n",
       "         ...,\n",
       "         [ 0.0119, -0.0070, -0.0054,  ...,  0.0201, -0.0117,  0.0069],\n",
       "         [ 0.0006,  0.0010, -0.0056,  ..., -0.0181,  0.0092, -0.0123],\n",
       "         [ 0.0002, -0.0087,  0.0044,  ..., -0.0047,  0.0006,  0.0192]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.26.feed_forward.w1.weight': tensor([[-1.9653e-02, -1.7090e-02, -9.4604e-03,  ...,  5.6152e-03,\n",
       "          -2.8809e-02, -1.0681e-02],\n",
       "         [-9.1553e-03, -2.5757e-02, -2.5513e-02,  ...,  1.8311e-02,\n",
       "          -1.1230e-02,  4.5471e-03],\n",
       "         [ 1.9409e-02,  5.7983e-03, -1.4282e-02,  ..., -5.0049e-03,\n",
       "           1.8188e-02,  6.7444e-03],\n",
       "         ...,\n",
       "         [-1.0559e-02, -1.1963e-02,  9.3994e-03,  ..., -1.0376e-02,\n",
       "           1.9226e-03,  1.4160e-02],\n",
       "         [ 2.6001e-02, -1.6689e-04,  1.3367e-02,  ...,  4.8828e-03,\n",
       "          -2.7222e-02,  1.0193e-02],\n",
       "         [-1.5625e-02,  2.3438e-02, -3.5763e-05,  ..., -8.7891e-03,\n",
       "          -6.5002e-03,  9.4223e-04]], dtype=torch.bfloat16),\n",
       " 'layers.26.feed_forward.w3.weight': tensor([[-0.0006, -0.0089, -0.0272,  ..., -0.0032,  0.0046,  0.0060],\n",
       "         [ 0.0035,  0.0095,  0.0084,  ..., -0.0109, -0.0015,  0.0085],\n",
       "         [ 0.0098,  0.0008,  0.0225,  ...,  0.0057, -0.0176, -0.0032],\n",
       "         ...,\n",
       "         [ 0.0143,  0.0132,  0.0014,  ...,  0.0186, -0.0198,  0.0060],\n",
       "         [ 0.0156,  0.0056,  0.0036,  ..., -0.0130, -0.0260,  0.0132],\n",
       "         [ 0.0073,  0.0010,  0.0032,  ..., -0.0092, -0.0140,  0.0020]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.26.feed_forward.w2.weight': tensor([[-0.0026,  0.0035,  0.0061,  ...,  0.0065, -0.0123, -0.0083],\n",
       "         [ 0.0060, -0.0010,  0.0159,  ..., -0.0034,  0.0214,  0.0212],\n",
       "         [ 0.0069,  0.0131, -0.0049,  ...,  0.0040,  0.0082,  0.0026],\n",
       "         ...,\n",
       "         [ 0.0032,  0.0110, -0.0140,  ...,  0.0048,  0.0051, -0.0090],\n",
       "         [ 0.0014,  0.0020,  0.0153,  ..., -0.0002,  0.0017, -0.0014],\n",
       "         [-0.0072, -0.0076,  0.0104,  ...,  0.0171,  0.0037, -0.0004]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.26.attention_norm.weight': tensor([0.4844, 0.4746, 0.4609,  ..., 0.4902, 0.4512, 0.4785],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.26.ffn_norm.weight': tensor([0.5234, 0.5273, 0.5352,  ..., 0.5234, 0.5391, 0.5273],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.27.attention.wq.weight': tensor([[-0.0242, -0.0103, -0.0178,  ...,  0.0200,  0.0063, -0.0134],\n",
       "         [ 0.0011, -0.0297, -0.0369,  ..., -0.0064, -0.0051,  0.0026],\n",
       "         [ 0.0144, -0.0036, -0.0197,  ...,  0.0093,  0.0100,  0.0077],\n",
       "         ...,\n",
       "         [-0.0491, -0.0030, -0.0005,  ...,  0.0111, -0.0308, -0.0098],\n",
       "         [ 0.0168, -0.0400,  0.0087,  ...,  0.0094,  0.0172,  0.0188],\n",
       "         [-0.0212, -0.0004,  0.0020,  ...,  0.0325,  0.0087, -0.0439]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.27.attention.wk.weight': tensor([[ 0.0337, -0.0332,  0.0216,  ..., -0.0282,  0.0110,  0.0096],\n",
       "         [-0.0040,  0.0040, -0.0121,  ...,  0.0154, -0.0160,  0.0013],\n",
       "         [ 0.0077, -0.0100,  0.0085,  ...,  0.0078,  0.0173,  0.0466],\n",
       "         ...,\n",
       "         [-0.0288,  0.0072,  0.0046,  ..., -0.0493,  0.0079, -0.0107],\n",
       "         [ 0.0147, -0.0048,  0.0072,  ..., -0.0144,  0.0089, -0.0071],\n",
       "         [-0.0223,  0.0322, -0.0033,  ...,  0.0129, -0.0037, -0.0554]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.27.attention.wv.weight': tensor([[ 2.0142e-03, -6.2561e-03,  1.4038e-02,  ..., -1.4343e-02,\n",
       "          -7.7248e-05,  1.7944e-02],\n",
       "         [ 1.8188e-02,  4.0894e-03,  6.8188e-05,  ...,  7.5378e-03,\n",
       "           1.6403e-03,  6.4697e-03],\n",
       "         [-1.2390e-02, -1.4893e-02,  2.5757e-02,  ...,  1.0315e-02,\n",
       "           1.0452e-03,  9.3994e-03],\n",
       "         ...,\n",
       "         [ 3.7537e-03, -9.3994e-03,  2.7008e-03,  ..., -3.3112e-03,\n",
       "           1.1780e-02, -2.1484e-02],\n",
       "         [ 1.4526e-02, -2.5368e-04,  1.0223e-03,  ..., -1.3306e-02,\n",
       "           1.3977e-02, -5.7678e-03],\n",
       "         [-1.0071e-02, -6.1646e-03, -2.5757e-02,  ..., -2.4796e-04,\n",
       "           9.0332e-03, -6.5918e-03]], dtype=torch.bfloat16),\n",
       " 'layers.27.attention.wo.weight': tensor([[ 0.0048,  0.0114, -0.0055,  ...,  0.0033,  0.0006, -0.0099],\n",
       "         [ 0.0112,  0.0064,  0.0219,  ..., -0.0041,  0.0002,  0.0070],\n",
       "         [-0.0115,  0.0156, -0.0135,  ...,  0.0106, -0.0017,  0.0137],\n",
       "         ...,\n",
       "         [ 0.0015,  0.0100, -0.0035,  ...,  0.0040, -0.0187, -0.0081],\n",
       "         [ 0.0114, -0.0069,  0.0059,  ..., -0.0089,  0.0102,  0.0022],\n",
       "         [-0.0193,  0.0098,  0.0183,  ...,  0.0015, -0.0067, -0.0077]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.27.feed_forward.w1.weight': tensor([[ 0.0009, -0.0220,  0.0031,  ..., -0.0123, -0.0054, -0.0044],\n",
       "         [-0.0056, -0.0098, -0.0249,  ..., -0.0051,  0.0038,  0.0134],\n",
       "         [-0.0123, -0.0175,  0.0008,  ...,  0.0132, -0.0053,  0.0253],\n",
       "         ...,\n",
       "         [-0.0132,  0.0172, -0.0043,  ..., -0.0082, -0.0099, -0.0192],\n",
       "         [-0.0049, -0.0266,  0.0064,  ...,  0.0101, -0.0021, -0.0046],\n",
       "         [ 0.0017, -0.0171,  0.0298,  ..., -0.0135, -0.0089, -0.0142]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.27.feed_forward.w3.weight': tensor([[-1.0986e-02,  1.9409e-02,  7.2021e-03,  ..., -3.5400e-03,\n",
       "          -1.2207e-02, -2.3560e-02],\n",
       "         [-1.9775e-02, -1.1719e-02, -4.3640e-03,  ..., -2.1729e-02,\n",
       "          -7.9346e-03, -1.6602e-02],\n",
       "         [-5.2795e-03,  2.4128e-04, -1.3794e-02,  ...,  2.9907e-03,\n",
       "           2.3041e-03,  1.8358e-05],\n",
       "         ...,\n",
       "         [-2.3438e-02, -7.0953e-04,  9.8877e-03,  ..., -6.2866e-03,\n",
       "          -1.4832e-02, -1.2268e-02],\n",
       "         [-8.1787e-03,  1.7456e-02,  4.1199e-03,  ..., -2.3746e-04,\n",
       "          -2.6855e-02,  2.0996e-02],\n",
       "         [-9.7046e-03, -2.5330e-03,  1.5991e-02,  ..., -1.0315e-02,\n",
       "           1.0986e-03, -9.3994e-03]], dtype=torch.bfloat16),\n",
       " 'layers.27.feed_forward.w2.weight': tensor([[-1.1902e-02,  1.5259e-02,  1.7471e-03,  ..., -3.9368e-03,\n",
       "          -4.7607e-03,  9.8419e-04],\n",
       "         [-2.7313e-03, -1.7929e-03, -5.5542e-03,  ...,  4.5776e-03,\n",
       "           1.2512e-02,  9.3384e-03],\n",
       "         [-9.0790e-04,  7.2327e-03,  2.8534e-03,  ..., -6.7749e-03,\n",
       "          -4.6082e-03,  7.2632e-03],\n",
       "         ...,\n",
       "         [-1.7212e-02,  1.5137e-02, -8.6975e-04,  ...,  8.6670e-03,\n",
       "          -4.8828e-03,  3.3112e-03],\n",
       "         [ 2.8229e-03, -1.1658e-02,  8.7261e-05,  ...,  1.2024e-02,\n",
       "          -1.0376e-02, -1.3885e-03],\n",
       "         [-3.5706e-03, -8.0566e-03,  1.2634e-02,  ...,  8.9111e-03,\n",
       "           4.6158e-04, -9.8877e-03]], dtype=torch.bfloat16),\n",
       " 'layers.27.attention_norm.weight': tensor([0.5312, 0.5312, 0.4980,  ..., 0.5352, 0.4844, 0.5117],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.27.ffn_norm.weight': tensor([0.5469, 0.5547, 0.5547,  ..., 0.5469, 0.5586, 0.5508],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.28.attention.wq.weight': tensor([[ 0.0060,  0.0011, -0.0132,  ..., -0.0084,  0.0044,  0.0067],\n",
       "         [ 0.0125, -0.0039,  0.0150,  ..., -0.0088,  0.0055, -0.0063],\n",
       "         [ 0.0197, -0.0201,  0.0016,  ..., -0.0129, -0.0176, -0.0154],\n",
       "         ...,\n",
       "         [ 0.0081,  0.0359,  0.0156,  ..., -0.0015, -0.0052,  0.0219],\n",
       "         [ 0.0003,  0.0220,  0.0104,  ...,  0.0087,  0.0070, -0.0035],\n",
       "         [-0.0044, -0.0147, -0.0012,  ..., -0.0206,  0.0090,  0.0184]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.28.attention.wk.weight': tensor([[-0.0194,  0.0260,  0.0017,  ..., -0.0154,  0.0156, -0.0058],\n",
       "         [ 0.0140,  0.0074, -0.0309,  ..., -0.0266, -0.0157, -0.0011],\n",
       "         [-0.0063,  0.0108, -0.0228,  ...,  0.0126, -0.0016, -0.0064],\n",
       "         ...,\n",
       "         [-0.0378,  0.0077,  0.0405,  ...,  0.0099, -0.0381, -0.0094],\n",
       "         [-0.0060,  0.0215, -0.0030,  ...,  0.0017, -0.0256, -0.0050],\n",
       "         [ 0.0177,  0.0173, -0.0408,  ..., -0.0349, -0.0030, -0.0153]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.28.attention.wv.weight': tensor([[-0.0030,  0.0049,  0.0059,  ..., -0.0233,  0.0186,  0.0320],\n",
       "         [-0.0205,  0.0013, -0.0034,  ...,  0.0035, -0.0239,  0.0074],\n",
       "         [-0.0337, -0.0140, -0.0188,  ..., -0.0023,  0.0123,  0.0153],\n",
       "         ...,\n",
       "         [ 0.0053,  0.0061,  0.0138,  ...,  0.0054, -0.0063,  0.0013],\n",
       "         [ 0.0042,  0.0208, -0.0109,  ...,  0.0021,  0.0112, -0.0051],\n",
       "         [-0.0139, -0.0220,  0.0043,  ...,  0.0143,  0.0067, -0.0220]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.28.attention.wo.weight': tensor([[ 0.0005, -0.0168, -0.0371,  ..., -0.0074, -0.0049,  0.0132],\n",
       "         [ 0.0088, -0.0069, -0.0143,  ...,  0.0135, -0.0031, -0.0104],\n",
       "         [ 0.0058, -0.0031, -0.0221,  ...,  0.0149, -0.0272,  0.0036],\n",
       "         ...,\n",
       "         [-0.0134,  0.0034, -0.0057,  ..., -0.0016,  0.0062, -0.0041],\n",
       "         [ 0.0217, -0.0232, -0.0002,  ..., -0.0267,  0.0211,  0.0115],\n",
       "         [ 0.0219,  0.0132,  0.0092,  ...,  0.0069, -0.0044, -0.0325]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.28.feed_forward.w1.weight': tensor([[-2.2705e-02,  8.3008e-03, -1.2817e-02,  ..., -4.3335e-03,\n",
       "          -1.2451e-02,  1.2817e-02],\n",
       "         [-7.5684e-03,  7.9956e-03,  9.5215e-03,  ...,  8.1177e-03,\n",
       "          -1.3184e-02, -9.5215e-03],\n",
       "         [ 1.1963e-02, -3.3875e-03,  2.0752e-02,  ...,  1.9409e-02,\n",
       "          -2.9785e-02, -8.2970e-05],\n",
       "         ...,\n",
       "         [ 1.6113e-02, -1.4771e-02,  7.7209e-03,  ...,  1.3245e-02,\n",
       "           1.8997e-03, -1.0864e-02],\n",
       "         [ 1.6846e-02, -2.6489e-02, -1.9897e-02,  ...,  1.0803e-02,\n",
       "           4.7302e-03, -7.7209e-03],\n",
       "         [ 1.7578e-02,  1.8555e-02, -1.1597e-02,  ...,  2.0264e-02,\n",
       "           3.5645e-02, -7.4387e-04]], dtype=torch.bfloat16),\n",
       " 'layers.28.feed_forward.w3.weight': tensor([[ 0.0071, -0.0216, -0.0050,  ..., -0.0027, -0.0156,  0.0055],\n",
       "         [ 0.0067, -0.0032, -0.0076,  ...,  0.0098,  0.0164,  0.0025],\n",
       "         [-0.0063, -0.0052, -0.0107,  ..., -0.0002, -0.0189,  0.0045],\n",
       "         ...,\n",
       "         [-0.0119, -0.0102,  0.0009,  ..., -0.0132,  0.0022, -0.0092],\n",
       "         [ 0.0002, -0.0127, -0.0075,  ..., -0.0057, -0.0058,  0.0073],\n",
       "         [-0.0058, -0.0084, -0.0045,  ..., -0.0074, -0.0005, -0.0065]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.28.feed_forward.w2.weight': tensor([[-0.0016, -0.0055, -0.0036,  ...,  0.0153,  0.0047,  0.0009],\n",
       "         [ 0.0011,  0.0033,  0.0102,  ..., -0.0054, -0.0042, -0.0249],\n",
       "         [-0.0088, -0.0137,  0.0020,  ..., -0.0056, -0.0008,  0.0126],\n",
       "         ...,\n",
       "         [-0.0198, -0.0297,  0.0035,  ..., -0.0005,  0.0093, -0.0146],\n",
       "         [ 0.0095,  0.0020,  0.0098,  ..., -0.0147,  0.0022, -0.0024],\n",
       "         [ 0.0004, -0.0019,  0.0129,  ..., -0.0126,  0.0005, -0.0041]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.28.attention_norm.weight': tensor([0.5039, 0.5156, 0.4941,  ..., 0.5156, 0.4902, 0.4922],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.28.ffn_norm.weight': tensor([0.5742, 0.5820, 0.5820,  ..., 0.5742, 0.5820, 0.5781],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.29.attention.wq.weight': tensor([[-0.0386, -0.0118,  0.0041,  ..., -0.0248, -0.0177, -0.0087],\n",
       "         [-0.0030, -0.0017, -0.0117,  ..., -0.0430, -0.0081,  0.0260],\n",
       "         [ 0.0142,  0.0168, -0.0139,  ...,  0.0189, -0.0004, -0.0011],\n",
       "         ...,\n",
       "         [ 0.0189, -0.0156,  0.0004,  ...,  0.0159,  0.0034, -0.0347],\n",
       "         [-0.0283, -0.0104,  0.0162,  ..., -0.0149, -0.0156, -0.0016],\n",
       "         [ 0.0093, -0.0033,  0.0004,  ...,  0.0188,  0.0070,  0.0039]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.29.attention.wk.weight': tensor([[-0.0131,  0.0039, -0.0099,  ..., -0.0234, -0.0107,  0.0095],\n",
       "         [ 0.0320, -0.0286, -0.0106,  ...,  0.0184, -0.0261,  0.0347],\n",
       "         [-0.0192,  0.0142,  0.0243,  ..., -0.0126, -0.0156, -0.0190],\n",
       "         ...,\n",
       "         [ 0.0081,  0.0001, -0.0071,  ..., -0.0005, -0.0288,  0.0248],\n",
       "         [-0.0271,  0.0056,  0.0008,  ..., -0.0101, -0.0151, -0.0078],\n",
       "         [-0.0024,  0.0356, -0.0106,  ..., -0.0256, -0.0043,  0.0234]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.29.attention.wv.weight': tensor([[ 0.0111, -0.0080,  0.0097,  ...,  0.0281, -0.0135,  0.0139],\n",
       "         [ 0.0039, -0.0102, -0.0322,  ..., -0.0061, -0.0118, -0.0010],\n",
       "         [-0.0036,  0.0225, -0.0038,  ...,  0.0034, -0.0228, -0.0141],\n",
       "         ...,\n",
       "         [-0.0294, -0.0291, -0.0046,  ...,  0.0017,  0.0124, -0.0054],\n",
       "         [ 0.0165, -0.0023, -0.0095,  ...,  0.0026, -0.0056,  0.0098],\n",
       "         [ 0.0143,  0.0126, -0.0144,  ..., -0.0078,  0.0154, -0.0161]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.29.attention.wo.weight': tensor([[-3.0518e-02,  1.5991e-02,  3.2806e-03,  ..., -7.9346e-03,\n",
       "           5.7373e-03,  1.7456e-02],\n",
       "         [ 1.3428e-02,  1.1414e-02, -5.1270e-03,  ..., -1.4771e-02,\n",
       "          -7.0496e-03,  7.4463e-03],\n",
       "         [-2.7100e-02,  9.0332e-03,  2.2793e-04,  ..., -3.6621e-03,\n",
       "          -2.8992e-03,  4.6997e-03],\n",
       "         ...,\n",
       "         [ 1.0132e-02, -4.1504e-03, -3.3569e-03,  ...,  1.0620e-02,\n",
       "          -6.2866e-03, -1.0620e-02],\n",
       "         [-4.1962e-05, -1.3428e-02, -9.2773e-03,  ...,  1.5625e-02,\n",
       "          -1.1047e-02,  1.2207e-02],\n",
       "         [ 2.0142e-02,  4.8065e-04,  4.3030e-03,  ..., -2.0599e-03,\n",
       "           8.8501e-03,  7.2479e-04]], dtype=torch.bfloat16),\n",
       " 'layers.29.feed_forward.w1.weight': tensor([[ 0.0045, -0.0500,  0.0121,  ..., -0.0118,  0.0116,  0.0214],\n",
       "         [ 0.0137, -0.0143,  0.0153,  ..., -0.0095,  0.0008,  0.0115],\n",
       "         [ 0.0026, -0.0131, -0.0190,  ...,  0.0107,  0.0106, -0.0261],\n",
       "         ...,\n",
       "         [ 0.0010,  0.0203,  0.0055,  ..., -0.0288,  0.0269, -0.0010],\n",
       "         [ 0.0094, -0.0095, -0.0120,  ..., -0.0095, -0.0203, -0.0041],\n",
       "         [ 0.0154, -0.0099, -0.0074,  ...,  0.0031, -0.0033,  0.0033]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.29.feed_forward.w3.weight': tensor([[ 0.0236, -0.0058, -0.0074,  ...,  0.0032, -0.0110,  0.0134],\n",
       "         [ 0.0161,  0.0043, -0.0152,  ..., -0.0008, -0.0189, -0.0090],\n",
       "         [-0.0153, -0.0067, -0.0087,  ..., -0.0055,  0.0071,  0.0095],\n",
       "         ...,\n",
       "         [-0.0003, -0.0139,  0.0195,  ...,  0.0039,  0.0214, -0.0041],\n",
       "         [ 0.0172,  0.0143, -0.0072,  ...,  0.0088,  0.0029, -0.0062],\n",
       "         [-0.0198,  0.0262, -0.0005,  ...,  0.0038, -0.0150, -0.0057]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.29.feed_forward.w2.weight': tensor([[-0.0101, -0.0014,  0.0172,  ...,  0.0034, -0.0042,  0.0026],\n",
       "         [ 0.0184, -0.0133, -0.0010,  ...,  0.0115, -0.0079,  0.0020],\n",
       "         [-0.0065, -0.0029,  0.0104,  ...,  0.0216,  0.0052,  0.0058],\n",
       "         ...,\n",
       "         [-0.0018,  0.0022, -0.0221,  ..., -0.0037,  0.0166,  0.0008],\n",
       "         [ 0.0039,  0.0076, -0.0014,  ...,  0.0195,  0.0226,  0.0036],\n",
       "         [-0.0112, -0.0087,  0.0076,  ..., -0.0095,  0.0276, -0.0228]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.29.attention_norm.weight': tensor([0.4590, 0.5547, 0.5391,  ..., 0.5234, 0.4922, 0.5391],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.29.ffn_norm.weight': tensor([0.5859, 0.5859, 0.5938,  ..., 0.5820, 0.5938, 0.5938],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.30.attention.wq.weight': tensor([[ 0.0195,  0.0017,  0.0204,  ...,  0.0113, -0.0078, -0.0062],\n",
       "         [ 0.0089,  0.0052,  0.0134,  ..., -0.0249,  0.0053,  0.0134],\n",
       "         [ 0.0200, -0.0505,  0.0162,  ...,  0.0033,  0.0289,  0.0164],\n",
       "         ...,\n",
       "         [-0.0356, -0.0176,  0.0132,  ..., -0.0030, -0.0120,  0.0064],\n",
       "         [-0.0104,  0.0010, -0.0145,  ..., -0.0035,  0.0287, -0.0150],\n",
       "         [-0.0181, -0.0128,  0.0075,  ..., -0.0259, -0.0097, -0.0204]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.30.attention.wk.weight': tensor([[-9.7046e-03,  3.6133e-02, -1.1368e-03,  ..., -1.9287e-02,\n",
       "          -1.0986e-02,  1.9897e-02],\n",
       "         [-8.5449e-03,  1.1719e-02,  1.4099e-02,  ..., -2.6703e-03,\n",
       "           5.3101e-03, -3.2959e-02],\n",
       "         [ 1.3855e-02,  1.5945e-03,  1.3489e-02,  ...,  6.8054e-03,\n",
       "          -7.5989e-03,  3.1738e-02],\n",
       "         ...,\n",
       "         [ 9.9487e-03,  5.2490e-03, -3.0640e-02,  ...,  2.4780e-02,\n",
       "           2.0874e-02, -5.7678e-03],\n",
       "         [-6.5002e-03, -2.1057e-03, -4.2419e-03,  ...,  1.3000e-02,\n",
       "          -9.7046e-03,  7.5684e-03],\n",
       "         [ 4.2419e-03, -3.8147e-05,  1.4267e-03,  ..., -1.4893e-02,\n",
       "           8.3008e-03,  5.1270e-03]], dtype=torch.bfloat16),\n",
       " 'layers.30.attention.wv.weight': tensor([[-0.0198, -0.0221, -0.0149,  ...,  0.0137, -0.0361, -0.0366],\n",
       "         [ 0.0120, -0.0002, -0.0225,  ...,  0.0342, -0.0047,  0.0143],\n",
       "         [-0.0060,  0.0251,  0.0337,  ..., -0.0138, -0.0311, -0.0157],\n",
       "         ...,\n",
       "         [-0.0177, -0.0062,  0.0349,  ..., -0.0155,  0.0074, -0.0052],\n",
       "         [-0.0222, -0.0168, -0.0194,  ...,  0.0031,  0.0149, -0.0178],\n",
       "         [-0.0233, -0.0140, -0.0226,  ...,  0.0298,  0.0171,  0.0133]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.30.attention.wo.weight': tensor([[ 0.0182, -0.0138,  0.0059,  ..., -0.0140,  0.0135, -0.0138],\n",
       "         [ 0.0096, -0.0120, -0.0167,  ..., -0.0059, -0.0154, -0.0144],\n",
       "         [ 0.0050,  0.0188, -0.0312,  ...,  0.0145, -0.0201,  0.0299],\n",
       "         ...,\n",
       "         [-0.0124, -0.0277,  0.0074,  ..., -0.0139, -0.0011,  0.0015],\n",
       "         [ 0.0247,  0.0018,  0.0260,  ...,  0.0069,  0.0240, -0.0034],\n",
       "         [ 0.0134, -0.0101,  0.0103,  ..., -0.0089, -0.0278, -0.0074]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.30.feed_forward.w1.weight': tensor([[-0.0029, -0.0140, -0.0122,  ..., -0.0042, -0.0036, -0.0004],\n",
       "         [ 0.0029,  0.0089, -0.0187,  ...,  0.0084,  0.0089, -0.0066],\n",
       "         [-0.0041, -0.0040, -0.0035,  ..., -0.0008,  0.0134, -0.0039],\n",
       "         ...,\n",
       "         [-0.0104,  0.0121, -0.0111,  ...,  0.0114,  0.0067,  0.0059],\n",
       "         [-0.0060, -0.0074, -0.0103,  ...,  0.0027, -0.0070,  0.0056],\n",
       "         [-0.0126, -0.0140, -0.0204,  ...,  0.0132,  0.0071, -0.0013]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.30.feed_forward.w3.weight': tensor([[ 7.5684e-03, -3.0975e-03, -1.7014e-03,  ...,  5.5847e-03,\n",
       "          -6.8188e-05,  3.7537e-03],\n",
       "         [-7.6599e-03, -5.8289e-03, -2.0630e-02,  ...,  2.7161e-03,\n",
       "           2.7466e-03, -3.0670e-03],\n",
       "         [-1.5198e-02,  9.3384e-03,  1.6724e-02,  ..., -7.3242e-03,\n",
       "          -5.2490e-03, -5.2795e-03],\n",
       "         ...,\n",
       "         [-1.9455e-03,  1.2512e-02,  1.3916e-02,  ...,  8.6975e-04,\n",
       "           5.6152e-03, -3.3569e-03],\n",
       "         [ 1.5442e-02,  8.6060e-03, -2.0752e-02,  ...,  2.0294e-03,\n",
       "          -9.0408e-04, -3.0212e-03],\n",
       "         [-2.1210e-03,  2.2278e-03, -4.6082e-03,  ...,  9.4604e-03,\n",
       "           3.4790e-03, -1.0254e-02]], dtype=torch.bfloat16),\n",
       " 'layers.30.feed_forward.w2.weight': tensor([[-0.0170, -0.0019,  0.0036,  ...,  0.0175, -0.0195,  0.0165],\n",
       "         [-0.0004, -0.0063, -0.0132,  ..., -0.0271, -0.0019, -0.0010],\n",
       "         [-0.0030,  0.0039, -0.0120,  ..., -0.0139, -0.0109, -0.0082],\n",
       "         ...,\n",
       "         [ 0.0028,  0.0077,  0.0060,  ...,  0.0058, -0.0063,  0.0063],\n",
       "         [ 0.0004, -0.0068, -0.0044,  ...,  0.0193,  0.0233,  0.0200],\n",
       "         [ 0.0069, -0.0028,  0.0061,  ...,  0.0107, -0.0238,  0.0052]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.30.attention_norm.weight': tensor([0.5000, 0.5000, 0.4766,  ..., 0.5078, 0.4727, 0.4531],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.30.ffn_norm.weight': tensor([0.6016, 0.5938, 0.5898,  ..., 0.5898, 0.6094, 0.5938],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.31.attention.wq.weight': tensor([[ 0.0084, -0.0035,  0.0079,  ..., -0.0007, -0.0014, -0.0020],\n",
       "         [-0.0140,  0.0139, -0.0068,  ...,  0.0085, -0.0004, -0.0014],\n",
       "         [ 0.0031, -0.0016,  0.0134,  ..., -0.0160, -0.0038,  0.0012],\n",
       "         ...,\n",
       "         [-0.0179, -0.0249,  0.0108,  ..., -0.0344,  0.0024, -0.0222],\n",
       "         [-0.0077, -0.0122, -0.0101,  ..., -0.0120, -0.0177,  0.0289],\n",
       "         [-0.0039, -0.0171,  0.0114,  ...,  0.0022, -0.0006, -0.0007]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.31.attention.wk.weight': tensor([[ 0.0126, -0.0272,  0.0303,  ...,  0.0481, -0.0062,  0.0065],\n",
       "         [-0.0189, -0.0044, -0.0088,  ..., -0.0052,  0.0300,  0.0415],\n",
       "         [-0.0266, -0.0155, -0.0435,  ..., -0.0216, -0.0515,  0.0091],\n",
       "         ...,\n",
       "         [ 0.0312,  0.0232,  0.0240,  ..., -0.0170, -0.0284, -0.0432],\n",
       "         [ 0.0457, -0.0337,  0.0067,  ..., -0.0342,  0.0306, -0.0156],\n",
       "         [-0.0092,  0.0048,  0.0143,  ..., -0.0170, -0.0391,  0.0198]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.31.attention.wv.weight': tensor([[ 0.0171,  0.0178, -0.0027,  ..., -0.0255, -0.0188,  0.0130],\n",
       "         [-0.0052,  0.0041, -0.0131,  ..., -0.0074,  0.0082, -0.0030],\n",
       "         [-0.0427, -0.0253, -0.0144,  ..., -0.0292,  0.0300, -0.0129],\n",
       "         ...,\n",
       "         [ 0.0076,  0.0003, -0.0002,  ...,  0.0096, -0.0047, -0.0043],\n",
       "         [-0.0016, -0.0041, -0.0073,  ..., -0.0107, -0.0015, -0.0214],\n",
       "         [-0.0231,  0.0022,  0.0057,  ...,  0.0069, -0.0096, -0.0069]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.31.attention.wo.weight': tensor([[ 0.0199, -0.0128, -0.0223,  ...,  0.0118, -0.0031,  0.0134],\n",
       "         [ 0.0003, -0.0035, -0.0044,  ...,  0.0014, -0.0001,  0.0105],\n",
       "         [-0.0073,  0.0129, -0.0082,  ..., -0.0009,  0.0072, -0.0061],\n",
       "         ...,\n",
       "         [ 0.0019,  0.0116, -0.0045,  ..., -0.0007, -0.0011,  0.0127],\n",
       "         [-0.0167,  0.0031,  0.0167,  ..., -0.0004, -0.0119,  0.0073],\n",
       "         [ 0.0179, -0.0021,  0.0160,  ..., -0.0198,  0.0091, -0.0002]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.31.feed_forward.w1.weight': tensor([[-1.4160e-02,  1.5503e-02, -2.3071e-02,  ...,  1.3855e-02,\n",
       "           4.3640e-03,  6.8054e-03],\n",
       "         [-8.6212e-04,  7.7209e-03,  7.7209e-03,  ...,  1.5381e-02,\n",
       "           7.3547e-03,  1.2207e-02],\n",
       "         [-1.1169e-02,  2.0264e-02, -1.4099e-02,  ...,  6.4697e-03,\n",
       "          -7.1411e-03, -9.1553e-05],\n",
       "         ...,\n",
       "         [ 5.4016e-03, -3.8452e-03,  2.5879e-02,  ...,  2.7161e-03,\n",
       "           1.7700e-02,  1.7700e-02],\n",
       "         [-1.7822e-02, -1.7822e-02,  5.0964e-03,  ...,  1.3245e-02,\n",
       "          -8.7280e-03, -1.1108e-02],\n",
       "         [-2.7222e-02, -2.6855e-02, -2.3560e-02,  ...,  3.6865e-02,\n",
       "           3.9062e-02,  8.4839e-03]], dtype=torch.bfloat16),\n",
       " 'layers.31.feed_forward.w3.weight': tensor([[-1.6602e-02, -2.5146e-02, -5.6152e-03,  ...,  1.8188e-02,\n",
       "          -7.7820e-03,  9.3994e-03],\n",
       "         [ 6.1951e-03,  1.6861e-03,  1.2390e-02,  ...,  7.6599e-03,\n",
       "           3.4180e-02, -2.9602e-03],\n",
       "         [ 4.8828e-03,  2.5330e-03,  5.7678e-03,  ..., -8.8501e-03,\n",
       "           1.4343e-02, -2.2095e-02],\n",
       "         ...,\n",
       "         [ 2.6245e-02,  1.7929e-03,  1.8677e-02,  ...,  4.8828e-03,\n",
       "           1.1108e-02, -3.4571e-05],\n",
       "         [-4.8218e-03,  1.3367e-02, -8.7280e-03,  ...,  6.3171e-03,\n",
       "           1.1292e-03,  1.1841e-02],\n",
       "         [ 9.5825e-03, -1.3855e-02, -2.0294e-03,  ..., -4.5776e-03,\n",
       "          -3.0670e-03, -9.1553e-03]], dtype=torch.bfloat16),\n",
       " 'layers.31.feed_forward.w2.weight': tensor([[-0.0344,  0.0157,  0.0188,  ...,  0.0018,  0.0121,  0.0007],\n",
       "         [-0.0042, -0.0064,  0.0035,  ..., -0.0035,  0.0032, -0.0089],\n",
       "         [-0.0090, -0.0223, -0.0219,  ...,  0.0029, -0.0059, -0.0084],\n",
       "         ...,\n",
       "         [ 0.0126,  0.0019, -0.0042,  ..., -0.0164, -0.0074,  0.0112],\n",
       "         [-0.0132,  0.0069,  0.0142,  ..., -0.0195,  0.0114,  0.0111],\n",
       "         [-0.0074, -0.0138,  0.0107,  ...,  0.0106,  0.0027,  0.0029]],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.31.attention_norm.weight': tensor([0.4648, 0.4004, 0.4453,  ..., 0.4297, 0.3906, 0.3008],\n",
       "        dtype=torch.bfloat16),\n",
       " 'layers.31.ffn_norm.weight': tensor([0.5273, 0.4902, 0.5078,  ..., 0.5273, 0.4883, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'norm.weight': tensor([2.6562, 2.5781, 2.6094,  ..., 2.5938, 2.2656, 2.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'output.weight': tensor([[ 0.0099,  0.0173,  0.0034,  ...,  0.0007, -0.0168, -0.0110],\n",
       "         [-0.0069,  0.0117,  0.0112,  ..., -0.0085,  0.0091, -0.0015],\n",
       "         [ 0.0143,  0.0096,  0.0089,  ..., -0.0024, -0.0062, -0.0142],\n",
       "         ...,\n",
       "         [-0.0034,  0.0020,  0.0058,  ...,  0.0015,  0.0059,  0.0069],\n",
       "         [-0.0034,  0.0020,  0.0058,  ...,  0.0015,  0.0059,  0.0069],\n",
       "         [-0.0034,  0.0020,  0.0058,  ...,  0.0015,  0.0059,  0.0069]],\n",
       "        dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "model_dict = torch.load('./8B-Instruct.local/consolidated.00.pth', map_location=\"cpu\")\n",
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_embeddings.weight\n",
      "layers.0.attention.wq.weight\n",
      "layers.0.attention.wk.weight\n",
      "layers.0.attention.wv.weight\n",
      "layers.0.attention.wo.weight\n",
      "layers.0.feed_forward.w1.weight\n",
      "layers.0.feed_forward.w3.weight\n",
      "layers.0.feed_forward.w2.weight\n",
      "layers.0.attention_norm.weight\n",
      "layers.0.ffn_norm.weight\n",
      "layers.1.attention.wq.weight\n",
      "layers.1.attention.wk.weight\n",
      "layers.1.attention.wv.weight\n",
      "layers.1.attention.wo.weight\n",
      "layers.1.feed_forward.w1.weight\n",
      "layers.1.feed_forward.w3.weight\n",
      "layers.1.feed_forward.w2.weight\n",
      "layers.1.attention_norm.weight\n",
      "layers.1.ffn_norm.weight\n",
      "layers.2.attention.wq.weight\n",
      "layers.2.attention.wk.weight\n",
      "layers.2.attention.wv.weight\n",
      "layers.2.attention.wo.weight\n",
      "layers.2.feed_forward.w1.weight\n",
      "layers.2.feed_forward.w3.weight\n",
      "layers.2.feed_forward.w2.weight\n",
      "layers.2.attention_norm.weight\n",
      "layers.2.ffn_norm.weight\n",
      "layers.3.attention.wq.weight\n",
      "layers.3.attention.wk.weight\n",
      "layers.3.attention.wv.weight\n",
      "layers.3.attention.wo.weight\n",
      "layers.3.feed_forward.w1.weight\n",
      "layers.3.feed_forward.w3.weight\n",
      "layers.3.feed_forward.w2.weight\n",
      "layers.3.attention_norm.weight\n",
      "layers.3.ffn_norm.weight\n",
      "layers.4.attention.wq.weight\n",
      "layers.4.attention.wk.weight\n",
      "layers.4.attention.wv.weight\n",
      "layers.4.attention.wo.weight\n",
      "layers.4.feed_forward.w1.weight\n",
      "layers.4.feed_forward.w3.weight\n",
      "layers.4.feed_forward.w2.weight\n",
      "layers.4.attention_norm.weight\n",
      "layers.4.ffn_norm.weight\n",
      "layers.5.attention.wq.weight\n",
      "layers.5.attention.wk.weight\n",
      "layers.5.attention.wv.weight\n",
      "layers.5.attention.wo.weight\n",
      "layers.5.feed_forward.w1.weight\n",
      "layers.5.feed_forward.w3.weight\n",
      "layers.5.feed_forward.w2.weight\n",
      "layers.5.attention_norm.weight\n",
      "layers.5.ffn_norm.weight\n",
      "layers.6.attention.wq.weight\n",
      "layers.6.attention.wk.weight\n",
      "layers.6.attention.wv.weight\n",
      "layers.6.attention.wo.weight\n",
      "layers.6.feed_forward.w1.weight\n",
      "layers.6.feed_forward.w3.weight\n",
      "layers.6.feed_forward.w2.weight\n",
      "layers.6.attention_norm.weight\n",
      "layers.6.ffn_norm.weight\n",
      "layers.7.attention.wq.weight\n",
      "layers.7.attention.wk.weight\n",
      "layers.7.attention.wv.weight\n",
      "layers.7.attention.wo.weight\n",
      "layers.7.feed_forward.w1.weight\n",
      "layers.7.feed_forward.w3.weight\n",
      "layers.7.feed_forward.w2.weight\n",
      "layers.7.attention_norm.weight\n",
      "layers.7.ffn_norm.weight\n",
      "layers.8.attention.wq.weight\n",
      "layers.8.attention.wk.weight\n",
      "layers.8.attention.wv.weight\n",
      "layers.8.attention.wo.weight\n",
      "layers.8.feed_forward.w1.weight\n",
      "layers.8.feed_forward.w3.weight\n",
      "layers.8.feed_forward.w2.weight\n",
      "layers.8.attention_norm.weight\n",
      "layers.8.ffn_norm.weight\n",
      "layers.9.attention.wq.weight\n",
      "layers.9.attention.wk.weight\n",
      "layers.9.attention.wv.weight\n",
      "layers.9.attention.wo.weight\n",
      "layers.9.feed_forward.w1.weight\n",
      "layers.9.feed_forward.w3.weight\n",
      "layers.9.feed_forward.w2.weight\n",
      "layers.9.attention_norm.weight\n",
      "layers.9.ffn_norm.weight\n",
      "layers.10.attention.wq.weight\n",
      "layers.10.attention.wk.weight\n",
      "layers.10.attention.wv.weight\n",
      "layers.10.attention.wo.weight\n",
      "layers.10.feed_forward.w1.weight\n",
      "layers.10.feed_forward.w3.weight\n",
      "layers.10.feed_forward.w2.weight\n",
      "layers.10.attention_norm.weight\n",
      "layers.10.ffn_norm.weight\n",
      "layers.11.attention.wq.weight\n",
      "layers.11.attention.wk.weight\n",
      "layers.11.attention.wv.weight\n",
      "layers.11.attention.wo.weight\n",
      "layers.11.feed_forward.w1.weight\n",
      "layers.11.feed_forward.w3.weight\n",
      "layers.11.feed_forward.w2.weight\n",
      "layers.11.attention_norm.weight\n",
      "layers.11.ffn_norm.weight\n",
      "layers.12.attention.wq.weight\n",
      "layers.12.attention.wk.weight\n",
      "layers.12.attention.wv.weight\n",
      "layers.12.attention.wo.weight\n",
      "layers.12.feed_forward.w1.weight\n",
      "layers.12.feed_forward.w3.weight\n",
      "layers.12.feed_forward.w2.weight\n",
      "layers.12.attention_norm.weight\n",
      "layers.12.ffn_norm.weight\n",
      "layers.13.attention.wq.weight\n",
      "layers.13.attention.wk.weight\n",
      "layers.13.attention.wv.weight\n",
      "layers.13.attention.wo.weight\n",
      "layers.13.feed_forward.w1.weight\n",
      "layers.13.feed_forward.w3.weight\n",
      "layers.13.feed_forward.w2.weight\n",
      "layers.13.attention_norm.weight\n",
      "layers.13.ffn_norm.weight\n",
      "layers.14.attention.wq.weight\n",
      "layers.14.attention.wk.weight\n",
      "layers.14.attention.wv.weight\n",
      "layers.14.attention.wo.weight\n",
      "layers.14.feed_forward.w1.weight\n",
      "layers.14.feed_forward.w3.weight\n",
      "layers.14.feed_forward.w2.weight\n",
      "layers.14.attention_norm.weight\n",
      "layers.14.ffn_norm.weight\n",
      "layers.15.attention.wq.weight\n",
      "layers.15.attention.wk.weight\n",
      "layers.15.attention.wv.weight\n",
      "layers.15.attention.wo.weight\n",
      "layers.15.feed_forward.w1.weight\n",
      "layers.15.feed_forward.w3.weight\n",
      "layers.15.feed_forward.w2.weight\n",
      "layers.15.attention_norm.weight\n",
      "layers.15.ffn_norm.weight\n",
      "layers.16.attention.wq.weight\n",
      "layers.16.attention.wk.weight\n",
      "layers.16.attention.wv.weight\n",
      "layers.16.attention.wo.weight\n",
      "layers.16.feed_forward.w1.weight\n",
      "layers.16.feed_forward.w3.weight\n",
      "layers.16.feed_forward.w2.weight\n",
      "layers.16.attention_norm.weight\n",
      "layers.16.ffn_norm.weight\n",
      "layers.17.attention.wq.weight\n",
      "layers.17.attention.wk.weight\n",
      "layers.17.attention.wv.weight\n",
      "layers.17.attention.wo.weight\n",
      "layers.17.feed_forward.w1.weight\n",
      "layers.17.feed_forward.w3.weight\n",
      "layers.17.feed_forward.w2.weight\n",
      "layers.17.attention_norm.weight\n",
      "layers.17.ffn_norm.weight\n",
      "layers.18.attention.wq.weight\n",
      "layers.18.attention.wk.weight\n",
      "layers.18.attention.wv.weight\n",
      "layers.18.attention.wo.weight\n",
      "layers.18.feed_forward.w1.weight\n",
      "layers.18.feed_forward.w3.weight\n",
      "layers.18.feed_forward.w2.weight\n",
      "layers.18.attention_norm.weight\n",
      "layers.18.ffn_norm.weight\n",
      "layers.19.attention.wq.weight\n",
      "layers.19.attention.wk.weight\n",
      "layers.19.attention.wv.weight\n",
      "layers.19.attention.wo.weight\n",
      "layers.19.feed_forward.w1.weight\n",
      "layers.19.feed_forward.w3.weight\n",
      "layers.19.feed_forward.w2.weight\n",
      "layers.19.attention_norm.weight\n",
      "layers.19.ffn_norm.weight\n",
      "layers.20.attention.wq.weight\n",
      "layers.20.attention.wk.weight\n",
      "layers.20.attention.wv.weight\n",
      "layers.20.attention.wo.weight\n",
      "layers.20.feed_forward.w1.weight\n",
      "layers.20.feed_forward.w3.weight\n",
      "layers.20.feed_forward.w2.weight\n",
      "layers.20.attention_norm.weight\n",
      "layers.20.ffn_norm.weight\n",
      "layers.21.attention.wq.weight\n",
      "layers.21.attention.wk.weight\n",
      "layers.21.attention.wv.weight\n",
      "layers.21.attention.wo.weight\n",
      "layers.21.feed_forward.w1.weight\n",
      "layers.21.feed_forward.w3.weight\n",
      "layers.21.feed_forward.w2.weight\n",
      "layers.21.attention_norm.weight\n",
      "layers.21.ffn_norm.weight\n",
      "layers.22.attention.wq.weight\n",
      "layers.22.attention.wk.weight\n",
      "layers.22.attention.wv.weight\n",
      "layers.22.attention.wo.weight\n",
      "layers.22.feed_forward.w1.weight\n",
      "layers.22.feed_forward.w3.weight\n",
      "layers.22.feed_forward.w2.weight\n",
      "layers.22.attention_norm.weight\n",
      "layers.22.ffn_norm.weight\n",
      "layers.23.attention.wq.weight\n",
      "layers.23.attention.wk.weight\n",
      "layers.23.attention.wv.weight\n",
      "layers.23.attention.wo.weight\n",
      "layers.23.feed_forward.w1.weight\n",
      "layers.23.feed_forward.w3.weight\n",
      "layers.23.feed_forward.w2.weight\n",
      "layers.23.attention_norm.weight\n",
      "layers.23.ffn_norm.weight\n",
      "layers.24.attention.wq.weight\n",
      "layers.24.attention.wk.weight\n",
      "layers.24.attention.wv.weight\n",
      "layers.24.attention.wo.weight\n",
      "layers.24.feed_forward.w1.weight\n",
      "layers.24.feed_forward.w3.weight\n",
      "layers.24.feed_forward.w2.weight\n",
      "layers.24.attention_norm.weight\n",
      "layers.24.ffn_norm.weight\n",
      "layers.25.attention.wq.weight\n",
      "layers.25.attention.wk.weight\n",
      "layers.25.attention.wv.weight\n",
      "layers.25.attention.wo.weight\n",
      "layers.25.feed_forward.w1.weight\n",
      "layers.25.feed_forward.w3.weight\n",
      "layers.25.feed_forward.w2.weight\n",
      "layers.25.attention_norm.weight\n",
      "layers.25.ffn_norm.weight\n",
      "layers.26.attention.wq.weight\n",
      "layers.26.attention.wk.weight\n",
      "layers.26.attention.wv.weight\n",
      "layers.26.attention.wo.weight\n",
      "layers.26.feed_forward.w1.weight\n",
      "layers.26.feed_forward.w3.weight\n",
      "layers.26.feed_forward.w2.weight\n",
      "layers.26.attention_norm.weight\n",
      "layers.26.ffn_norm.weight\n",
      "layers.27.attention.wq.weight\n",
      "layers.27.attention.wk.weight\n",
      "layers.27.attention.wv.weight\n",
      "layers.27.attention.wo.weight\n",
      "layers.27.feed_forward.w1.weight\n",
      "layers.27.feed_forward.w3.weight\n",
      "layers.27.feed_forward.w2.weight\n",
      "layers.27.attention_norm.weight\n",
      "layers.27.ffn_norm.weight\n",
      "layers.28.attention.wq.weight\n",
      "layers.28.attention.wk.weight\n",
      "layers.28.attention.wv.weight\n",
      "layers.28.attention.wo.weight\n",
      "layers.28.feed_forward.w1.weight\n",
      "layers.28.feed_forward.w3.weight\n",
      "layers.28.feed_forward.w2.weight\n",
      "layers.28.attention_norm.weight\n",
      "layers.28.ffn_norm.weight\n",
      "layers.29.attention.wq.weight\n",
      "layers.29.attention.wk.weight\n",
      "layers.29.attention.wv.weight\n",
      "layers.29.attention.wo.weight\n",
      "layers.29.feed_forward.w1.weight\n",
      "layers.29.feed_forward.w3.weight\n",
      "layers.29.feed_forward.w2.weight\n",
      "layers.29.attention_norm.weight\n",
      "layers.29.ffn_norm.weight\n",
      "layers.30.attention.wq.weight\n",
      "layers.30.attention.wk.weight\n",
      "layers.30.attention.wv.weight\n",
      "layers.30.attention.wo.weight\n",
      "layers.30.feed_forward.w1.weight\n",
      "layers.30.feed_forward.w3.weight\n",
      "layers.30.feed_forward.w2.weight\n",
      "layers.30.attention_norm.weight\n",
      "layers.30.ffn_norm.weight\n",
      "layers.31.attention.wq.weight\n",
      "layers.31.attention.wk.weight\n",
      "layers.31.attention.wv.weight\n",
      "layers.31.attention.wo.weight\n",
      "layers.31.feed_forward.w1.weight\n",
      "layers.31.feed_forward.w3.weight\n",
      "layers.31.feed_forward.w2.weight\n",
      "layers.31.attention_norm.weight\n",
      "layers.31.ffn_norm.weight\n",
      "norm.weight\n",
      "output.weight\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(model_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_embeddings.weight:\t525_336_576\ttorch.Size([128256, 4096])\n",
      "layers.0.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.0.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.0.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.0.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.0.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.0.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.0.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.0.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.0.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.1.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.1.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.1.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.1.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.1.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.1.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.1.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.1.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.1.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.2.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.2.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.2.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.2.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.2.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.2.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.2.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.2.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.2.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.3.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.3.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.3.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.3.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.3.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.3.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.3.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.3.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.3.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.4.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.4.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.4.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.4.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.4.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.4.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.4.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.4.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.4.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.5.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.5.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.5.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.5.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.5.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.5.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.5.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.5.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.5.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.6.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.6.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.6.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.6.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.6.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.6.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.6.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.6.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.6.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.7.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.7.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.7.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.7.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.7.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.7.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.7.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.7.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.7.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.8.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.8.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.8.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.8.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.8.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.8.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.8.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.8.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.8.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.9.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.9.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.9.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.9.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.9.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.9.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.9.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.9.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.9.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.10.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.10.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.10.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.10.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.10.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.10.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.10.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.10.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.10.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.11.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.11.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.11.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.11.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.11.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.11.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.11.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.11.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.11.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.12.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.12.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.12.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.12.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.12.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.12.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.12.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.12.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.12.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.13.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.13.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.13.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.13.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.13.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.13.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.13.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.13.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.13.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.14.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.14.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.14.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.14.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.14.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.14.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.14.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.14.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.14.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.15.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.15.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.15.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.15.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.15.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.15.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.15.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.15.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.15.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.16.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.16.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.16.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.16.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.16.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.16.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.16.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.16.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.16.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.17.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.17.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.17.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.17.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.17.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.17.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.17.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.17.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.17.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.18.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.18.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.18.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.18.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.18.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.18.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.18.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.18.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.18.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.19.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.19.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.19.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.19.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.19.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.19.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.19.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.19.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.19.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.20.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.20.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.20.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.20.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.20.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.20.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.20.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.20.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.20.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.21.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.21.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.21.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.21.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.21.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.21.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.21.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.21.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.21.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.22.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.22.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.22.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.22.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.22.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.22.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.22.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.22.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.22.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.23.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.23.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.23.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.23.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.23.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.23.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.23.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.23.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.23.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.24.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.24.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.24.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.24.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.24.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.24.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.24.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.24.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.24.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.25.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.25.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.25.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.25.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.25.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.25.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.25.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.25.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.25.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.26.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.26.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.26.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.26.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.26.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.26.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.26.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.26.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.26.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.27.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.27.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.27.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.27.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.27.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.27.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.27.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.27.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.27.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.28.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.28.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.28.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.28.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.28.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.28.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.28.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.28.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.28.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.29.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.29.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.29.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.29.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.29.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.29.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.29.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.29.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.29.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.30.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.30.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.30.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.30.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.30.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.30.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.30.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.30.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.30.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.31.attention.wq.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.31.attention.wk.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.31.attention.wv.weight:\t4_194_304\ttorch.Size([1024, 4096])\n",
      "layers.31.attention.wo.weight:\t16_777_216\ttorch.Size([4096, 4096])\n",
      "layers.31.feed_forward.w1.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.31.feed_forward.w3.weight:\t58_720_256\ttorch.Size([14336, 4096])\n",
      "layers.31.feed_forward.w2.weight:\t58_720_256\ttorch.Size([4096, 14336])\n",
      "layers.31.attention_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "layers.31.ffn_norm.weight:\t4_096\ttorch.Size([4096])\n",
      "norm.weight:\t4_096\ttorch.Size([4096])\n",
      "output.weight:\t525_336_576\ttorch.Size([128256, 4096])\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([f'{k}:\\t{model_dict[k].numel():_}\\t{model_dict[k].shape}' for k in model_dict.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14336, 4096])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w10 = model_dict['layers.0.feed_forward.w1.weight']\n",
    "w10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.570000e+03, 1.791000e+03, 2.207000e+03, 2.596000e+03,\n",
       "        2.942000e+03, 3.498000e+03, 4.187000e+03, 5.179000e+03,\n",
       "        7.689000e+03, 7.362000e+03, 9.221000e+03, 1.194100e+04,\n",
       "        1.411200e+04, 1.681700e+04, 2.081400e+04, 2.601000e+04,\n",
       "        3.122700e+04, 3.795100e+04, 5.846600e+04, 6.319900e+04,\n",
       "        7.393400e+04, 8.988600e+04, 1.146390e+05, 1.610990e+05,\n",
       "        1.707970e+05, 1.978080e+05, 2.437050e+05, 2.821690e+05,\n",
       "        3.253080e+05, 4.288450e+05, 4.519750e+05, 5.182990e+05,\n",
       "        5.825070e+05, 6.588200e+05, 8.428620e+05, 8.699910e+05,\n",
       "        1.051991e+06, 1.098946e+06, 1.191893e+06, 1.362735e+06,\n",
       "        1.388197e+06, 1.482712e+06, 1.683037e+06, 1.777007e+06,\n",
       "        1.847441e+06, 1.851044e+06, 2.015560e+06, 2.024870e+06,\n",
       "        2.094836e+06, 2.122247e+06, 2.125560e+06, 2.095558e+06,\n",
       "        2.024156e+06, 2.015530e+06, 1.852357e+06, 1.845704e+06,\n",
       "        1.779002e+06, 1.683303e+06, 1.485633e+06, 1.388300e+06,\n",
       "        1.364039e+06, 1.193268e+06, 1.099848e+06, 1.051842e+06,\n",
       "        8.706510e+05, 8.436000e+05, 6.617250e+05, 5.830300e+05,\n",
       "        5.183420e+05, 4.527600e+05, 4.286800e+05, 3.265710e+05,\n",
       "        2.831850e+05, 2.441140e+05, 1.984500e+05, 1.717860e+05,\n",
       "        1.610990e+05, 1.152760e+05, 9.054600e+04, 7.452100e+04,\n",
       "        6.336700e+04, 5.872800e+04, 3.808100e+04, 3.131700e+04,\n",
       "        2.612500e+04, 2.152700e+04, 1.706100e+04, 1.453900e+04,\n",
       "        1.208200e+04, 9.181000e+03, 7.525000e+03, 7.808000e+03,\n",
       "        5.202000e+03, 4.180000e+03, 3.468000e+03, 3.060000e+03,\n",
       "        2.776000e+03, 2.153000e+03, 1.671000e+03, 1.474000e+03]),\n",
       " array([-0.05 , -0.049, -0.048, -0.047, -0.046, -0.045, -0.044, -0.043,\n",
       "        -0.042, -0.041, -0.04 , -0.039, -0.038, -0.037, -0.036, -0.035,\n",
       "        -0.034, -0.033, -0.032, -0.031, -0.03 , -0.029, -0.028, -0.027,\n",
       "        -0.026, -0.025, -0.024, -0.023, -0.022, -0.021, -0.02 , -0.019,\n",
       "        -0.018, -0.017, -0.016, -0.015, -0.014, -0.013, -0.012, -0.011,\n",
       "        -0.01 , -0.009, -0.008, -0.007, -0.006, -0.005, -0.004, -0.003,\n",
       "        -0.002, -0.001,  0.   ,  0.001,  0.002,  0.003,  0.004,  0.005,\n",
       "         0.006,  0.007,  0.008,  0.009,  0.01 ,  0.011,  0.012,  0.013,\n",
       "         0.014,  0.015,  0.016,  0.017,  0.018,  0.019,  0.02 ,  0.021,\n",
       "         0.022,  0.023,  0.024,  0.025,  0.026,  0.027,  0.028,  0.029,\n",
       "         0.03 ,  0.031,  0.032,  0.033,  0.034,  0.035,  0.036,  0.037,\n",
       "         0.038,  0.039,  0.04 ,  0.041,  0.042,  0.043,  0.044,  0.045,\n",
       "         0.046,  0.047,  0.048,  0.049,  0.05 ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.hist(x=w10.flatten().float(), bins=100, range=(-0.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2493.,    3051.,    3365.,    5060.,    4456.,    5229.,\n",
       "           8011.,    6986.,    7879.,    8995.,   13634.,   13970.,\n",
       "          17365.,   20144.,   21235.,   28963.,   28772.,   41158.,\n",
       "          39549.,   52815.,   57445.,   76988.,   89770.,   91899.,\n",
       "         125116.,  131336.,  182256.,  182006.,  251190.,  251780.,\n",
       "         353437.,  430223.,  479345.,  574812.,  654745.,  775741.,\n",
       "         865377.,  990069., 1120257., 1246266., 1510964., 1594787.,\n",
       "        1741044., 1848193., 1971325., 2181923., 2219156., 2319789.,\n",
       "        2362959., 2391494., 2393321., 2364850., 2317078., 2217118.,\n",
       "        2178710., 1964163., 1840817., 1735759., 1585187., 1501193.,\n",
       "        1236046., 1110444.,  978871.,  858653.,  767368.,  648327.,\n",
       "         569597.,  474315.,  424749.,  349973.,  249599.,  248553.,\n",
       "         181170.,  179701.,  130268.,  124586.,   90946.,   90036.,\n",
       "          77537.,   56990.,   53007.,   39416.,   41360.,   28741.,\n",
       "          29298.,   20879.,   20095.,   17275.,   14035.,   13661.,\n",
       "           8880.,    7999.,    7024.,    7970.,    5109.,    4431.,\n",
       "           5075.,    3357.,    2917.,    2421.]),\n",
       " array([-0.08  , -0.0784, -0.0768, -0.0752, -0.0736, -0.072 , -0.0704,\n",
       "        -0.0688, -0.0672, -0.0656, -0.064 , -0.0624, -0.0608, -0.0592,\n",
       "        -0.0576, -0.056 , -0.0544, -0.0528, -0.0512, -0.0496, -0.048 ,\n",
       "        -0.0464, -0.0448, -0.0432, -0.0416, -0.04  , -0.0384, -0.0368,\n",
       "        -0.0352, -0.0336, -0.032 , -0.0304, -0.0288, -0.0272, -0.0256,\n",
       "        -0.024 , -0.0224, -0.0208, -0.0192, -0.0176, -0.016 , -0.0144,\n",
       "        -0.0128, -0.0112, -0.0096, -0.008 , -0.0064, -0.0048, -0.0032,\n",
       "        -0.0016,  0.    ,  0.0016,  0.0032,  0.0048,  0.0064,  0.008 ,\n",
       "         0.0096,  0.0112,  0.0128,  0.0144,  0.016 ,  0.0176,  0.0192,\n",
       "         0.0208,  0.0224,  0.024 ,  0.0256,  0.0272,  0.0288,  0.0304,\n",
       "         0.032 ,  0.0336,  0.0352,  0.0368,  0.0384,  0.04  ,  0.0416,\n",
       "         0.0432,  0.0448,  0.0464,  0.048 ,  0.0496,  0.0512,  0.0528,\n",
       "         0.0544,  0.056 ,  0.0576,  0.0592,  0.0608,  0.0624,  0.064 ,\n",
       "         0.0656,  0.0672,  0.0688,  0.0704,  0.072 ,  0.0736,  0.0752,\n",
       "         0.0768,  0.0784,  0.08  ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x=model_dict['layers.31.feed_forward.w1.weight'].flatten().float(), bins=100, range=(-0.08, 0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.600000e+02, 6.770000e+02, 7.990000e+02, 1.036000e+03,\n",
       "        1.129000e+03, 1.266000e+03, 1.520000e+03, 1.868000e+03,\n",
       "        2.943000e+03, 2.788000e+03, 3.554000e+03, 4.661000e+03,\n",
       "        5.901000e+03, 7.335000e+03, 9.252000e+03, 1.197900e+04,\n",
       "        1.515700e+04, 1.927600e+04, 3.081100e+04, 3.462200e+04,\n",
       "        4.285800e+04, 5.342000e+04, 7.003200e+04, 1.016640e+05,\n",
       "        1.139230e+05, 1.372710e+05, 1.748420e+05, 2.096220e+05,\n",
       "        2.500280e+05, 3.412560e+05, 3.700330e+05, 4.364400e+05,\n",
       "        5.067370e+05, 5.878230e+05, 7.655200e+05, 8.065730e+05,\n",
       "        9.982440e+05, 1.061436e+06, 1.177522e+06, 1.374270e+06,\n",
       "        1.426051e+06, 1.544690e+06, 1.772321e+06, 1.893164e+06,\n",
       "        1.988634e+06, 2.010077e+06, 2.193215e+06, 2.207188e+06,\n",
       "        2.279171e+06, 2.304931e+06, 2.305142e+06, 2.280097e+06,\n",
       "        2.204645e+06, 2.194462e+06, 2.011343e+06, 1.985149e+06,\n",
       "        1.892430e+06, 1.770895e+06, 1.543126e+06, 1.423662e+06,\n",
       "        1.377139e+06, 1.180425e+06, 1.064361e+06, 9.963680e+05,\n",
       "        8.059520e+05, 7.647000e+05, 5.878250e+05, 5.065300e+05,\n",
       "        4.359090e+05, 3.696770e+05, 3.405850e+05, 2.498340e+05,\n",
       "        2.095150e+05, 1.747830e+05, 1.369060e+05, 1.142510e+05,\n",
       "        1.027810e+05, 7.029700e+04, 5.367800e+04, 4.219700e+04,\n",
       "        3.487200e+04, 3.068800e+04, 1.925300e+04, 1.512000e+04,\n",
       "        1.210400e+04, 9.495000e+03, 7.284000e+03, 6.021000e+03,\n",
       "        4.603000e+03, 3.710000e+03, 2.843000e+03, 2.892000e+03,\n",
       "        1.916000e+03, 1.487000e+03, 1.232000e+03, 1.105000e+03,\n",
       "        1.028000e+03, 8.010000e+02, 6.620000e+02, 5.730000e+02]),\n",
       " array([-0.05 , -0.049, -0.048, -0.047, -0.046, -0.045, -0.044, -0.043,\n",
       "        -0.042, -0.041, -0.04 , -0.039, -0.038, -0.037, -0.036, -0.035,\n",
       "        -0.034, -0.033, -0.032, -0.031, -0.03 , -0.029, -0.028, -0.027,\n",
       "        -0.026, -0.025, -0.024, -0.023, -0.022, -0.021, -0.02 , -0.019,\n",
       "        -0.018, -0.017, -0.016, -0.015, -0.014, -0.013, -0.012, -0.011,\n",
       "        -0.01 , -0.009, -0.008, -0.007, -0.006, -0.005, -0.004, -0.003,\n",
       "        -0.002, -0.001,  0.   ,  0.001,  0.002,  0.003,  0.004,  0.005,\n",
       "         0.006,  0.007,  0.008,  0.009,  0.01 ,  0.011,  0.012,  0.013,\n",
       "         0.014,  0.015,  0.016,  0.017,  0.018,  0.019,  0.02 ,  0.021,\n",
       "         0.022,  0.023,  0.024,  0.025,  0.026,  0.027,  0.028,  0.029,\n",
       "         0.03 ,  0.031,  0.032,  0.033,  0.034,  0.035,  0.036,  0.037,\n",
       "         0.038,  0.039,  0.04 ,  0.041,  0.042,  0.043,  0.044,  0.045,\n",
       "         0.046,  0.047,  0.048,  0.049,  0.05 ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGsCAYAAAAPJKchAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfGklEQVR4nO3dfXBV9Z348c8FJGA1oUhJAIPQ+lhEoCgQu11kmi2y1Mo+WIdZC+tWXafY2uJ2ha2VsbO70VVaOi4t67SWoTsWiq04K90qC6VWibrg0sIibG3lQSVBS0mE0UDJ+f3hj9sGEuTGJN88vF4zd5yce07u9xwu5O0355yby7IsCwCARHqlHgAA0LOJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAIKkuFSNPPvlkXHXVVTF06NDI5XKxatWqgr9HlmVx3333xfnnnx9FRUUxbNiw+Kd/+qe2HywAcEr6pB5AIQ4dOhRjxoyJv/mbv4k///M/b9X3uPXWW+OJJ56I++67L0aPHh379++P/fv3t/FIAYBTleuqH5SXy+XikUceiRkzZuSXNTQ0xJe+9KX43ve+FwcOHIiLL7447rnnnrjiiisiIuKFF16ISy65JLZu3RoXXHBBmoEDAE10qV/TvJNbbrklqqurY/ny5fGLX/wirrnmmrjyyivjl7/8ZURE/Md//Ee8//3vj8ceeyxGjhwZI0aMiBtuuMHMCAAk1G1iZPfu3fGd73wnVq5cGR/5yEfiAx/4QPzd3/1d/NEf/VF85zvfiYiIX//617Fr165YuXJlLFu2LJYuXRqbNm2Kv/zLv0w8egDoubrUOSMns2XLljh69Gicf/75TZY3NDTEWWedFRERjY2N0dDQEMuWLcuv9+1vfzvGjx8fO3bs8KsbAEig28TIwYMHo3fv3rFp06bo3bt3k+fOOOOMiIgYMmRI9OnTp0mwXHTRRRHx9syKGAGAjtdtYmTcuHFx9OjR2LdvX3zkIx9pdp0Pf/jD8bvf/S5+9atfxQc+8IGIiPi///u/iIg455xzOmysAMDvdamraQ4ePBgvvvhiRLwdH1/96ldjypQpMXDgwBg+fHhcd9118fTTT8fChQtj3Lhx8dprr8XatWvjkksuienTp0djY2NcdtllccYZZ8SiRYuisbEx5syZE8XFxfHEE08k3jsA6Jm6VIysX78+pkyZcsLy2bNnx9KlS+PIkSPxj//4j7Fs2bJ45ZVXYtCgQTFp0qS46667YvTo0RER8eqrr8ZnP/vZeOKJJ+I973lPTJs2LRYuXBgDBw7s6N0BAKKLxQgA0P10m0t7AYCuSYwAAEl1iatpGhsb49VXX40zzzwzcrlc6uEAAKcgy7J44403YujQodGrV8vzH10iRl599dUoLy9PPQwAoBX27NkTZ599dovPd4kYOfPMMyPi7Z0pLi5OPBoA4FTU19dHeXl5/ud4S7pEjBz71UxxcbEYAYAu5p1OsXACKwCQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgqT6pBwD0LCPmrX7HdXbePb0DRgJ0FmZGAICkxAgAkJQYAQCScs4I0K5O5RyRU9nGeSTQfZkZAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSbgcPtJnW3PodQIwAXcLxoeOzaqD7ECNAq6WcCfFhetB9OGcEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEiqoBipqqqKyy67LM4888wYPHhwzJgxI3bs2PGO261cuTIuvPDC6NevX4wePTp+9KMftXrAAED3UlCM/PSnP405c+bEM888E2vWrIkjR47Exz72sTh06FCL22zYsCFmzpwZn/70p+N//ud/YsaMGTFjxozYunXrux48AND15bIsy1q78WuvvRaDBw+On/70p/HHf/zHza5z7bXXxqFDh+Kxxx7LL5s0aVKMHTs2lixZckqvU19fHyUlJVFXVxfFxcWtHS7wLoyYtzr1EAq28+7pqYcAPdqp/vx+V+eM1NXVRUTEwIEDW1ynuro6KisrmyybOnVqVFdXt7hNQ0ND1NfXN3kAAN1Tq2OksbExPv/5z8eHP/zhuPjii1tcr6amJkpLS5ssKy0tjZqamha3qaqqipKSkvyjvLy8tcMEADq5VsfInDlzYuvWrbF8+fK2HE9ERMyfPz/q6uryjz179rT5awAAnUOf1mx0yy23xGOPPRZPPvlknH322Sddt6ysLGpra5ssq62tjbKysha3KSoqiqKiotYMDWgjXfEckeM1tw/OI4HOp6CZkSzL4pZbbolHHnkk1q1bFyNHjnzHbSoqKmLt2rVNlq1ZsyYqKioKGykA0C0VNDMyZ86ceOihh+LRRx+NM888M3/eR0lJSfTv3z8iImbNmhXDhg2LqqqqiIi49dZbY/LkybFw4cKYPn16LF++PDZu3BgPPPBAG+8KANAVFTQz8s1vfjPq6uriiiuuiCFDhuQfK1asyK+ze/fu2Lt3b/7ryy+/PB566KF44IEHYsyYMfHwww/HqlWrTnrSKwDQcxQ0M3IqtyRZv379CcuuueaauOaaawp5KQCgh/DZNABAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFKt+tReoHvpDp/Qe6qO31ef4gvpmRkBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSfVIPAOh4I+atTj2ETqO5Y7Hz7ukJRgI9l5kRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgqT6pBwC0rxHzVqceAsBJiRGA4xwfcDvvnp5oJNAz+DUNAJBUwTHy5JNPxlVXXRVDhw6NXC4Xq1atOun669evj1wud8KjpqamtWMGALqRgmPk0KFDMWbMmFi8eHFB2+3YsSP27t2bfwwePLjQlwYAuqGCzxmZNm1aTJs2reAXGjx4cAwYMKDg7QCA7q3DzhkZO3ZsDBkyJP7kT/4knn766ZOu29DQEPX19U0eAED31O4xMmTIkFiyZEn84Ac/iB/84AdRXl4eV1xxRTz//PMtblNVVRUlJSX5R3l5eXsPEwBIJJdlWdbqjXO5eOSRR2LGjBkFbTd58uQYPnx4fPe73232+YaGhmhoaMh/XV9fH+Xl5VFXVxfFxcWtHS70SO4z8u65tBdap76+PkpKSt7x53eS+4xMmDAhnnrqqRafLyoqiqKiog4cEQCQSpL7jGzevDmGDBmS4qUBgE6m4JmRgwcPxosvvpj/+qWXXorNmzfHwIEDY/jw4TF//vx45ZVXYtmyZRERsWjRohg5cmSMGjUq3nrrrfjWt74V69atiyeeeKLt9gIA6LIKjpGNGzfGlClT8l/PnTs3IiJmz54dS5cujb1798bu3bvzzx8+fDhuu+22eOWVV+L000+PSy65JP7rv/6ryfcAAHqud3UCa0c51RNggBM5gfXdcwIrtM6p/vz22TQAQFJiBABISowAAEmJEQAgKTECACSV5A6sQPtx9Uzba+6YusIG2o6ZEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSLu2FLsxlvOkcf+xd6gutZ2YEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICk+qQeAHDqRsxbnXoItKC5P5udd09PMBLoesyMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEn1ST0AoHkj5q1OPQTepeP/DHfePT3RSKBzMzMCACQlRgCApMQIAJCUGAEAkhIjAEBSBcfIk08+GVdddVUMHTo0crlcrFq16h23Wb9+fXzoQx+KoqKiOPfcc2Pp0qWtGCoA0B0VHCOHDh2KMWPGxOLFi09p/ZdeeimmT58eU6ZMic2bN8fnP//5uOGGG+Lxxx8veLAAQPdT8H1Gpk2bFtOmTTvl9ZcsWRIjR46MhQsXRkTERRddFE899VR87Wtfi6lTpxb68gBAN9Pu54xUV1dHZWVlk2VTp06N6urqFrdpaGiI+vr6Jg8AoHtq9zuw1tTURGlpaZNlpaWlUV9fH2+++Wb079//hG2qqqrirrvuau+hQafijqvdX3N/xu7KCp30apr58+dHXV1d/rFnz57UQwIA2km7z4yUlZVFbW1tk2W1tbVRXFzc7KxIRERRUVEUFRW199AAgE6g3WdGKioqYu3atU2WrVmzJioqKtr7pQGALqDgGDl48GBs3rw5Nm/eHBFvX7q7efPm2L17d0S8/SuWWbNm5de/+eab49e//nX8/d//fWzfvj2+8Y1vxPe///34whe+0DZ7AAB0aQXHyMaNG2PcuHExbty4iIiYO3dujBs3Lu68886IiNi7d28+TCIiRo4cGatXr441a9bEmDFjYuHChfGtb33LZb0AQERE5LIsy1IP4p3U19dHSUlJ1NXVRXFxcerhQLtwNU3P5GoaurNT/fndKa+mAQB6DjECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJ9Ug8AeqIR81anHgKdxPHvhZ13T080EkjHzAgAkJQYAQCSEiMAQFJiBABISowAAEm5mgY6gKtnAFomRgA6kebC1eW+dHd+TQMAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICk+qQeAHQ3I+atTj0Eupnj31M7756eaCTQPsyMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEiqVTGyePHiGDFiRPTr1y8mTpwYzz33XIvrLl26NHK5XJNHv379Wj1gAKB7KThGVqxYEXPnzo0FCxbE888/H2PGjImpU6fGvn37WtymuLg49u7dm3/s2rXrXQ0aAOg+Co6Rr371q3HjjTfG9ddfHx/84AdjyZIlcfrpp8eDDz7Y4ja5XC7Kysryj9LS0nc1aACg+yjos2kOHz4cmzZtivnz5+eX9erVKyorK6O6urrF7Q4ePBjnnHNONDY2xoc+9KH453/+5xg1alSL6zc0NERDQ0P+6/r6+kKGCR3KZ9HQ0Zp7z/m8GrqygmZGXn/99Th69OgJMxulpaVRU1PT7DYXXHBBPPjgg/Hoo4/Gv//7v0djY2Ncfvnl8fLLL7f4OlVVVVFSUpJ/lJeXFzJMAKALaferaSoqKmLWrFkxduzYmDx5cvzwhz+M973vffFv//ZvLW4zf/78qKuryz/27NnT3sMEABIp6Nc0gwYNit69e0dtbW2T5bW1tVFWVnZK3+O0006LcePGxYsvvtjiOkVFRVFUVFTI0ACALqqgmZG+ffvG+PHjY+3atflljY2NsXbt2qioqDil73H06NHYsmVLDBkypLCRAgDdUkEzIxERc+fOjdmzZ8ell14aEyZMiEWLFsWhQ4fi+uuvj4iIWbNmxbBhw6KqqioiIr7yla/EpEmT4txzz40DBw7EvffeG7t27YobbrihbfcEAOiSCo6Ra6+9Nl577bW48847o6amJsaOHRs//vGP8ye17t69O3r1+v2Ey29/+9u48cYbo6amJt773vfG+PHjY8OGDfHBD36w7fYCAOiyclmWZakH8U7q6+ujpKQk6urqori4OPVwoAmX9tIZuLSXzuhUf377bBoAICkxAgAkJUYAgKQKPoEVejLnh9BZHf/edA4JXYmZEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICl3YIWTcMdVuqrm3rvuykpnZWYEAEhKjAAASYkRACAp54zA/+f8ELo7n+xLZ2VmBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKR8ai89lk/ppadr7u+AT/IlBTMjAEBSYgQASEqMAABJiREAICkxAgAk5WoaegRXzsCpOf7viqtr6AhmRgCApMQIAJCUGAEAkhIjAEBSYgQASMrVNHRLrp6BtuHza+gIZkYAgKTECACQlBgBAJISIwBAUk5gpctzsip0LLeMp62ZGQEAkhIjAEBSYgQASMo5I3Qpzg+BzseN0Xi3zIwAAEmZGaFTMxMCXZMrbiiEmREAICkxAgAkJUYAgKTECACQlBNY6TScrArdl8t/ORkzIwBAUmZGSMZMCPRsLv/lGDMjAEBSZkboEGZBgHfivJKeS4zQLsQH0BYESs/QqhhZvHhx3HvvvVFTUxNjxoyJ+++/PyZMmNDi+itXrowvf/nLsXPnzjjvvPPinnvuiT/90z9t9aDpXIQH0JGca9L9FBwjK1asiLlz58aSJUti4sSJsWjRopg6dWrs2LEjBg8efML6GzZsiJkzZ0ZVVVV8/OMfj4ceeihmzJgRzz//fFx88cVtshN0LPEBdCZmT7q+XJZlWSEbTJw4MS677LL413/914iIaGxsjPLy8vjsZz8b8+bNO2H9a6+9Ng4dOhSPPfZYftmkSZNi7NixsWTJklN6zfr6+igpKYm6urooLi4uZLgUSGgAPYVgaX+n+vO7oJmRw4cPx6ZNm2L+/Pn5Zb169YrKysqorq5udpvq6uqYO3duk2VTp06NVatWtfg6DQ0N0dDQkP+6rq4uIt7eKU7NxQseTz0EgE5t+BdWFrzN1rumtsNIuq9jP7ffad6joBh5/fXX4+jRo1FaWtpkeWlpaWzfvr3ZbWpqappdv6ampsXXqaqqirvuuuuE5eXl5YUMFwDaVMmi1CPomt54440oKSlp8flOeTXN/Pnzm8ymNDY2xv79++Oss86KXC6XcGTp1dfXR3l5eezZs8evrNqZY90xHOeO4Th3DMe5qSzL4o033oihQ4eedL2CYmTQoEHRu3fvqK2tbbK8trY2ysrKmt2mrKysoPUjIoqKiqKoqKjJsgEDBhQy1G6vuLjYG72DONYdw3HuGI5zx3Ccf+9kMyLHFHQH1r59+8b48eNj7dq1+WWNjY2xdu3aqKioaHabioqKJutHRKxZs6bF9QGAnqXgX9PMnTs3Zs+eHZdeemlMmDAhFi1aFIcOHYrrr78+IiJmzZoVw4YNi6qqqoiIuPXWW2Py5MmxcOHCmD59eixfvjw2btwYDzzwQNvuCQDQJRUcI9dee2289tprceedd0ZNTU2MHTs2fvzjH+dPUt29e3f06vX7CZfLL788HnroobjjjjviH/7hH+K8886LVatWucdIKxUVFcWCBQtO+DUWbc+x7hiOc8dwnDuG49w6Bd9nBACgLfnUXgAgKTECACQlRgCApMQIAJCUGOmE9u/fH3/1V38VxcXFMWDAgPj0pz8dBw8ePOk2b731VsyZMyfOOuusOOOMM+Iv/uIvTrjZ3DG/+c1v4uyzz45cLhcHDhxohz3oGtrjOP/85z+PmTNnRnl5efTv3z8uuuii+PrXv97eu9KpLF68OEaMGBH9+vWLiRMnxnPPPXfS9VeuXBkXXnhh9OvXL0aPHh0/+tGPmjyfZVnceeedMWTIkOjfv39UVlbGL3/5y/bchS6hLY/zkSNH4vbbb4/Ro0fHe97znhg6dGjMmjUrXn311fbejS6hrd/Tf+jmm2+OXC4XixYtauNRdzEZnc6VV16ZjRkzJnvmmWeyn/3sZ9m5556bzZw586Tb3HzzzVl5eXm2du3abOPGjdmkSZOyyy+/vNl1r7766mzatGlZRGS//e1v22EPuob2OM7f/va3s8997nPZ+vXrs1/96lfZd7/73ax///7Z/fff39670yksX74869u3b/bggw9m//u//5vdeOON2YABA7La2tpm13/66aez3r17Z//yL/+Sbdu2Lbvjjjuy0047LduyZUt+nbvvvjsrKSnJVq1alf385z/PPvGJT2QjR47M3nzzzY7arU6nrY/zgQMHssrKymzFihXZ9u3bs+rq6mzChAnZ+PHjO3K3OqX2eE8f88Mf/jAbM2ZMNnTo0OxrX/taO+9J5yZGOplt27ZlEZH993//d37Zf/7nf2a5XC575ZVXmt3mwIED2WmnnZatXLkyv+yFF17IIiKrrq5usu43vvGNbPLkydnatWt7dIy093H+Q5/5zGeyKVOmtN3gO7EJEyZkc+bMyX999OjRbOjQoVlVVVWz63/yk5/Mpk+f3mTZxIkTs7/927/NsizLGhsbs7Kysuzee+/NP3/gwIGsqKgo+973vtcOe9A1tPVxbs5zzz2XRUS2a9euthl0F9Vex/rll1/Ohg0blm3dujU755xzenyM+DVNJ1NdXR0DBgyISy+9NL+ssrIyevXqFc8++2yz22zatCmOHDkSlZWV+WUXXnhhDB8+PKqrq/PLtm3bFl/5yldi2bJlTW5M1xO153E+Xl1dXQwcOLDtBt9JHT58ODZt2tTk+PTq1SsqKytbPD7V1dVN1o+ImDp1an79l156KWpqapqsU1JSEhMnTjzpMe/O2uM4N6euri5yuVyP/lyw9jrWjY2N8alPfSq++MUvxqhRo9pn8F1Mz/6J1AnV1NTE4MGDmyzr06dPDBw4MGpqalrcpm/fvif8o1FaWprfpqGhIWbOnBn33ntvDB8+vF3G3pW013E+3oYNG2LFihVx0003tcm4O7PXX389jh49mr8b8zEnOz41NTUnXf/Yfwv5nt1dexzn47311ltx++23x8yZM3v0h72117G+5557ok+fPvG5z32u7QfdRYmRDjJv3rzI5XInfWzfvr3dXn/+/Plx0UUXxXXXXddur9EZpD7Of2jr1q1x9dVXx4IFC+JjH/tYh7wmvFtHjhyJT37yk5FlWXzzm99MPZxuZ9OmTfH1r389li5dGrlcLvVwOo2CP5uG1rntttvir//6r0+6zvvf//4oKyuLffv2NVn+u9/9Lvbv3x9lZWXNbldWVhaHDx+OAwcONPm/9tra2vw269atiy1btsTDDz8cEW9foRARMWjQoPjSl74Ud911Vyv3rHNJfZyP2bZtW3z0ox+Nm266Ke64445W7UtXM2jQoOjdu/cJV3E1d3yOKSsrO+n6x/5bW1sbQ4YMabLO2LFj23D0XUd7HOdjjoXIrl27Yt26dT16ViSifY71z372s9i3b1+TGeqjR4/GbbfdFosWLYqdO3e27U50FalPWqGpYydWbty4Mb/s8ccfP6UTKx9++OH8su3btzc5sfLFF1/MtmzZkn88+OCDWURkGzZsaPGs8O6svY5zlmXZ1q1bs8GDB2df/OIX228HOqkJEyZkt9xyS/7ro0ePZsOGDTvpyX4f//jHmyyrqKg44QTW++67L/98XV2dE1jb+DhnWZYdPnw4mzFjRjZq1Khs37597TPwLqitj/Xrr7/e5N/iLVu2ZEOHDs1uv/32bPv27e23I52cGOmErrzyymzcuHHZs88+mz311FPZeeed1+SS05dffjm74IILsmeffTa/7Oabb86GDx+erVu3Ltu4cWNWUVGRVVRUtPgaP/nJT3r01TRZ1j7HecuWLdn73ve+7Lrrrsv27t2bf/SUf9yXL1+eFRUVZUuXLs22bduW3XTTTdmAAQOympqaLMuy7FOf+lQ2b968/PpPP/101qdPn+y+++7LXnjhhWzBggXNXto7YMCA7NFHH81+8YtfZFdffbVLe9v4OB8+fDj7xCc+kZ199tnZ5s2bm7x3GxoakuxjZ9Ee7+njuZpGjHRKv/nNb7KZM2dmZ5xxRlZcXJxdf/312RtvvJF//qWXXsoiIvvJT36SX/bmm29mn/nMZ7L3vve92emnn5792Z/9WbZ3794WX0OMtM9xXrBgQRYRJzzOOeecDtyztO6///5s+PDhWd++fbMJEyZkzzzzTP65yZMnZ7Nnz26y/ve///3s/PPPz/r27ZuNGjUqW716dZPnGxsbsy9/+ctZaWlpVlRUlH30ox/NduzY0RG70qm15XE+9l5v7vGH7/+eqq3f08cTI1mWy7L/f/IAAEACrqYBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEn9P9IIGi1dxA2BAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x=model_dict['layers.0.feed_forward.w2.weight'].flatten().float(), bins=100, range=(-0.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.090000e+02, 2.940000e+02, 3.500000e+02, 4.610000e+02,\n",
       "        5.760000e+02, 8.060000e+02, 1.022000e+03, 1.299000e+03,\n",
       "        2.235000e+03, 2.369000e+03, 3.093000e+03, 4.279000e+03,\n",
       "        5.840000e+03, 7.175000e+03, 9.409000e+03, 1.235800e+04,\n",
       "        1.578600e+04, 2.021200e+04, 3.233500e+04, 3.700700e+04,\n",
       "        4.517200e+04, 5.686700e+04, 7.507200e+04, 1.097040e+05,\n",
       "        1.209790e+05, 1.445680e+05, 1.846800e+05, 2.197240e+05,\n",
       "        2.600120e+05, 3.511850e+05, 3.804410e+05, 4.462270e+05,\n",
       "        5.140880e+05, 5.941750e+05, 7.724780e+05, 8.116350e+05,\n",
       "        1.000893e+06, 1.065417e+06, 1.177098e+06, 1.364812e+06,\n",
       "        1.409904e+06, 1.527557e+06, 1.755499e+06, 1.871545e+06,\n",
       "        1.966942e+06, 1.988069e+06, 2.177407e+06, 2.200801e+06,\n",
       "        2.285428e+06, 2.320002e+06, 2.318873e+06, 2.286680e+06,\n",
       "        2.202164e+06, 2.179494e+06, 1.989595e+06, 1.968466e+06,\n",
       "        1.872898e+06, 1.757060e+06, 1.527305e+06, 1.409115e+06,\n",
       "        1.364079e+06, 1.176238e+06, 1.063805e+06, 1.001649e+06,\n",
       "        8.138340e+05, 7.744660e+05, 5.924580e+05, 5.144860e+05,\n",
       "        4.462780e+05, 3.801230e+05, 3.511660e+05, 2.596630e+05,\n",
       "        2.185120e+05, 1.842570e+05, 1.445580e+05, 1.213730e+05,\n",
       "        1.095120e+05, 7.499300e+04, 5.717100e+04, 4.491500e+04,\n",
       "        3.679200e+04, 3.279500e+04, 2.010700e+04, 1.581800e+04,\n",
       "        1.230300e+04, 9.622000e+03, 7.188000e+03, 5.601000e+03,\n",
       "        4.266000e+03, 3.178000e+03, 2.422000e+03, 2.074000e+03,\n",
       "        1.344000e+03, 1.043000e+03, 7.550000e+02, 5.800000e+02,\n",
       "        4.480000e+02, 3.650000e+02, 2.550000e+02, 2.320000e+02]),\n",
       " array([-0.05 , -0.049, -0.048, -0.047, -0.046, -0.045, -0.044, -0.043,\n",
       "        -0.042, -0.041, -0.04 , -0.039, -0.038, -0.037, -0.036, -0.035,\n",
       "        -0.034, -0.033, -0.032, -0.031, -0.03 , -0.029, -0.028, -0.027,\n",
       "        -0.026, -0.025, -0.024, -0.023, -0.022, -0.021, -0.02 , -0.019,\n",
       "        -0.018, -0.017, -0.016, -0.015, -0.014, -0.013, -0.012, -0.011,\n",
       "        -0.01 , -0.009, -0.008, -0.007, -0.006, -0.005, -0.004, -0.003,\n",
       "        -0.002, -0.001,  0.   ,  0.001,  0.002,  0.003,  0.004,  0.005,\n",
       "         0.006,  0.007,  0.008,  0.009,  0.01 ,  0.011,  0.012,  0.013,\n",
       "         0.014,  0.015,  0.016,  0.017,  0.018,  0.019,  0.02 ,  0.021,\n",
       "         0.022,  0.023,  0.024,  0.025,  0.026,  0.027,  0.028,  0.029,\n",
       "         0.03 ,  0.031,  0.032,  0.033,  0.034,  0.035,  0.036,  0.037,\n",
       "         0.038,  0.039,  0.04 ,  0.041,  0.042,  0.043,  0.044,  0.045,\n",
       "         0.046,  0.047,  0.048,  0.049,  0.05 ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x=model_dict['layers.0.feed_forward.w3.weight'].flatten().float(), bins=100, range=(-0.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  11100.,   11938.,   13552.,   15329.,   15126.,   15705.,\n",
       "          16733.,   18398.,   23931.,   20445.,   23002.,   25295.,\n",
       "          25605.,   27109.,   29235.,   31162.,   32470.,   34628.,\n",
       "          47292.,   43805.,   45422.,   49501.,   53955.,   66894.,\n",
       "          63097.,   64820.,   72533.,   75509.,   79546.,   96842.,\n",
       "          94061.,   99243.,  103729.,  112782.,  137034.,  135768.,\n",
       "         158323.,  160132.,  170236.,  191231.,  194266.,  210361.,\n",
       "         243882.,  267171.,  289326.,  312094.,  381557.,  456816.,\n",
       "         673613., 2646313., 2645134.,  672685.,  457803.,  381559.,\n",
       "         313069.,  291342.,  265941.,  244937.,  209353.,  194139.,\n",
       "         191929.,  170007.,  159867.,  158479.,  135447.,  138300.,\n",
       "         112451.,  104321.,   99758.,   93589.,   96193.,   80143.,\n",
       "          76152.,   72659.,   64813.,   63200.,   66720.,   54055.,\n",
       "          49066.,   45612.,   44369.,   47860.,   34604.,   32272.,\n",
       "          30949.,   28879.,   27261.,   25967.,   25060.,   22958.,\n",
       "          20651.,   24014.,   18489.,   16898.,   15649.,   14963.,\n",
       "          15325.,   13587.,   11913.,   11254.]),\n",
       " array([-0.05 , -0.049, -0.048, -0.047, -0.046, -0.045, -0.044, -0.043,\n",
       "        -0.042, -0.041, -0.04 , -0.039, -0.038, -0.037, -0.036, -0.035,\n",
       "        -0.034, -0.033, -0.032, -0.031, -0.03 , -0.029, -0.028, -0.027,\n",
       "        -0.026, -0.025, -0.024, -0.023, -0.022, -0.021, -0.02 , -0.019,\n",
       "        -0.018, -0.017, -0.016, -0.015, -0.014, -0.013, -0.012, -0.011,\n",
       "        -0.01 , -0.009, -0.008, -0.007, -0.006, -0.005, -0.004, -0.003,\n",
       "        -0.002, -0.001,  0.   ,  0.001,  0.002,  0.003,  0.004,  0.005,\n",
       "         0.006,  0.007,  0.008,  0.009,  0.01 ,  0.011,  0.012,  0.013,\n",
       "         0.014,  0.015,  0.016,  0.017,  0.018,  0.019,  0.02 ,  0.021,\n",
       "         0.022,  0.023,  0.024,  0.025,  0.026,  0.027,  0.028,  0.029,\n",
       "         0.03 ,  0.031,  0.032,  0.033,  0.034,  0.035,  0.036,  0.037,\n",
       "         0.038,  0.039,  0.04 ,  0.041,  0.042,  0.043,  0.044,  0.045,\n",
       "         0.046,  0.047,  0.048,  0.049,  0.05 ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x=model_dict['layers.0.attention.wq.weight'].flatten().float(), bins=100, range=(-0.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.16000e+02, 5.82000e+02, 6.55000e+02, 1.00700e+03, 8.66000e+02,\n",
       "        1.04400e+03, 1.63100e+03, 1.40500e+03, 1.52600e+03, 1.88600e+03,\n",
       "        2.90900e+03, 3.10000e+03, 3.80100e+03, 4.70200e+03, 4.84300e+03,\n",
       "        7.01200e+03, 7.20600e+03, 1.04670e+04, 1.00820e+04, 1.39270e+04,\n",
       "        1.49620e+04, 2.05600e+04, 2.47110e+04, 2.48730e+04, 3.43100e+04,\n",
       "        3.66330e+04, 4.97920e+04, 4.99980e+04, 6.76960e+04, 6.77910e+04,\n",
       "        9.54280e+04, 1.14912e+05, 1.27875e+05, 1.53281e+05, 1.72982e+05,\n",
       "        2.02885e+05, 2.26760e+05, 2.59589e+05, 2.94455e+05, 3.29722e+05,\n",
       "        4.03778e+05, 4.33743e+05, 4.80786e+05, 5.17870e+05, 5.63400e+05,\n",
       "        6.42681e+05, 6.67721e+05, 7.15410e+05, 7.46160e+05, 7.65744e+05,\n",
       "        7.63645e+05, 7.45693e+05, 7.14503e+05, 6.66070e+05, 6.42375e+05,\n",
       "        5.63651e+05, 5.18866e+05, 4.80232e+05, 4.34927e+05, 4.04033e+05,\n",
       "        3.28076e+05, 2.94875e+05, 2.59724e+05, 2.26891e+05, 2.02944e+05,\n",
       "        1.72980e+05, 1.53412e+05, 1.28519e+05, 1.15423e+05, 9.49140e+04,\n",
       "        6.79200e+04, 6.79470e+04, 4.97270e+04, 4.94980e+04, 3.66150e+04,\n",
       "        3.42760e+04, 2.48480e+04, 2.43170e+04, 2.07740e+04, 1.50550e+04,\n",
       "        1.40310e+04, 1.00190e+04, 1.04150e+04, 7.08700e+03, 7.03600e+03,\n",
       "        4.95600e+03, 4.62800e+03, 3.88100e+03, 2.98500e+03, 2.82200e+03,\n",
       "        1.88900e+03, 1.65300e+03, 1.40300e+03, 1.57400e+03, 9.98000e+02,\n",
       "        8.99000e+02, 1.00300e+03, 6.68000e+02, 6.19000e+02, 5.00000e+02]),\n",
       " array([-0.08  , -0.0784, -0.0768, -0.0752, -0.0736, -0.072 , -0.0704,\n",
       "        -0.0688, -0.0672, -0.0656, -0.064 , -0.0624, -0.0608, -0.0592,\n",
       "        -0.0576, -0.056 , -0.0544, -0.0528, -0.0512, -0.0496, -0.048 ,\n",
       "        -0.0464, -0.0448, -0.0432, -0.0416, -0.04  , -0.0384, -0.0368,\n",
       "        -0.0352, -0.0336, -0.032 , -0.0304, -0.0288, -0.0272, -0.0256,\n",
       "        -0.024 , -0.0224, -0.0208, -0.0192, -0.0176, -0.016 , -0.0144,\n",
       "        -0.0128, -0.0112, -0.0096, -0.008 , -0.0064, -0.0048, -0.0032,\n",
       "        -0.0016,  0.    ,  0.0016,  0.0032,  0.0048,  0.0064,  0.008 ,\n",
       "         0.0096,  0.0112,  0.0128,  0.0144,  0.016 ,  0.0176,  0.0192,\n",
       "         0.0208,  0.0224,  0.024 ,  0.0256,  0.0272,  0.0288,  0.0304,\n",
       "         0.032 ,  0.0336,  0.0352,  0.0368,  0.0384,  0.04  ,  0.0416,\n",
       "         0.0432,  0.0448,  0.0464,  0.048 ,  0.0496,  0.0512,  0.0528,\n",
       "         0.0544,  0.056 ,  0.0576,  0.0592,  0.0608,  0.0624,  0.064 ,\n",
       "         0.0656,  0.0672,  0.0688,  0.0704,  0.072 ,  0.0736,  0.0752,\n",
       "         0.0768,  0.0784,  0.08  ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x=model_dict['layers.31.attention.wq.weight'].flatten().float(), bins=100, range=(-0.08, 0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  5264.,   5477.,   6151.,   6746.,   6651.,   6894.,   7228.,\n",
       "          7796.,   9856.,   8472.,   9387.,   9859.,   9942.,  10458.,\n",
       "         10941.,  11274.,  11867.,  12563.,  17036.,  15226.,  15658.,\n",
       "         16634.,  17873.,  21647.,  20400.,  20456.,  22309.,  22974.,\n",
       "         23776.,  28540.,  26950.,  28055.,  28629.,  30452.,  36407.,\n",
       "         35037.,  39614.,  38943.,  40111.,  44170.,  43729.,  46273.,\n",
       "         52893.,  57461.,  61741.,  66920.,  83981., 104937., 164207.,\n",
       "        545709., 545025., 163677., 104965.,  83615.,  67188.,  61270.,\n",
       "         56566.,  53125.,  46603.,  43912.,  44226.,  40598.,  38841.,\n",
       "         39472.,  34623.,  35981.,  30354.,  28511.,  27948.,  26993.,\n",
       "         28177.,  23786.,  23050.,  22463.,  20453.,  20209.,  21776.,\n",
       "         17918.,  16412.,  15608.,  15260.,  17060.,  12653.,  11790.,\n",
       "         11545.,  11211.,  10452.,  10055.,   9929.,   9248.,   8328.,\n",
       "          9830.,   7591.,   7303.,   6683.,   6570.,   6788.,   6005.,\n",
       "          5381.,   5233.]),\n",
       " array([-0.05 , -0.049, -0.048, -0.047, -0.046, -0.045, -0.044, -0.043,\n",
       "        -0.042, -0.041, -0.04 , -0.039, -0.038, -0.037, -0.036, -0.035,\n",
       "        -0.034, -0.033, -0.032, -0.031, -0.03 , -0.029, -0.028, -0.027,\n",
       "        -0.026, -0.025, -0.024, -0.023, -0.022, -0.021, -0.02 , -0.019,\n",
       "        -0.018, -0.017, -0.016, -0.015, -0.014, -0.013, -0.012, -0.011,\n",
       "        -0.01 , -0.009, -0.008, -0.007, -0.006, -0.005, -0.004, -0.003,\n",
       "        -0.002, -0.001,  0.   ,  0.001,  0.002,  0.003,  0.004,  0.005,\n",
       "         0.006,  0.007,  0.008,  0.009,  0.01 ,  0.011,  0.012,  0.013,\n",
       "         0.014,  0.015,  0.016,  0.017,  0.018,  0.019,  0.02 ,  0.021,\n",
       "         0.022,  0.023,  0.024,  0.025,  0.026,  0.027,  0.028,  0.029,\n",
       "         0.03 ,  0.031,  0.032,  0.033,  0.034,  0.035,  0.036,  0.037,\n",
       "         0.038,  0.039,  0.04 ,  0.041,  0.042,  0.043,  0.044,  0.045,\n",
       "         0.046,  0.047,  0.048,  0.049,  0.05 ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x=model_dict['layers.0.attention.wk.weight'].flatten().float(), bins=100, range=(-0.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.00000e+00, 2.00000e+00, 1.00000e+00, 4.00000e+00, 3.00000e+00,\n",
       "        8.00000e+00, 6.00000e+00, 7.00000e+00, 1.50000e+01, 1.50000e+01,\n",
       "        2.70000e+01, 3.60000e+01, 3.70000e+01, 4.80000e+01, 6.60000e+01,\n",
       "        1.25000e+02, 1.37000e+02, 1.63000e+02, 3.11000e+02, 4.15000e+02,\n",
       "        4.76000e+02, 6.14000e+02, 9.36000e+02, 1.26800e+03, 1.64600e+03,\n",
       "        2.04300e+03, 2.77400e+03, 3.34100e+03, 4.38100e+03, 6.17200e+03,\n",
       "        7.27300e+03, 9.00000e+03, 1.10260e+04, 1.37450e+04, 1.95480e+04,\n",
       "        2.19930e+04, 2.93420e+04, 3.35900e+04, 4.05230e+04, 5.08280e+04,\n",
       "        5.79120e+04, 6.91000e+04, 8.81100e+04, 1.05241e+05, 1.25700e+05,\n",
       "        1.47074e+05, 1.90746e+05, 2.32800e+05, 3.12625e+05, 5.05985e+05,\n",
       "        5.06218e+05, 3.12753e+05, 2.32797e+05, 1.90493e+05, 1.46918e+05,\n",
       "        1.26271e+05, 1.05710e+05, 8.77360e+04, 6.88380e+04, 5.77550e+04,\n",
       "        5.08540e+04, 4.05010e+04, 3.39410e+04, 2.93010e+04, 2.16210e+04,\n",
       "        1.94540e+04, 1.36870e+04, 1.10450e+04, 9.08400e+03, 7.12000e+03,\n",
       "        6.25100e+03, 4.29900e+03, 3.31300e+03, 2.70900e+03, 1.99400e+03,\n",
       "        1.65800e+03, 1.28500e+03, 8.94000e+02, 6.20000e+02, 4.52000e+02,\n",
       "        4.25000e+02, 3.25000e+02, 1.84000e+02, 1.47000e+02, 1.21000e+02,\n",
       "        8.60000e+01, 5.20000e+01, 3.90000e+01, 3.30000e+01, 2.00000e+01,\n",
       "        1.40000e+01, 1.70000e+01, 8.00000e+00, 6.00000e+00, 2.00000e+00,\n",
       "        3.00000e+00, 3.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00]),\n",
       " array([-0.05 , -0.049, -0.048, -0.047, -0.046, -0.045, -0.044, -0.043,\n",
       "        -0.042, -0.041, -0.04 , -0.039, -0.038, -0.037, -0.036, -0.035,\n",
       "        -0.034, -0.033, -0.032, -0.031, -0.03 , -0.029, -0.028, -0.027,\n",
       "        -0.026, -0.025, -0.024, -0.023, -0.022, -0.021, -0.02 , -0.019,\n",
       "        -0.018, -0.017, -0.016, -0.015, -0.014, -0.013, -0.012, -0.011,\n",
       "        -0.01 , -0.009, -0.008, -0.007, -0.006, -0.005, -0.004, -0.003,\n",
       "        -0.002, -0.001,  0.   ,  0.001,  0.002,  0.003,  0.004,  0.005,\n",
       "         0.006,  0.007,  0.008,  0.009,  0.01 ,  0.011,  0.012,  0.013,\n",
       "         0.014,  0.015,  0.016,  0.017,  0.018,  0.019,  0.02 ,  0.021,\n",
       "         0.022,  0.023,  0.024,  0.025,  0.026,  0.027,  0.028,  0.029,\n",
       "         0.03 ,  0.031,  0.032,  0.033,  0.034,  0.035,  0.036,  0.037,\n",
       "         0.038,  0.039,  0.04 ,  0.041,  0.042,  0.043,  0.044,  0.045,\n",
       "         0.046,  0.047,  0.048,  0.049,  0.05 ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x=model_dict['layers.0.attention.wv.weight'].flatten().float(), bins=100, range=(-0.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.150000e+02, 1.090000e+02, 1.360000e+02, 1.420000e+02,\n",
       "        1.720000e+02, 1.890000e+02, 1.940000e+02, 2.250000e+02,\n",
       "        3.270000e+02, 2.600000e+02, 3.560000e+02, 4.270000e+02,\n",
       "        4.700000e+02, 5.550000e+02, 6.100000e+02, 7.410000e+02,\n",
       "        8.880000e+02, 1.064000e+03, 1.646000e+03, 1.836000e+03,\n",
       "        2.169000e+03, 2.844000e+03, 3.770000e+03, 5.743000e+03,\n",
       "        6.814000e+03, 8.187000e+03, 1.113800e+04, 1.454000e+04,\n",
       "        1.832800e+04, 2.709000e+04, 3.162900e+04, 4.065300e+04,\n",
       "        5.106100e+04, 6.521100e+04, 9.337700e+04, 1.092840e+05,\n",
       "        1.510790e+05, 1.782830e+05, 2.197920e+05, 2.854820e+05,\n",
       "        3.283530e+05, 3.942170e+05, 5.028830e+05, 5.903850e+05,\n",
       "        6.809010e+05, 7.462440e+05, 8.697010e+05, 9.236690e+05,\n",
       "        9.925030e+05, 1.020617e+06, 1.021983e+06, 9.923760e+05,\n",
       "        9.252330e+05, 8.717400e+05, 7.439390e+05, 6.793320e+05,\n",
       "        5.903100e+05, 5.017740e+05, 3.944130e+05, 3.284730e+05,\n",
       "        2.855420e+05, 2.199320e+05, 1.783840e+05, 1.509220e+05,\n",
       "        1.097210e+05, 9.356900e+04, 6.528900e+04, 5.119400e+04,\n",
       "        4.109800e+04, 3.166000e+04, 2.712700e+04, 1.831800e+04,\n",
       "        1.424600e+04, 1.124000e+04, 8.204000e+03, 6.668000e+03,\n",
       "        5.751000e+03, 3.742000e+03, 2.870000e+03, 2.236000e+03,\n",
       "        1.836000e+03, 1.688000e+03, 1.095000e+03, 8.850000e+02,\n",
       "        7.520000e+02, 6.340000e+02, 5.110000e+02, 5.010000e+02,\n",
       "        4.270000e+02, 3.420000e+02, 2.880000e+02, 3.370000e+02,\n",
       "        2.250000e+02, 2.050000e+02, 1.690000e+02, 1.630000e+02,\n",
       "        1.660000e+02, 1.210000e+02, 1.290000e+02, 1.190000e+02]),\n",
       " array([-0.05 , -0.049, -0.048, -0.047, -0.046, -0.045, -0.044, -0.043,\n",
       "        -0.042, -0.041, -0.04 , -0.039, -0.038, -0.037, -0.036, -0.035,\n",
       "        -0.034, -0.033, -0.032, -0.031, -0.03 , -0.029, -0.028, -0.027,\n",
       "        -0.026, -0.025, -0.024, -0.023, -0.022, -0.021, -0.02 , -0.019,\n",
       "        -0.018, -0.017, -0.016, -0.015, -0.014, -0.013, -0.012, -0.011,\n",
       "        -0.01 , -0.009, -0.008, -0.007, -0.006, -0.005, -0.004, -0.003,\n",
       "        -0.002, -0.001,  0.   ,  0.001,  0.002,  0.003,  0.004,  0.005,\n",
       "         0.006,  0.007,  0.008,  0.009,  0.01 ,  0.011,  0.012,  0.013,\n",
       "         0.014,  0.015,  0.016,  0.017,  0.018,  0.019,  0.02 ,  0.021,\n",
       "         0.022,  0.023,  0.024,  0.025,  0.026,  0.027,  0.028,  0.029,\n",
       "         0.03 ,  0.031,  0.032,  0.033,  0.034,  0.035,  0.036,  0.037,\n",
       "         0.038,  0.039,  0.04 ,  0.041,  0.042,  0.043,  0.044,  0.045,\n",
       "         0.046,  0.047,  0.048,  0.049,  0.05 ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x=model_dict['layers.0.attention.wo.weight'].flatten().float(), bins=100, range=(-0.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.1800000e+02, 1.9800000e+02, 2.7300000e+02, 4.4100000e+02,\n",
       "        6.4300000e+02, 9.1700000e+02, 1.3650000e+03, 1.9150000e+03,\n",
       "        3.6280000e+03, 4.1770000e+03, 6.2770000e+03, 9.2810000e+03,\n",
       "        1.2902000e+04, 1.7665000e+04, 2.4805000e+04, 3.4591000e+04,\n",
       "        4.7408000e+04, 6.3909000e+04, 1.1093200e+05, 1.3411600e+05,\n",
       "        1.7538700e+05, 2.3435600e+05, 3.2203600e+05, 5.0729400e+05,\n",
       "        5.9529100e+05, 7.4333800e+05, 9.8858500e+05, 1.2388760e+06,\n",
       "        1.5345720e+06, 2.1790450e+06, 2.4481030e+06, 3.0040550e+06,\n",
       "        3.5901760e+06, 4.3053750e+06, 5.8111790e+06, 6.3314600e+06,\n",
       "        8.0611020e+06, 8.8799900e+06, 1.0044613e+07, 1.1944488e+07,\n",
       "        1.2629533e+07, 1.3988410e+07, 1.6368980e+07, 1.7775619e+07,\n",
       "        1.8959307e+07, 1.9390803e+07, 2.1409153e+07, 2.1754404e+07,\n",
       "        2.2681757e+07, 2.3912219e+07, 2.3917099e+07, 2.2689091e+07,\n",
       "        2.1783282e+07, 2.1434918e+07, 1.9417271e+07, 1.9004238e+07,\n",
       "        1.7824900e+07, 1.6417351e+07, 1.4034916e+07, 1.2672369e+07,\n",
       "        1.1992601e+07, 1.0089993e+07, 8.9171760e+06, 8.0984650e+06,\n",
       "        6.3658640e+06, 5.8417230e+06, 4.3325340e+06, 3.6112040e+06,\n",
       "        3.0261350e+06, 2.4730010e+06, 2.1945870e+06, 1.5484080e+06,\n",
       "        1.2486300e+06, 9.9800700e+05, 7.5425300e+05, 6.0332000e+05,\n",
       "        5.1491600e+05, 3.2706600e+05, 2.3855800e+05, 1.7961900e+05,\n",
       "        1.3767000e+05, 1.1428200e+05, 6.6900000e+04, 4.9490000e+04,\n",
       "        3.6210000e+04, 2.6110000e+04, 1.9109000e+04, 1.3953000e+04,\n",
       "        1.0132000e+04, 6.9890000e+03, 4.8950000e+03, 4.4270000e+03,\n",
       "        2.4310000e+03, 1.6930000e+03, 1.2490000e+03, 9.4400000e+02,\n",
       "        7.1100000e+02, 5.3000000e+02, 3.9800000e+02, 2.9300000e+02]),\n",
       " array([-0.05 , -0.049, -0.048, -0.047, -0.046, -0.045, -0.044, -0.043,\n",
       "        -0.042, -0.041, -0.04 , -0.039, -0.038, -0.037, -0.036, -0.035,\n",
       "        -0.034, -0.033, -0.032, -0.031, -0.03 , -0.029, -0.028, -0.027,\n",
       "        -0.026, -0.025, -0.024, -0.023, -0.022, -0.021, -0.02 , -0.019,\n",
       "        -0.018, -0.017, -0.016, -0.015, -0.014, -0.013, -0.012, -0.011,\n",
       "        -0.01 , -0.009, -0.008, -0.007, -0.006, -0.005, -0.004, -0.003,\n",
       "        -0.002, -0.001,  0.   ,  0.001,  0.002,  0.003,  0.004,  0.005,\n",
       "         0.006,  0.007,  0.008,  0.009,  0.01 ,  0.011,  0.012,  0.013,\n",
       "         0.014,  0.015,  0.016,  0.017,  0.018,  0.019,  0.02 ,  0.021,\n",
       "         0.022,  0.023,  0.024,  0.025,  0.026,  0.027,  0.028,  0.029,\n",
       "         0.03 ,  0.031,  0.032,  0.033,  0.034,  0.035,  0.036,  0.037,\n",
       "         0.038,  0.039,  0.04 ,  0.041,  0.042,  0.043,  0.044,  0.045,\n",
       "         0.046,  0.047,  0.048,  0.049,  0.05 ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGsCAYAAAAPJKchAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgfklEQVR4nO3dfZBW1X0H8N8CsqCyi0jYBVxeWmNUgkBQYG0TdLIVGXwh0zEOkwTi+FIbaGLQVGitRJtmbZWGTEqkjkXGtBSCidgRY0pBJMiqBUsCEhhtEZCwi0bZBUYXyt7+kbLJwi7wrLt7dpfPZ+aO89znnL2/e/IMzzfnOffevCzLsgAASKRL6gIAgDObMAIAJCWMAABJCSMAQFLCCACQlDACACQljAAASQkjAEBSwggAkJQwAgAk1aHCyNq1a+P666+PAQMGRF5eXixfvjyn/t/85jcjLy/vhO2cc85pnYIBgFPqUGHk0KFDMWLEiJg/f36z+t9zzz2xd+/eBtull14aN910UwtXCgCcrg4VRiZOnBjf+ta34nOf+1yj79fW1sY999wTAwcOjHPOOSfGjh0ba9asqX//3HPPjeLi4vqtqqoqtm7dGrfeemsbnQEAcLwOFUZOZcaMGVFRURFLliyJX/ziF3HTTTfFtddeG2+88Uaj7R9//PG46KKL4tOf/nQbVwoAHNNpwsiuXbviiSeeiGXLlsWnP/3p+P3f//2455574g//8A/jiSeeOKH9hx9+GP/yL/9iVgQAEuuWuoCWsnnz5jh69GhcdNFFDfbX1tbG+eeff0L7p59+Og4cOBDTpk1rqxIBgEZ0mjBy8ODB6Nq1a2zcuDG6du3a4L1zzz33hPaPP/54XHfddVFUVNRWJQIAjeg0YWTUqFFx9OjR2Ldv3ynXgOzYsSNeeOGF+Ld/+7c2qg4AaEqHCiMHDx6MN998s/71jh07YtOmTdGnT5+46KKL4gtf+EJMnTo15s6dG6NGjYp33nknVq1aFZdddllMmjSpvt/ChQujf//+MXHixBSnAQD8jrwsy7LURZyuNWvWxNVXX33C/mnTpsWiRYviyJEj8a1vfSuefPLJ2LNnT/Tt2zfGjRsXDzzwQAwfPjwiIurq6mLw4MExderU+Ju/+Zu2PgUA4DgdKowAAJ1PTpf2lpeXxxVXXBG9evWKfv36xeTJk2P79u0n7bNo0aITbr/eo0ePj1Q0ANB55BRGXnzxxZg+fXq8/PLLsXLlyjhy5Ehcc801cejQoZP2KygoaHAL9p07d36kogGAziOnBazPP/98g9eLFi2Kfv36xcaNG+Mzn/lMk/3y8vKiuLi4eRXGb9Z5/OpXv4pevXpFXl5es/8OANB2siyLAwcOxIABA6JLl6bnPz7S1TTV1dUREdGnT5+Ttjt48GAMHjw46urq4lOf+lR8+9vfjmHDhjXZvra2Nmpra+tf79mzJy699NKPUioAkMju3bvjggsuaPL9Zi9graurixtuuCH2798f69ata7JdRUVFvPHGG3HZZZdFdXV1PPLII7F27dp4/fXXmyzsm9/8ZjzwwAMn7N+9e3cUFBQ0p1wAoI3V1NRESUlJ7N+/PwoLC5ts1+ww8qd/+qfxk5/8JNatW3fStHO8I0eOxCWXXBJTpkyJv/7rv260zfEzI8dOprq6WhgBgA6ipqYmCgsLT/n93ayfaWbMmBHPPvtsrF27NqcgEhFx1llnxahRoxrcvOx4+fn5kZ+f35zSAIAOJqerabIsixkzZsTTTz8dq1evjqFDh+Z8wKNHj8bmzZujf//+OfcFADqfnGZGpk+fHosXL45nnnkmevXqFZWVlRERUVhYGD179oyIiKlTp8bAgQOjvLw8IiIefPDBGDduXFx44YWxf//+ePjhh2Pnzp1x2223tfCpAAAdUU5h5NFHH42IiKuuuqrB/ieeeCK+/OUvR0TErl27Gly+8/7778ftt98elZWVcd5558Xo0aNj/fr1ro4BACKig9wO/nQXwAAA7cfpfn/ntGYEAKClCSMAQFLCCACQlDACACQljAAASQkjAEBSwggAkJQwAgAkJYwAAEk166m9AM01ZNaKU7Z566FJbVAJ0F6YGQEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJLqlroAoHMbMmtFi/R566FJLVEO0A6ZGQEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkvLUXqDFNOcJvc39257iC52HmREAIClhBABIShgBAJISRgCApCxgBZqtNResNufYFrVCx2RmBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACCpnMJIeXl5XHHFFdGrV6/o169fTJ48ObZv337KfsuWLYuLL744evToEcOHD4/nnnuu2QUDAJ1LTmHkxRdfjOnTp8fLL78cK1eujCNHjsQ111wThw4darLP+vXrY8qUKXHrrbfGf/3Xf8XkyZNj8uTJsWXLlo9cPADQ8eVlWZY1t/M777wT/fr1ixdffDE+85nPNNrm5ptvjkOHDsWzzz5bv2/cuHExcuTIWLBgwWkdp6amJgoLC6O6ujoKCgqaWy7QwobMWpG6hAbeemhS6hKA33G6398fac1IdXV1RET06dOnyTYVFRVRVlbWYN+ECROioqKiyT61tbVRU1PTYAMAOqdmh5G6urq466674g/+4A/ik5/8ZJPtKisro6ioqMG+oqKiqKysbLJPeXl5FBYW1m8lJSXNLRMAaOeaHUamT58eW7ZsiSVLlrRkPRERMXv27Kiurq7fdu/e3eLHAADah27N6TRjxox49tlnY+3atXHBBRectG1xcXFUVVU12FdVVRXFxcVN9snPz4/8/PzmlAYAdDA5zYxkWRYzZsyIp59+OlavXh1Dhw49ZZ/S0tJYtWpVg30rV66M0tLS3CoFADqlnGZGpk+fHosXL45nnnkmevXqVb/uo7CwMHr27BkREVOnTo2BAwdGeXl5RER87Wtfi/Hjx8fcuXNj0qRJsWTJktiwYUM89thjLXwqAEBHlNPMyKOPPhrV1dVx1VVXRf/+/eu3pUuX1rfZtWtX7N27t/71lVdeGYsXL47HHnssRowYEU899VQsX778pIteAYAzR04zI6dzS5I1a9acsO+mm26Km266KZdDAQBnCM+mAQCSEkYAgKSadWkvcOZpb7d+b8zxNbo9PHQMZkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkXE0DNKojXD1zKo2dgytsoP0xMwIAJCWMAABJCSMAQFLCCACQlDACACQljAAASQkjAEBSwggAkJQwAgAkJYwAAEkJIwBAUsIIAJCUMAIAJCWMAABJCSMAQFLCCACQVLfUBQC0pSGzVjR4/dZDkxJVAhwjjAAnfEEDtCU/0wAASQkjAEBSwggAkJQwAgAkJYwAAEkJIwBAUsIIAJCUMAIAJCWMAABJCSMAQFLCCACQlDACACQljAAASQkjAEBSwggAkJQwAgAkJYwAAEkJIwBAUsIIAJBUt9QFAG1vyKwVqUtoNxobi7cempSgEjhzmRkBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASCrnMLJ27dq4/vrrY8CAAZGXlxfLly8/afs1a9ZEXl7eCVtlZWVzawYAOpGcw8ihQ4dixIgRMX/+/Jz6bd++Pfbu3Vu/9evXL9dDAwCdULdcO0ycODEmTpyY84H69esXvXv3zrkfANC5tdmakZEjR0b//v3jj/7oj+Kll146adva2tqoqalpsAEAnVOrh5H+/fvHggUL4kc/+lH86Ec/ipKSkrjqqqvitddea7JPeXl5FBYW1m8lJSWtXSYAkEhelmVZszvn5cXTTz8dkydPzqnf+PHjY9CgQfGDH/yg0fdra2ujtra2/nVNTU2UlJREdXV1FBQUNLdc4P8NmbUidQnt2lsPTUpdAnQKNTU1UVhYeMrv75zXjLSEMWPGxLp165p8Pz8/P/Lz89uwIgAglST3Gdm0aVP0798/xaEBgHYm55mRgwcPxptvvln/eseOHbFp06bo06dPDBo0KGbPnh179uyJJ598MiIi5s2bF0OHDo1hw4bFhx9+GI8//nisXr06/v3f/73lzgIA6LByDiMbNmyIq6++uv71zJkzIyJi2rRpsWjRoti7d2/s2rWr/v3Dhw/H3XffHXv27Imzzz47LrvssviP//iPBn8DADhzfaQFrG3ldBfAAKfHAtaTs4AVWsbpfn97Ng0AkJQwAgAkJYwAAEkJIwBAUsIIAJCUMAIAJCWMAABJJXk2DdB23FMkd8ePmfuOQOsyMwIAJCWMAABJCSMAQFLCCACQlDACACQljAAASQkjAEBSwggAkJQwAgAkJYwAAEkJIwBAUsIIAJCUMAIAJCWMAABJCSMAQFLCCACQlDACACQljAAASQkjAEBS3VIXALSsIbNWpC6h02lsTN96aFKCSqBzMjMCACQljAAASQkjAEBSwggAkJQwAgAkJYwAAEkJIwBAUsIIAJCUMAIAJOUOrNCBudtqOsePvTuyQvOZGQEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEgq5zCydu3auP7662PAgAGRl5cXy5cvP2WfNWvWxKc+9anIz8+PCy+8MBYtWtSMUgGAzijnMHLo0KEYMWJEzJ8//7Ta79ixIyZNmhRXX311bNq0Ke6666647bbb4qc//WnOxQIAnU+3XDtMnDgxJk6ceNrtFyxYEEOHDo25c+dGRMQll1wS69ati+985zsxYcKEXA8PAHQyOYeRXFVUVERZWVmDfRMmTIi77rqryT61tbVRW1tb/7qmpqa1yoMOZcisFalLoAmN/W/z1kOTElQCHU+rL2CtrKyMoqKiBvuKioqipqYmPvjgg0b7lJeXR2FhYf1WUlLS2mUCAIm0y6tpZs+eHdXV1fXb7t27U5cEALSSVv+Zpri4OKqqqhrsq6qqioKCgujZs2ejffLz8yM/P7+1SwMA2oFWnxkpLS2NVatWNdi3cuXKKC0tbe1DAwAdQM5h5ODBg7Fp06bYtGlTRPzm0t1NmzbFrl27IuI3P7FMnTq1vv2dd94Z//M//xN//ud/Htu2bYvvf//78cMf/jC+/vWvt8wZAAAdWs5hZMOGDTFq1KgYNWpURETMnDkzRo0aFffff39EROzdu7c+mEREDB06NFasWBErV66MESNGxNy5c+Pxxx93WS8AEBEReVmWZamLOJWampooLCyM6urqKCgoSF0OJOPS3o7Fpb2c6U73+7tdXk0DAJw5hBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKRa/am9AGeq4++Y646s0DhhBNopt34HzhR+pgEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKTcDh6gjTR2i3/PqwFhBNoNz6IBzlR+pgEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApYQQASEoYAQCSEkYAgKSEEQAgKWEEAEiqW+oC4Ew0ZNaK1CXQThz/WXjroUmJKoF0zIwAAEkJIwBAUsIIAJCUMAIAJCWMAABJCSMAQFIu7QVoRxq77NvlvnR2wgi0AfcVAWian2kAgKSEEQAgKWEEAEhKGAEAkhJGAICkhBEAIClhBABIqllhZP78+TFkyJDo0aNHjB07Nl599dUm2y5atCjy8vIabD169Gh2wQBA55JzGFm6dGnMnDkz5syZE6+99lqMGDEiJkyYEPv27WuyT0FBQezdu7d+27lz50cqGgDoPHIOI3//938ft99+e9xyyy1x6aWXxoIFC+Lss8+OhQsXNtknLy8viouL67eioqKPVDQA0HnkFEYOHz4cGzdujLKyst/+gS5doqysLCoqKprsd/DgwRg8eHCUlJTEjTfeGK+//vpJj1NbWxs1NTUNNgCgc8opjLz77rtx9OjRE2Y2ioqKorKystE+n/jEJ2LhwoXxzDPPxD//8z9HXV1dXHnllfH22283eZzy8vIoLCys30pKSnIpEwDoQFr9aprS0tKYOnVqjBw5MsaPHx8//vGP42Mf+1j84z/+Y5N9Zs+eHdXV1fXb7t27W7tMACCRnJ7a27dv3+jatWtUVVU12F9VVRXFxcWn9TfOOuusGDVqVLz55ptNtsnPz4/8/PxcSgMAOqicZka6d+8eo0ePjlWrVtXvq6uri1WrVkVpaelp/Y2jR4/G5s2bo3///rlVCgB0SjnNjEREzJw5M6ZNmxaXX355jBkzJubNmxeHDh2KW265JSIipk6dGgMHDozy8vKIiHjwwQdj3LhxceGFF8b+/fvj4Ycfjp07d8Ztt93WsmcCAHRIOYeRm2++Od555524//77o7KyMkaOHBnPP/98/aLWXbt2RZcuv51wef/99+P222+PysrKOO+882L06NGxfv36uPTSS1vuLACADisvy7IsdRGnUlNTE4WFhVFdXR0FBQWpy4GcDZm1InUJdGBvPTQpdQnQLKf7/e3ZNABAUsIIAJCUMAIAJJXzAlbg5KwPoaUd/5myhoTOxswIAJCUMAIAJCWMAABJCSMAQFLCCACQlDACACQljAAASQkjAEBSwggAkJQ7sMJH5I6rtLXGPnPuykpHZmYEAEhKGAEAkhJGAICkhBEAIClhBABIShgBAJISRgCApIQRACApNz2DHLjBGe3V8Z9NN0GjIzEzAgAkJYwAAEkJIwBAUsIIAJCUMAIAJCWMAABJCSMAQFLuMwIn4b4idFSNfXbde4T2yswIAJCUMAIAJCWMAABJWTMC/8/6EDo7z6+hvTIzAgAkJYwAAEkJIwBAUsIIAJCUMAIAJCWMAABJCSMAQFLCCACQlJueAZyhPEyP9kIY4YzljqsA7YOfaQCApIQRACApYQQASMqaEc4I1ofA6fFkX1IwMwIAJCWMAABJCSMAQFLWjNApWSMCLcON0WgLZkYAgKSEEQAgKT/T0OH5SQbalst/aWlmRgCApMyMAPCRWOTKRyWM0KH4SQag8xFGaNeED+iYrCshF9aMAABJmRkBoNVZV8LJNGtmZP78+TFkyJDo0aNHjB07Nl599dWTtl+2bFlcfPHF0aNHjxg+fHg899xzzSqWzm3IrBUnbAB0fjnPjCxdujRmzpwZCxYsiLFjx8a8efNiwoQJsX379ujXr98J7devXx9TpkyJ8vLyuO6662Lx4sUxefLkeO211+KTn/xki5wEHZOwAWc260o4Ji/LsiyXDmPHjo0rrrgi/uEf/iEiIurq6qKkpCT+7M/+LGbNmnVC+5tvvjkOHToUzz77bP2+cePGxciRI2PBggWndcyampooLCyM6urqKCgoyKVcEhE0gNYitHQcp/v9ndPMyOHDh2Pjxo0xe/bs+n1dunSJsrKyqKioaLRPRUVFzJw5s8G+CRMmxPLly5s8Tm1tbdTW1ta/rq6ujojfnBTpfXLOT1OXAJzBBn192SnbbHlgQhtUwqkc+94+1bxHTmHk3XffjaNHj0ZRUVGD/UVFRbFt27ZG+1RWVjbavrKyssnjlJeXxwMPPHDC/pKSklzKBeAMVTgvdQX8rgMHDkRhYWGT77fLq2lmz57dYDalrq4u3nvvvTj//PMjLy8vYWXp1dTURElJSezevdtPVq3MWLcN49w2jHPbMM4NZVkWBw4ciAEDBpy0XU5hpG/fvtG1a9eoqqpqsL+qqiqKi4sb7VNcXJxT+4iI/Pz8yM/Pb7Cvd+/euZTa6RUUFPigtxFj3TaMc9swzm3DOP/WyWZEjsnp0t7u3bvH6NGjY9WqVfX76urqYtWqVVFaWtpon9LS0gbtIyJWrlzZZHsA4MyS8880M2fOjGnTpsXll18eY8aMiXnz5sWhQ4filltuiYiIqVOnxsCBA6O8vDwiIr72ta/F+PHjY+7cuTFp0qRYsmRJbNiwIR577LGWPRMAoEPKOYzcfPPN8c4778T9998flZWVMXLkyHj++efrF6nu2rUrunT57YTLlVdeGYsXL4777rsv/uIv/iI+/vGPx/Lly91jpJny8/Njzpw5J/yMRcsz1m3DOLcN49w2jHPz5HyfEQCAluRBeQBAUsIIAJCUMAIAJCWMAABJCSPt0HvvvRdf+MIXoqCgIHr37h233nprHDx48KR9Pvzww5g+fXqcf/75ce6558Yf//Efn3CzuWN+/etfxwUXXBB5eXmxf//+VjiDjqE1xvnnP/95TJkyJUpKSqJnz55xySWXxHe/+93WPpV2Zf78+TFkyJDo0aNHjB07Nl599dWTtl+2bFlcfPHF0aNHjxg+fHg899xzDd7Psizuv//+6N+/f/Ts2TPKysrijTfeaM1T6BBacpyPHDkS9957bwwfPjzOOeecGDBgQEydOjV+9atftfZpdAgt/Zn+XXfeeWfk5eXFvHnzWrjqDiaj3bn22muzESNGZC+//HL2s5/9LLvwwguzKVOmnLTPnXfemZWUlGSrVq3KNmzYkI0bNy678sorG2174403ZhMnTswiInv//fdb4Qw6htYY53/6p3/KvvrVr2Zr1qzJ/vu//zv7wQ9+kPXs2TP73ve+19qn0y4sWbIk6969e7Zw4cLs9ddfz26//fasd+/eWVVVVaPtX3rppaxr167Z3/3d32Vbt27N7rvvvuyss87KNm/eXN/moYceygoLC7Ply5dnP//5z7MbbrghGzp0aPbBBx+01Wm1Oy09zvv378/KysqypUuXZtu2bcsqKiqyMWPGZKNHj27L02qXWuMzfcyPf/zjbMSIEdmAAQOy73znO618Ju2bMNLObN26NYuI7D//8z/r9/3kJz/J8vLysj179jTaZ//+/dlZZ52VLVu2rH7fL3/5yywisoqKigZtv//972fjx4/PVq1adUaHkdYe59/1la98Jbv66qtbrvh2bMyYMdn06dPrXx89ejQbMGBAVl5e3mj7z3/+89mkSZMa7Bs7dmz2J3/yJ1mWZVldXV1WXFycPfzww/Xv79+/P8vPz8/+9V//tRXOoGNo6XFuzKuvvppFRLZz586WKbqDaq2xfvvtt7OBAwdmW7ZsyQYPHnzGhxE/07QzFRUV0bt377j88svr95WVlUWXLl3ilVdeabTPxo0b48iRI1FWVla/7+KLL45BgwZFRUVF/b6tW7fGgw8+GE8++WSDG9OdiVpznI9XXV0dffr0abni26nDhw/Hxo0bG4xPly5doqysrMnxqaioaNA+ImLChAn17Xfs2BGVlZUN2hQWFsbYsWNPOuadWWuMc2Oqq6sjLy/vjH4uWGuNdV1dXXzpS1+Kb3zjGzFs2LDWKb6DObO/kdqhysrK6NevX4N93bp1iz59+kRlZWWTfbp3737CPxpFRUX1fWpra2PKlCnx8MMPx6BBg1ql9o6ktcb5eOvXr4+lS5fGHXfc0SJ1t2fvvvtuHD16tP5uzMecbHwqKytP2v7Yf3P5m51da4zz8T788MO49957Y8qUKWf0w95aa6z/9m//Nrp16xZf/epXW77oDkoYaSOzZs2KvLy8k27btm1rtePPnj07LrnkkvjiF7/YasdoD1KP8+/asmVL3HjjjTFnzpy45ppr2uSY8FEdOXIkPv/5z0eWZfHoo4+mLqfT2bhxY3z3u9+NRYsWRV5eXupy2o2cn01D89x9993x5S9/+aRtfu/3fi+Ki4tj3759Dfb/7//+b7z33ntRXFzcaL/i4uI4fPhw7N+/v8H/a6+qqqrvs3r16ti8eXM89dRTEfGbKxQiIvr27Rt/+Zd/GQ888EAzz6x9ST3Ox2zdujU++9nPxh133BH33Xdfs86lo+nbt2907dr1hKu4GhufY4qLi0/a/th/q6qqon///g3ajBw5sgWr7zhaY5yPORZEdu7cGatXrz6jZ0UiWmesf/azn8W+ffsazFAfPXo07r777pg3b1689dZbLXsSHUXqRSs0dGxh5YYNG+r3/fSnPz2thZVPPfVU/b5t27Y1WFj55ptvZps3b67fFi5cmEVEtn79+iZXhXdmrTXOWZZlW7Zsyfr165d94xvfaL0TaKfGjBmTzZgxo/710aNHs4EDB550sd91113XYF9paekJC1gfeeSR+verq6stYG3hcc6yLDt8+HA2efLkbNiwYdm+fftap/AOqKXH+t13323wb/HmzZuzAQMGZPfee2+2bdu21juRdk4YaYeuvfbabNSoUdkrr7ySrVu3Lvv4xz/e4JLTt99+O/vEJz6RvfLKK/X77rzzzmzQoEHZ6tWrsw0bNmSlpaVZaWlpk8d44YUXzuirabKsdcZ58+bN2cc+9rHsi1/8YrZ379767Uz5x33JkiVZfn5+tmjRomzr1q3ZHXfckfXu3TurrKzMsizLvvSlL2WzZs2qb//SSy9l3bp1yx555JHsl7/8ZTZnzpxGL+3t3bt39swzz2S/+MUvshtvvNGlvS08zocPH85uuOGG7IILLsg2bdrU4LNbW1ub5Bzbi9b4TB/P1TTCSLv061//OpsyZUp27rnnZgUFBdktt9ySHThwoP79HTt2ZBGRvfDCC/X7Pvjgg+wrX/lKdt5552Vnn3129rnPfS7bu3dvk8cQRlpnnOfMmZNFxAnb4MGD2/DM0vre976XDRo0KOvevXs2ZsyY7OWXX65/b/z48dm0adMatP/hD3+YXXTRRVn37t2zYcOGZStWrGjwfl1dXfZXf/VXWVFRUZafn5999rOfzbZv394Wp9KuteQ4H/usN7b97uf/TNXSn+njCSNZlpdl/794AAAgAVfTAABJCSMAQFLCCACQlDACACQljAAASQkjAEBSwggAkJQwAgAkJYwAAEkJIwBAUsIIAJCUMAIAJPV/1BuirZj1f2oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x=model_dict['tok_embeddings.weight'].flatten().float(), bins=100, range=(-0.05, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 9,\n",
       " 'model': OrderedDict([('attention.wq.weight',\n",
       "               tensor([[-2.7618e-03, -2.9053e-02, -3.1586e-03,  ...,  7.3547e-03,\n",
       "                        -4.6875e-02, -2.1606e-02],\n",
       "                       [ 2.6367e-02,  3.3264e-03, -8.4839e-03,  ..., -7.5378e-03,\n",
       "                        -5.7678e-03,  5.6458e-03],\n",
       "                       [-1.2512e-02, -6.9824e-02, -3.8605e-03,  ..., -1.2573e-02,\n",
       "                        -4.9805e-02,  2.0508e-02],\n",
       "                       ...,\n",
       "                       [-5.2795e-03, -1.4709e-02,  4.1504e-02,  ...,  5.4321e-03,\n",
       "                        -3.2349e-03,  4.4346e-05],\n",
       "                       [ 4.4632e-04,  3.1250e-02, -6.1523e-02,  ..., -2.3804e-03,\n",
       "                         1.1444e-03, -1.8768e-03],\n",
       "                       [-4.1504e-03, -1.6724e-02,  3.0396e-02,  ...,  8.6060e-03,\n",
       "                         8.0872e-04,  3.1433e-03]])),\n",
       "              ('attention.wk.weight',\n",
       "               tensor([[-0.1040, -0.1543,  0.0737,  ...,  0.0312, -0.0231,  0.0442],\n",
       "                       [-0.0447, -0.0293,  0.0396,  ...,  0.0067,  0.0242, -0.0035],\n",
       "                       [-0.0564, -0.0869,  0.0188,  ...,  0.0193, -0.0073,  0.0293],\n",
       "                       ...,\n",
       "                       [ 0.0136,  0.0356, -0.0162,  ..., -0.0177,  0.0018,  0.0102],\n",
       "                       [-0.0052, -0.0284,  0.0289,  ...,  0.0135,  0.0055, -0.0042],\n",
       "                       [ 0.0039, -0.0100,  0.0118,  ..., -0.0153,  0.0016, -0.0206]])),\n",
       "              ('attention.wv.weight',\n",
       "               tensor([[ 0.0089, -0.0020, -0.0005,  ...,  0.0026,  0.0008,  0.0031],\n",
       "                       [ 0.0002, -0.0040, -0.0001,  ..., -0.0029, -0.0040,  0.0025],\n",
       "                       [ 0.0102,  0.0008,  0.0015,  ..., -0.0062,  0.0080,  0.0070],\n",
       "                       ...,\n",
       "                       [ 0.0079,  0.0008,  0.0029,  ..., -0.0014, -0.0064, -0.0064],\n",
       "                       [ 0.0032,  0.0012,  0.0025,  ...,  0.0027, -0.0046, -0.0011],\n",
       "                       [-0.0024, -0.0070,  0.0017,  ...,  0.0033,  0.0071, -0.0034]])),\n",
       "              ('attention.wo.weight',\n",
       "               tensor([[ 0.0020, -0.0010, -0.0092,  ..., -0.0011, -0.0132,  0.0021],\n",
       "                       [-0.0023,  0.0153,  0.0090,  ..., -0.0031, -0.0066,  0.0049],\n",
       "                       [-0.0023,  0.0006,  0.0032,  ..., -0.0074, -0.0009, -0.0010],\n",
       "                       ...,\n",
       "                       [ 0.0073, -0.0038, -0.0393,  ...,  0.0165, -0.0033,  0.0060],\n",
       "                       [-0.0094,  0.0005, -0.0048,  ..., -0.0017, -0.0024, -0.0027],\n",
       "                       [-0.0075,  0.0029, -0.0044,  ..., -0.0052,  0.0033,  0.0013]])),\n",
       "              ('feed_forward.w1.weight',\n",
       "               tensor([[-1.1549e-02, -5.4396e-03, -4.0058e-03,  ...,  1.4351e-02,\n",
       "                        -1.3360e-02, -3.4561e-03],\n",
       "                       [-5.9537e-03, -2.5368e-02, -2.8398e-03,  ...,  1.2642e-02,\n",
       "                         4.5071e-03, -1.2370e-03],\n",
       "                       [ 1.0417e-02, -1.4679e-04,  1.2066e-02,  ..., -5.1081e-04,\n",
       "                         4.1322e-03,  4.2623e-03],\n",
       "                       ...,\n",
       "                       [ 2.9433e-05, -1.1298e-02, -9.3961e-03,  ..., -1.1276e-02,\n",
       "                         4.8924e-03, -1.7537e-02],\n",
       "                       [-3.9874e-03, -8.8200e-04, -4.5389e-03,  ..., -1.7292e-02,\n",
       "                        -1.3375e-02,  4.3739e-03],\n",
       "                       [-5.7417e-03,  9.4263e-03,  4.8875e-03,  ..., -6.6815e-03,\n",
       "                         1.3962e-02, -4.4973e-03]])),\n",
       "              ('feed_forward.w2.weight',\n",
       "               tensor([[ 0.0098, -0.0128, -0.0084,  ...,  0.0087, -0.0043,  0.0130],\n",
       "                       [ 0.0184, -0.0099, -0.0055,  ..., -0.0016,  0.0153,  0.0031],\n",
       "                       [ 0.0078, -0.0052, -0.0009,  ..., -0.0029,  0.0006, -0.0132],\n",
       "                       ...,\n",
       "                       [ 0.0086, -0.0185,  0.0231,  ..., -0.0203,  0.0064, -0.0143],\n",
       "                       [-0.0135, -0.0071, -0.0103,  ...,  0.0068, -0.0027, -0.0119],\n",
       "                       [-0.0039,  0.0084,  0.0090,  ..., -0.0090, -0.0051, -0.0132]])),\n",
       "              ('feed_forward.w3.weight',\n",
       "               tensor([[-0.0138,  0.0036,  0.0058,  ...,  0.0013, -0.0067, -0.0019],\n",
       "                       [-0.0118,  0.0163,  0.0002,  ..., -0.0078, -0.0049,  0.0097],\n",
       "                       [-0.0049, -0.0043,  0.0044,  ..., -0.0081, -0.0029,  0.0045],\n",
       "                       ...,\n",
       "                       [-0.0027,  0.0117,  0.0056,  ..., -0.0056,  0.0060,  0.0129],\n",
       "                       [-0.0167,  0.0111,  0.0048,  ...,  0.0052,  0.0091, -0.0055],\n",
       "                       [-0.0045, -0.0138, -0.0012,  ..., -0.0041, -0.0052,  0.0092]])),\n",
       "              ('attention_norm.weight',\n",
       "               tensor([0.0537, 0.2090, 0.4492,  ..., 0.0859, 0.0437, 0.0292])),\n",
       "              ('ffn_norm.weight',\n",
       "               tensor([0.1327, 0.1212, 0.1350,  ..., 0.1344, 0.1336, 0.1306]))]),\n",
       " 'optim': {'state': {12: {'step': tensor(1280.),\n",
       "    'exp_avg': tensor([[ 1.6185e-11, -1.0814e-11, -3.1461e-12,  ...,  3.8720e-11,\n",
       "             -1.8638e-11, -9.0642e-12],\n",
       "            [-1.0605e-11, -3.4859e-11, -5.4144e-12,  ..., -1.5653e-11,\n",
       "              3.4785e-11, -3.6188e-12],\n",
       "            [-5.5924e-12,  1.0908e-11, -8.3542e-12,  ...,  1.1051e-11,\n",
       "              5.6468e-11, -1.3313e-11],\n",
       "            ...,\n",
       "            [ 1.2252e-11, -2.1003e-11, -1.3740e-11,  ..., -8.3023e-12,\n",
       "              1.9180e-11, -1.2548e-11],\n",
       "            [-4.5614e-12, -8.7807e-12,  3.0762e-12,  ...,  1.7899e-11,\n",
       "             -2.8030e-11, -1.0720e-11],\n",
       "            [-4.8876e-11, -7.2279e-12, -4.0058e-13,  ..., -4.0540e-11,\n",
       "              2.8848e-11,  2.4300e-11]]),\n",
       "    'exp_avg_sq': tensor([[5.4936e-21, 5.3514e-21, 4.8661e-21,  ..., 9.5714e-21, 1.1350e-20,\n",
       "             9.4292e-21],\n",
       "            [5.8226e-21, 5.0188e-21, 5.2155e-21,  ..., 1.0214e-20, 1.2766e-20,\n",
       "             9.6558e-21],\n",
       "            [5.7112e-21, 5.5037e-21, 5.0849e-21,  ..., 1.0620e-20, 1.3552e-20,\n",
       "             1.0381e-20],\n",
       "            ...,\n",
       "            [7.6204e-21, 7.0842e-21, 6.1763e-21,  ..., 1.3689e-20, 1.6416e-20,\n",
       "             1.2216e-20],\n",
       "            [5.5944e-21, 5.1754e-21, 4.6658e-21,  ..., 9.0784e-21, 1.1686e-20,\n",
       "             9.5543e-21],\n",
       "            [5.3030e-21, 4.8407e-21, 4.6576e-21,  ..., 9.9562e-21, 1.1104e-20,\n",
       "             8.9123e-21]])},\n",
       "   13: {'step': tensor(1280.),\n",
       "    'exp_avg': tensor([[ 1.9084e-12, -4.6134e-11, -6.3187e-11,  ...,  3.4000e-11,\n",
       "              4.0563e-11,  4.7974e-11],\n",
       "            [-7.1863e-11, -1.4247e-11,  2.6123e-11,  ..., -5.8260e-11,\n",
       "             -4.5427e-12, -9.9420e-11],\n",
       "            [ 2.6706e-11, -4.1588e-11,  1.5976e-11,  ...,  3.0888e-11,\n",
       "             -4.3367e-11,  1.9969e-11],\n",
       "            ...,\n",
       "            [ 7.4332e-11, -4.5509e-11, -3.6766e-11,  ..., -1.1778e-11,\n",
       "              5.3991e-11, -4.5803e-11],\n",
       "            [-2.5501e-11,  5.5771e-11,  5.3245e-12,  ...,  8.8867e-11,\n",
       "              1.4000e-11,  6.9799e-11],\n",
       "            [ 6.4584e-11,  5.7477e-11,  1.6329e-11,  ...,  1.4016e-12,\n",
       "              5.7044e-11, -1.2246e-12]]),\n",
       "    'exp_avg_sq': tensor([[2.2558e-20, 2.1191e-20, 2.5630e-20,  ..., 2.3994e-20, 2.5632e-20,\n",
       "             2.2313e-20],\n",
       "            [2.3810e-20, 1.9927e-20, 2.4389e-20,  ..., 2.4114e-20, 2.4087e-20,\n",
       "             2.4417e-20],\n",
       "            [2.3868e-20, 1.9411e-20, 2.4473e-20,  ..., 2.4713e-20, 2.3476e-20,\n",
       "             2.3596e-20],\n",
       "            ...,\n",
       "            [2.6936e-20, 2.1091e-20, 2.7390e-20,  ..., 2.9313e-20, 2.3231e-20,\n",
       "             2.5451e-20],\n",
       "            [2.2696e-20, 1.8551e-20, 2.3588e-20,  ..., 2.4899e-20, 2.6119e-20,\n",
       "             2.4033e-20],\n",
       "            [2.3089e-20, 2.0985e-20, 2.5129e-20,  ..., 2.6652e-20, 2.1659e-20,\n",
       "             2.3519e-20]])},\n",
       "   14: {'step': tensor(1280.),\n",
       "    'exp_avg': tensor([[ 2.7914e-11, -2.5103e-12,  5.2132e-11,  ..., -2.5391e-11,\n",
       "             -3.4505e-11,  4.2273e-11],\n",
       "            [-1.9292e-11, -5.0381e-12,  1.4441e-11,  ..., -5.6857e-11,\n",
       "             -4.6622e-11, -7.2467e-12],\n",
       "            [ 8.2995e-12, -1.0872e-10, -3.7925e-11,  ..., -4.9014e-11,\n",
       "             -3.7106e-11,  1.3471e-11],\n",
       "            ...,\n",
       "            [ 7.5067e-13,  3.6194e-11, -2.6505e-11,  ...,  3.5856e-12,\n",
       "             -1.1318e-10, -1.3697e-13],\n",
       "            [-1.4928e-11, -1.4500e-11,  1.0448e-11,  ...,  5.0609e-11,\n",
       "             -1.5364e-11,  7.6271e-11],\n",
       "            [-5.5957e-11,  4.8141e-11,  8.1457e-12,  ...,  4.7638e-11,\n",
       "             -2.8219e-11, -2.9525e-11]]),\n",
       "    'exp_avg_sq': tensor([[1.7940e-20, 1.8733e-20, 1.6509e-20,  ..., 1.9379e-20, 1.7225e-20,\n",
       "             1.9071e-20],\n",
       "            [1.9850e-20, 1.7888e-20, 1.8420e-20,  ..., 2.1900e-20, 2.1426e-20,\n",
       "             1.8940e-20],\n",
       "            [2.0079e-20, 2.2234e-20, 1.8801e-20,  ..., 2.0892e-20, 1.9176e-20,\n",
       "             2.1850e-20],\n",
       "            ...,\n",
       "            [2.4523e-20, 2.6323e-20, 2.1645e-20,  ..., 2.4818e-20, 2.1838e-20,\n",
       "             2.4314e-20],\n",
       "            [1.8847e-20, 1.8919e-20, 1.7986e-20,  ..., 2.2327e-20, 2.0697e-20,\n",
       "             1.7622e-20],\n",
       "            [1.8196e-20, 1.7486e-20, 1.6770e-20,  ..., 1.8323e-20, 1.7036e-20,\n",
       "             1.8152e-20]])},\n",
       "   15: {'step': tensor(1280.),\n",
       "    'exp_avg': tensor([[-6.5860e-12, -7.6678e-11, -3.7989e-11,  ...,  1.0533e-11,\n",
       "              3.3281e-12, -8.0063e-12],\n",
       "            [ 1.5804e-11, -4.8584e-11, -3.4268e-11,  ...,  3.6198e-11,\n",
       "              3.2803e-11, -7.1632e-11],\n",
       "            [ 2.8985e-11, -1.2184e-11,  5.1635e-12,  ..., -9.2457e-12,\n",
       "             -5.6590e-11, -2.8281e-11],\n",
       "            ...,\n",
       "            [-8.4727e-12,  6.3140e-11,  2.5236e-11,  ..., -8.3076e-12,\n",
       "              5.7208e-11,  1.3816e-11],\n",
       "            [-4.2494e-11,  2.7432e-11, -2.3931e-11,  ...,  8.2008e-12,\n",
       "              4.3688e-11,  1.5787e-11],\n",
       "            [ 8.8697e-12, -4.8498e-11, -1.3669e-11,  ..., -1.5250e-11,\n",
       "             -3.0743e-11,  8.8153e-11]]),\n",
       "    'exp_avg_sq': tensor([[2.2949e-20, 1.8717e-20, 2.6937e-20,  ..., 2.2762e-20, 2.3017e-20,\n",
       "             2.3085e-20],\n",
       "            [2.3890e-20, 1.9440e-20, 2.2513e-20,  ..., 2.6072e-20, 2.3967e-20,\n",
       "             2.2294e-20],\n",
       "            [2.2781e-20, 1.9414e-20, 2.3374e-20,  ..., 2.2920e-20, 2.4263e-20,\n",
       "             2.1805e-20],\n",
       "            ...,\n",
       "            [2.6518e-20, 2.3839e-20, 2.4402e-20,  ..., 2.8252e-20, 2.8465e-20,\n",
       "             2.5939e-20],\n",
       "            [2.2824e-20, 1.9410e-20, 2.4532e-20,  ..., 2.6711e-20, 2.4223e-20,\n",
       "             2.2382e-20],\n",
       "            [2.1851e-20, 1.9239e-20, 2.2541e-20,  ..., 2.3943e-20, 2.3546e-20,\n",
       "             2.2165e-20]])},\n",
       "   17: {'step': tensor(1280.),\n",
       "    'exp_avg': tensor([ 3.5820e-10, -3.4853e-10,  8.6560e-10,  ...,  2.1715e-09,\n",
       "             8.4196e-10, -4.1553e-11]),\n",
       "    'exp_avg_sq': tensor([6.3894e-16, 5.4128e-16, 8.1748e-16,  ..., 7.8450e-16, 6.5200e-16,\n",
       "            5.9820e-16])}},\n",
       "  'param_groups': [{'lr': 0.0009872179631939468,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'params': [0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     8,\n",
       "     9,\n",
       "     10,\n",
       "     11,\n",
       "     12,\n",
       "     13,\n",
       "     14,\n",
       "     15,\n",
       "     16,\n",
       "     17]}]}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "l0_dict = torch.load('./train/20240604-block_0-wo+fn+w1+w2+w3-lr1e-3/model_10-acc5.5827.chkpt', map_location=\"cpu\")\n",
    "l0_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention.wq.weight\n",
      "attention.wk.weight\n",
      "attention.wv.weight\n",
      "attention.wo.weight\n",
      "feed_forward.w1.weight\n",
      "feed_forward.w2.weight\n",
      "feed_forward.w3.weight\n",
      "attention_norm.weight\n",
      "ffn_norm.weight\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(l0_dict['model'].keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
